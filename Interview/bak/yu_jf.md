+
+
+
++
+
+
+
++
+
+
+
++==

## 自我介绍

面试官好，我叫虞结福，现在是杭州电子科技大学电子信息专业的研三硕士生，我的课题方向是车牌识别，这是实验室和企业的一个横向课题，比较偏实际应用。目前研究生阶段有一篇车牌识别的专利在投，还有一篇CCF-C 论文已经被接收，然后课外实践方面，在研二暑假参加学校的数学建模集训，也是和队友一起拿到了华为杯研究生数学建模全国二等奖。

软件开发方面，我在本科的时候就开始使用 C# 做 winform 开发，研究生阶段又学了 Python 进行数据处理分析和深度学习研究。

开发的技术栈方面，我对 Java 包括面向对象，集合，JUC，和常用的设计模式有一定的了解，然后 Apache Spring 系列开发框架，还有关系型数据库 MySQL 和非关系型数据库 Redis ，和其他的一些开发组件都有学习和实践的经验。

目前是做了一个类似腾讯课堂的微服务架构学习平台作为项目开发实践，还有一个前后端分离的博客YBlog，已经在云服务器进行容器化部署上线。后端代码托管在Gitee上，代码现在是持续优化的状态，也方便自己做日常的积累。



## HW



### ICT 计算产品线

**应用软件开发工程师：** 负责 IDE 调优调试工具链的设计与开发，构筑融合调优调试基础能力。

IDE （集成开发环境）用于提供程序开发环境的[应用程序](https://baike.baidu.com/item/应用程序/5985445?fromModule=lemma_inlink)，一般包括[代码](https://baike.baidu.com/item/代码/86048?fromModule=lemma_inlink)编辑器、[编译器](https://baike.baidu.com/item/编译器/8853067?fromModule=lemma_inlink)、[调试器](https://baike.baidu.com/item/调试器/3351943?fromModule=lemma_inlink)和[图形用户界面](https://baike.baidu.com/item/图形用户界面/3352324?fromModule=lemma_inlink)等工具。集成了代码编写功能、分析功能、编译功能、调试功能等一体化的开发软件服务套。所有具备这一特性的软件或者软件套（组）都可以叫集成开发环境。

比如Visual Studio Code，IDEA，其中 ==CodeArts IDE for Java== 是华为面向 Java 开发者提供的开发测试工具， ==DevEco== 华为面向智能设备开发的IDE。



### 数学建模

==切割工艺：==
三阶段的排样方式[2]是一种特殊的剪切排样方式，采用齐头切的剪切方式。
同一阶段的剪切方向一致，相邻阶段的剪切 方向互相垂直，每一阶段的切割都是建立在前一阶段的切割结果之上，三阶段排样即共有 三个切割阶段。

==问题一：== 排样优化问题。其实是一个混合整数规划问题，数据集里面给出了很多种尺寸样式的物料，然后要求在满足切割工艺约束条件下完成生产订单需求，设计的切割方案要尽可能减少板材用量。
问题1约束：
1）在相同栈（stack）里的产品项（item）的宽度（或长度）应该相同；
2）最终切割生成的产品项是完整的，非拼接而成。

**解决方案：**
根据要求，我们需要满足在相同栈里的产品项 的宽度（或长度）应该相同，同时最终切割生成的产品项是要是完整的，不能进行拼接。 
所以我们将其分为三个阶段进行计算，首先将产品项组成不同的栈，然后再由栈合成不同 的条带，最后由条带组成一块块板材原片，求取最少所需的板材原片数量及板材利用率。


==问题二：== 订单组批问题。在原本的约束前提下，增加更多约束，并将订单分组，然后对每个批次进行独立切割排样，优化目标也是尽可能少的使用板材物料。
在满足子问题1约束的基础上进一步要求：
1)   每份订单当且仅当出现在一个批次中；
2)   每个批次中的相同材质的产品项（item）才能使用同一块板材原片进行排样；
3)   为保证加工环节快速流转，每个批次产品项（item）总数不能超过限定值；
4)   因工厂产能限制，每个批次产品项（item）的面积总和不能超过限定值；

**解决方案：**
子问题 2 在子问题 1 的基础上对全部订单进行组批，要求每份订单仅能出现在一个批 次中，并且每个批次中只有相同材质的产品项才能在同一块原片上进行排样，同时对单个 组批的产品项数量和总面积都有上限要求。根据题意组批不能过少，也不能过多。所以我 们利用每个批次中的产品项数量/单个组批的产品项数量上限、每个批次中的产品项面积和 /单个组批的产品项总面积上限对组批进行约束，针对材料和订单号进行进行聚类分组，然 后再对其进行排样优化，求取最少所需的板材原片数量及板材利用率。

**算法流程：**

本文首先按照订单的材料分布情况对其进 行聚类并利用自适应遗传算法使其满足约束条件，然后对贪心算法再次进行改进，使其满 足新模型的要求，最终解得数据集 B 中的各组数据满足条件的可行解



## Coding

### A1

```java
public class Solution {

    @Test
    public void codeTest() {
        int[] temperatures = {73,74,75,71,69,72,76,73};
        int[] result = dailyTemperatures(temperatures);
        System.out.print(Arrays.toString(result));
    }

    public int[] dailyTemperatures(int[] temperatures) {
        int len = temperatures.length;
        int[] res = new int[len];
        /**
         1、如果当前遍历的元素小于栈顶元素，可以直接入栈。
         2、若当前遍历元素大于等于栈顶元素，表示 栈顶元素的 右边的最大的元素就是 当前遍历的元素，
         所以弹出 栈顶元素，并记录
         如果栈不空的话，还要考虑新的栈顶与当前元素的大小关系。
         注意，单调栈里 加入的元素是 下标。
         */
        Deque<Integer> stack = new LinkedList<>();
        stack.push(0);
        // 遍历栈
        for (int i = 1; i < len; i++) {
            // 当前元素小于栈顶元素
            if (temperatures[i] <= temperatures[stack.peek()]) {
                stack.push(i);
            } else {
                // 大于的时候，且不为空 while比较
                while (!stack.isEmpty() && temperatures[i] > temperatures[stack.peek()]) {
                    res[stack.peek()] = i - stack.peek();
                    stack.pop();
                }
                stack.push(i);
            }
        }
        return res;
    }
}
```



### A2

```java
public class MinStack {

    private Stack<Integer> stack;
    private Stack<Integer> minStack;

    public MinStack() {
        stack = new Stack<>();
        minStack = new Stack<>();
    }

    /**
     * 将栈元素推入栈中
     * @param x 待入栈元素
     */
    public void push(int x) {
        stack.push(x);
        if (!minStack.isEmpty()) {
            int top = minStack.peek();
            // 小于等于则入栈
            if (x <= top) {
                minStack.push(x);
            }
        } else {
            // 栈为空
            minStack.push(x);
        }
    }

    /**
     * 删除栈顶元素
     */
    public void pop() {
        int pop = stack.pop();
        int top = minStack.peek();
        if (pop == top) {
            minStack.pop();
        }
    }

    /**
     * 获取栈顶部的元素
     * @return 栈顶元素
     */
    public int top() {
        return stack.peek();
    }

    /**
     * 获取栈中最小元素
     * @return 最小元素值
     */
    public int getMin() {
        return minStack.peek();
    }
}
```






## Java

### 关于jvm、jre、jdk

**Java 虚拟机（JVM）** 是运行 Java 字节码的虚拟机。

**JRE（Java Runtime Environment）** 是 Java 运行时环境。主要包括 Java 虚拟机（JVM）和 Java 基础类库（Class Library）。

**JDK（Java Development Kit）** 它是功能齐全的 Java SDK，提供给开发者使用的，能够创建和编译 Java 程序。他包含了 JRE，同时还包含了编译 java 源码的编译器 javac 以及一些其他工具比如 javadoc（文档注释工具）、jdb（调试器）、jconsole（基于 JMX 的可视化监控⼯具）、javap（反编译工具）等等。


### 1、什么是字节码？采用字节码的好处

在java中，字节码（**.class文件**，十六进制组成）是指能够被JVM理解的代码。它不面向任何特定的机器，只面向虚拟机，因此将Java编译成字节码文件后，在任何操作系统上都可以运行。这也使得Java具有优异的跨平台移植性以及不错的执行效率。

Java语言通过字节码的方式，在一定程度上解决了传统解释型语言（**Java 通过引入JIT，Just in Time，可以理解为编译型语言，但整体上通过JVM解释运行**）执行效率低的问题，同时又保留了解释型语言可移植的特点。

### 2、基本类型和包装类型的区别
- 基本数据类型：boolean  byte  short char  int float  long double
- 包装类型：String  Boolean  Byte  Short Character  Integer  Long  Double
- 用途：基本数据类型一般用于常量和局部变量，而包装类一般用于方法参数，并且可以使用泛型
- 存储位置：基本数据类型存于栈中，包装类（非 static ）存储在堆中
- 大小：基本数据类型占用空间很小，而对象会相对较大
- 比较方式：基本数据类型可以直接用==比较，而包装类之间使用 equals() 比较;
- 默认值：包装类的默认值为 null。
- **补充：** ==装箱==调用了包装类的 `valueOf()` 方法，==拆箱==调用了 `xxxValue()` 方法。

### 3、接口和抽象类的区别
面向对象编程，如果要提高程序的复用率，增加程序的可维护性，可扩展性，就必须是面向接口和抽象的编程。
- 一个类可以实现多个接口，但只能继承一个抽象类。
- 接口中没有构造方法和普通成员变量，抽象类中可以有构造方法和成员变量。
- 接口和抽象类都可以有静态成员变量，但接口默认且只能 public static final 修饰，抽象类不限制。
- 抽象类可以有普通方法；接口只有抽象方法，JDK8 可以有默认方法，JDK9 后可有私有方法。
- ~~抽象类可以有静态方法；接口没有，在 JDK8 可以有，且只能被接口类所调用。~~
- 抽象类用于描述类之间的共同特征，而接口用于实现类之间的共同行为。

**补充：** jdk8允许接口中定义==默认方法，使用default关键字==。这个特性使得在不破坏现有代码的情况下，可以向接口中添加新的方法。==向后兼容性==

- 允许在接口中提供方法实现（default关键字）
- 默认方法可以被接口的实现类继承或覆盖
- **解决接口的多重继承问题：** 因为一个类可以实现多个接口，而每个接口可以提供默认方法的实现。这就允许一个类在多个接口之间共享通用的实现。

### 4、面向对象三大特征

- 封装：对象可以隐藏自己的属性和方法不被外界访问
- 继承：通过继承子类可以使用现有类的所有功能，并在无需重新编写原来的类的情况下对这些功能进行扩展。
- 多态性：它是指在父类中定义的属性和方法被子类继承之后，可以具有不同的数据类型或表现出不同的行为，这使得同一个属性或方法在父类及其各个子类中具有不同的含义。

### 5、== 和equals 的区别

** == ** 常用于相同的基本数据类型之间的比较，也可用于相同类型的对象之间的比较；

- 如果 == 比较的是基本数据类型，那么比较的是两个基本数据类型的值是否相等；
- 如果 == 是比较的两个对象，那么比较的是两个对象的引用，也就是判断两个对象是否指向了同一块内存区域；

**equals** 方法主要用于两个对象之间，检测一个对象是否等于另一个对象

- 如果没有对 equals 方法进行重写，则比较的是引用类型的变量所指向的对象的地址；
- 诸如 String、Date 等类对 equals 方法进行了重写的话，比较的是所指向的对象的内容

### 6、引用拷贝、深拷贝和浅拷贝区别？

**浅拷贝**：浅拷贝会在堆上创建一个新的对象（==区别于引用拷贝的一点==），如果原对象内部的属性是引用类型的话，浅拷贝会直接复制内部对象的引用地址。~~也就是说拷贝对象和原对象共用同一个内部对象。~~

**深拷贝**：深拷贝会完全复制整个对象，包括这个对象所包含的内部对象。

**引用拷贝：**直接复制对象的引用地址

### 7、String、StringBuffer和StringBuilder的区别

- **可变与不可变：**

  - String 类中使用字符数组保存字符串，因为有 **`final`** 修饰符，所以 String 对象是不可变的。

    **对于已经存在的 String 对象的修改都是重新创建一个新的对象，然后把新的值复制进去。**

  - StringBuilder 与 StringBuffer 都继承自 AbstractStringBuilder 类，在 AbstractStringBuilder 中是使用字符数组保存字符串，这两种对象都是可变的。

- **是否线程安全：**

  - String 中对象是不可变的，可以理解为常量，因此线程安全

  - StringBuffer 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的
  - StringBuilder 是非线程安全的

- **性能**

  - 每次对 String 类型进行改变的时候，都会生成一个新的 String 对象，然后将指针指向新的 String 对象，因此性能较差

  - StringBuffer 每次都会对 StringBuffer 对象本身进行操作，而不是生成新的对象并改变对象引用。

    相同情况下使用StirngBuilder 相比使用StringBuffer **仅能获得10%~15%** 的性能提升，但却要**冒多线程不安全**的风险。

### 8、String为什么要设计成不可变的？

- 便于实现字符串池（String pool）

- 使多线程安全

- 加快字符串处理速度：由于 String 是不可变的，保证了 hashcode 的==唯一性==，于是在创建对象时其 hashcode 就可以放心的缓存了，不需要重新计算。这也就是 Map 喜欢将 String 作为 Key 的原因，处理速度要快过其它的键对象。所以 HashMap 中的键往往都使用 String。

### 9、什么是字符串常量池？

**字符串常量池：** JVM 为了提升性能和减少内存开销，避免字符的重复创建，其维护了一块特殊的内存空间，即字符串池，当需要使用字符串时，先去字符串池中查看该字符串是否已经存在，如果存在，则可以直接使用，如果不存在，初始化，并将该字符串放入字符串常量池中。

在 jdk8 中，常量池的位置在元空间（永久代（方法区）被元空间取代）

**Java 中三个常量池概念：**

- **`字符串常量池`** 在每个 JVM 中只有一份，存放的是字符串常量的引用值。

- **`class 文件常量池`** 是在编译的时候每个 class 文件都有的，在编译阶段，存放的是==常量==和==符号引用==。

- **`运行时常量池`** 在类加载完成之后，会将每个 class 常量池中的符号引用值转存到运行时常量池中。

  每个类都有一个运行时常量池，类在解析之后，将符号引用替换成直接引用，与字符串常量池中的引用值保持一致。

**符号引用和直接引用的关系：** ==符号引用==就是一个类中（或方法、引用字段）引入了其他的类，可是 JVM 当前并不知道引入的其他类的地址，就使用一个符号来代替。等到==类加载器==去解析的时候，就会根据符号引用找到**引用类的地址**，这个地址就是==直接引用==。

### 10、什么是反射及其优缺点

**概念** 反射是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为 Java 语言的反射机制。例如：==动态代理==，==注解==

**优点：** 能够运行时动态获取类的实例，提高灵活性；可与动态编译结合`Class.forName('com.mysql.jdbc.Driver.class')`，如：加载MySQL的驱动类。

**缺点：** 使用反射性能较低，需要解析字节码，将内存中的对象进行解析。其==解决方案==是：通过setAccessible(true)关闭JDK的安全检查来提升反射速度；多次创建一个类的实例时，有缓存会快很多；ReflectASM工具类，通过字节码生成的方式加快反射速度。

### 11、Error和Exception区别是什么

两者都继承**Throwable类**

- Exceptiton：程序本身可以处理的异常，可以被try-catch捕获
- Error：程序本身无法处理的异常，例如虚拟机错误（`Virtual MachineError`）、内存溢出(`OutOfMemoryError`)、类定义错误（`NoClassDefFoundError`）等等

### 12、throw和throws的区别

- throw 关键字用在==方法内部==，只能用于抛出一种异常，用来抛出方法或代码块中的异常，受查异常和非受查异常都可以被抛出。
- throws 关键字用在==方法声明上==，可以抛出多个异常，用来标识该方法可能抛出的异常列表。一个方法用 throws 标识了可能抛出的异常列表，调用该方法的方法中必须包含可处理异常的代码，否则也要在方法签名中用 throws 关键字声明相应的异常。

### 【补充】几个关键字final，static

- **final关键字** 用于声明不可改变的特性。`final` 用来修饰变量、方法、类和参数等，可以提高代码的可读性、稳定性和可维护性。

  - ==final变量== 的值一般大写，智能在声明时进行初始化，不允许修改；

  - ==final方法== 主要是在父类，防止被子类重写
  - ==final类== 表示该类不能被继承，主要用于具有特定实现或安全性需求的类
  - ==**final 参数**== 用于确保参数在方法内部不会被更改。

- **static 关键字**  用于声明静态成员（静态变量、静态方法、静态代码块）或静态内部类。被 **static** 修饰的成员存放在==方法区==，作用是创建独立于对象存在的变量或方法，当类被加载时，被 static 修饰的变量或方法就可以通过类名进行访问



## 集合

### 集合体系
主要是由两大接口派生而来：
一个是 ==Collection== 接口，主要用于存放单一元素。包含三个主要的子接口：`List`、`Set` 和 `Queue`；
另一个是 ==Map== 接口，主要用于存放键值对。

- List  存储的元素是有序的、可重复的。
	- `ArrayList`：`Object[]` 数组
	- `Vector`：`Object[]` 数组
	- `LinkedList`：双向链表(JDK1.6 之前为循环链表，JDK1.7 取消了循环)
- Set  存储的元素不可重复的。
	- `HashSet`(无序，唯一): 基于 `HashMap` 实现的，底层采用 `HashMap` 来保存元素
	- `LinkedHashSet`: `HashSet` 的子类，其内部是通过 `LinkedHashMap` 来实现的。
	- `TreeSet`(有序，唯一): 红黑树(自平衡的排序二叉树)
- Queue  按特定规则来确定先后顺序，存储的元素是有序的、可重复的。
	- `PriorityQueue`: 数组来实现最小堆（最大堆），最小元素在堆顶部。线程不安全，可用线程安全的 `PriorityBlockingQueue` 替代。
	- `ArrayDeque`: 允许在队列的两端（队头和队尾）进行高效的插入和删除操作。线程不安全，底层数据结构是一个可调整大小的数组。
	- `LikedList`: 内部是双向链表，线程不安全。

### 1、ArrayList 与 LinkedList 区别

- **是否线程安全：** 都不保证线程安全

- **底层结构：** ArrayList 实际是维护了一个数组，LinkedList 是维护一个双向链表

- **插入与删除：**
- ArrayList 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响；
  
- LinkedList 采用链表存储，插入删除元素时间复杂度==受元素位置==的影响，头尾插入近似 O(1)，中间插入需要遍历再插入 O(n)，而数组为近似 O(n)。
  
- 随机访问：ArrayList 支持快速随机访问，LinkedList 不支持（内存地址不连续，只能指针来定位）（实现 ==RandomAccess== 接口，数组使用索引遍历~~二分法~~更高效)

- 内存占用：ArrayList浪费空间体现在尾部会留有一些空余空间，而LinkedList体现在节点占用的内存会更高

### 2、ArrayList扩容机制

ArrayList扩容的本质就是计算出新的扩容数组的size后实例化，并将原有数组内容复制到新数组中去。 **默认情况下，新的容量会是原容量的1.5倍**

当使用无参构造创建ArrayList时，不会对数组赋值，只有当添加第一个元素，==初始容量10==，之后当元素添加导致数组容量不够时会按==1.5倍进行扩容==。

### 3、ArrayList 的 Fail-Fast 机制？

集合具有快速失败机制，即当一个线程读取集合时其他线程进行了修改，会触发快速失败机制，抛出对应的异常。

底层实现：集合内部维护了一个~~非 **volatile** 修饰~~变量 **modCount** 用于记录修改次数，在创建迭代器时会添加一个 expectedModCount 变量，当迭代时发现 expectedModCount 与 modCount 不相等了，则说明其他线程做了修改，抛出异常。

拓展： **安全失败（Fail-Safe）**

- 采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。
- 原理：由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发 ConcurrentModification Exception。

### 4、Comparable 和 Comparator 的区别

- Comparable 可以直接在需要进行排序的类中实现，即在需要比较的对象中 ==重写 compateTo(T o)== 方法，即 Arrays.sort(persons);
- Comparator 需要另外定义一个 ==实现 Comparator 接口== 的实现类来作为 **比较器** ，即 Arrays.sort(persons, new PersonComparator());

### 5、HashMap的底层数据结构是什么？

在JDK1.7 中，由“数组+链表”组成，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的。

在JDK1.8 中，由 **“数组+链表+红黑树”** 组成。当链表过长，则会严重影响 HashMap 的性能，红黑树搜索时间复杂度是 O(logn)，而链表是 O(n)。因此，JDK1.8 对数据结构做了进一步的优化，引入了红黑树，链表和红黑树在达到一定条件会进行转换：

- 将链表转换成红黑树前会判断：如果链表长度超过8，但是当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树，以减少搜索时间。
- 如果链表长度超过8，且当前数组的长度超过 64 才会转红黑树。

### 【补充】HashMap 的扩容方式

HashMap 在容量超过负载因子所定义的容量之后，就会扩容。Java 里的数组是无法自动扩容的，方法是将 HashMap 的大小扩大为原来数组的两倍，并将原来的对象放入新的数组中。

### 6、HashMap如何解决hash冲突？

解决Hash冲突方法:开放定址法、再哈希法、链地址法（拉链法）、建立公共溢出区。HashMap中采用的是 **链地址法 。**

 “拉链法”就是：将链表和数组相结合。~~也就是说创建一个链表数组，数组中每一格就是一个链表。 若遇到哈希冲突，则将冲突的值加到链表中即可。~~

如果不同的key 计算出相同的==哈希值==或者映射到相同的==存储索引== （计算过程：**通过 key 的值计算出 hashcode 的值，然后 hashcode 值经过==扰动函数==处理后计算出 hash 值，最后通过 hash &（n-1）取模计算得到存储的位置**），就会发生==哈希冲突==。解决过程：

- 如果冲突后是链表，判断该链表是否大于 8 ，如果大于 8 并且数组容量小于 64，就进行扩容；如果链表节点大于 8 并且数组的容量大于 64，则将这个结构转换为红黑树；
- 如果冲突后，发现该节点是红黑树，就将这个节点挂在树上；

tips：扰动函数指的就是 HashMap 的 `hash` 方法。使用扰动函数是为了防止一些实现性能差的 `hashCode()` 方法，减少hash冲突。==**n是数组的长度**==
```java
static final int hash(Object key) {  // key.hashCode()：返回散列值也就是hashcode
    int h; // >>>:无符号右移，忽略符号位，空位都以0补齐
	return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);  // ^：按位异或
}
```

### 【补充】HashMap 中红黑树会不会退化成链表？

会的。红黑树退化成链表的两种情况：

- 删除元素后，导致红黑树的 root 节点为空，或者 root 的右节点、root 的左节点、root 左节点的左节点为空时，链表退化

  ```java
  if (root == null || root.right == null || (rl = root.left) == null || rl.left == null) {
      tab[index] = first.untreeify(map);  // too small
      return;
  }
  ```

- 在扩容时 low、high 两个 TreeNode 长度小于等于 ==UNTREEIFY_THRESHOLD=6== 时 会退化为链表。

### 【补充】红黑树基本了解

**红黑树** 是一种自平衡的二叉搜索树。树的搜索、插入和删除操作的平均时间复杂度为 O(log n)，其中 n 是树中节点的数量。

红黑树通过一系列规则确保树的平衡性（通过==变色，左旋、右旋==保证规则不被打破）：

- 树的根节点必须是黑色的。

- 每个节点要么是红色，要么是黑色。

- 每个叶子节点都是黑色的空节点（NIL 节点）；

- 如果一个节点是红色的，那么其子节点必须是黑色的（不能有两个相邻的红色节点，反之不一定）。

- 从任何节点到其每个叶子节点的路径都包含相同数量的黑色节点。（即相同的黑色高度）

**为什么要使用红黑树：** 为了解决二叉查找树的缺陷，因为二叉查找树（==节点左子树小于该值，右子树大于该值==）在某些情况下会退化成一个线性结构。

**红黑树的应用：** TreeMap、TreeSet 以及 JDK1.8 的 HashMap 底层都用到了红黑树。

### 【补充】一般用什么作为HashMap的key

一般用 Integer、String 这种不可变类作为 HashMap 的 key，而且 String 最为常用。

- 因为字符串是不可变的，所以在它创建的时候 hashcode 就被缓存了，不需要重新计算。这就是 HashMap 中的键往往都使用字符串的原因。
- 因为获取对象的时候要用到 equals() 和 hashCode() 方法，这些类已经很规范的重写了 hashCode() 以及 equals() 方法。

**拓展：HashMap 如何将对象作为 key**

如果要使用自定义的对象作为 HashMap 的 key，需要重写该对象的 ==equals()== 和 ==hashCode()== 方法

- **hashCode()：**  需要重写 hashCode 方法，因为默认调用 Object 类的 hashCode 方法，而 Object 类的 hashCode 方法返回的 hash 值是对象的内存地址，不同的对象内存地址是不一样的。
- **equals()：** HashMap 是用**链地址法**来处理冲突的，当计算出的 hash 值相同的时候，就会默认调用Object类的equals()方法，它默认是根据两个对象的内存地址判断是否相等的。因此还需要重写equals()方法。

### 7、HashMap默认加载因子是多少？

默认的loadFactor是0.75，0.75是对空间和时间效率的一个平衡选择，一般不要修改，除非在时间和空间比较特殊的情况下 ：

- 如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值 。
- 相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1。

### 8、HashMap中put的执行过程

简要流程如下：

1. 首先根据 key 的值计算 hash 值，找到该元素在数组中存储的下标；
2. 如果数组是空的，则调用 resize 进行初始化；
3. 如果没有哈希冲突直接放在对应的数组下标里；
4. 如果冲突了，且 key 已经存在，就覆盖掉 value；
5. 如果冲突后，发现该节点是红黑树，就将这个节点挂在树上；
6. 如果冲突后是链表，判断该链表是否大于 8 ，如果大于 8 并且数组容量小于 64，就进行扩容；如果链表节点大于 8 并且数组的容量大于 64，则将这个结构转换为红黑树；否则，链表插入键值对，若 key 存在，就覆盖掉 value。

### 9、HashMap为什么线程不安全？

- **多线程下扩容死循环：** JDK1.7中的 HashMap 使用==头插法==插入元素，在多线程的环境下，扩容的时候有可能导致环形链表的出现，形成死循环。因此，JDK1.8使用==尾插法==插入元素，在扩容时会保持链表元素原本的顺序，不会出现环形链表的问题。
- **多线程的put可能导致元素的丢失。** 多线程同时执行 put 操作，如果计算出来的索引位置是相同的，那会造成前一个 key 被后一个 key 覆盖，从而导致元素的丢失。在JDK 1.7和 JDK 1.8 中都存在。
- **put和get并发时，可能导致get为null。** 线程1执行put时，因为元素个数超出 threshold 而导致 rehash，线程2此时执行get，有可能导致这个问题。在JDK 1.7和 JDK 1.8 中都存在。

###  10、ConcurrentHashMap

线程安全的HashMap，适用于并发场景

**JDK1.7 ：** 将哈希桶分割成多段（大数组分成小数组），用分段锁保证并发场景的线程安全，不同段不会互相影响，增加了并发量。最多 16 段。

**JDK1.8 以后：**在数据结构上， JDK1.8 中的 ConcurrentHashMap 选择了与 HashMap 相同的**数组+链表+红黑树**结构；

​					在锁的实现上，抛弃了原有的 ==Segment 分段锁（继承 ReentrantLock）==，采用 ==CAS + synchronized== 实现更加低粒度的锁。

==将锁的级别控制在了更细粒度的哈希桶元素（即数组每个节点）级别==，即只需锁住该链表头结点（红黑树的根节点），就不会影响其他的哈希桶元素读写，大大提高了并发度。

### 11、什么是WeakHashMap

使用弱引用来管理元素，在垃圾回收时弱引用不会被看作有效引用，因此其中的元素可能会在垃圾回收时被清除，适用于缓存场景。

### 12、HashMap和HashTable的区别

- HashMap 线程不安全，HashTable 线程安全
- HashMap 效率高一些
- HashMap 可以存 null 值，HashTable 不允许 null 值
- HashMap 初始大小16，之后按 2n 扩容；HashTable 初始大小 11，之后按 2n+1 扩容
- HashMap 创建时指定大小会自动扩到 2 的幂次方，HashTable 没有这个机制
- HashMap 有树化机制，HashTable 没有

### 13、Queue和Dqueue的区别

单端队列—双端队列

- `Queue` 是一种基本的队列数据结构，仅支持在队尾添加元素和在队头移除元素。`Deque` 支持在队头和队尾添加和移除元素，具有更大的灵活性。
- `Deque` 可以用于实现队列、栈以及其他需要双向操作的数据结构，实现通常有 `ArrayDeque` 和 `LinkedList`。而 `Queue` 主要用于实现队列。

### 14、什么是 BlockingQueue

阻塞队列 `BlockingQueue` 是一个接口，它可以在队列为空时阻塞尝试获取元素的操作，或者在队列已满时阻塞尝试添加元素的操作。常用于生产者-消费者模型。

- **底层数据结构：** 不同的实现会使用不同的底层数据结构，如数组或链表。例如，`ArrayBlockingQueue` 使用数组，而 `LinkedBlockingQueue` 使用链表（==无容量限制==）。
  
-  **线程安全性：** 通常会使用锁（例如，内部的 `ReentrantLock`）或其他同步机制来确保线程安全。这允许多个线程同时进行入队和出队操作，而不会导致数据不一致或竞态条件。
   
- **阻塞机制：** 当队列为空时，尝试从中获取元素的线程将被阻塞，直到队列中有元素可用。当队列已满时，尝试将元素放入队列的线程也会被阻塞，直到有空间可用。
  
- **等待和通知：** 通常会使用等待和通知机制来实现阻塞操作。当一个线程尝试执行一个阻塞操作时，它会进入等待状态，直到满足某个条件，例如队列非空或队列有空闲空间。其他线程在执行入队或出队操作时，会触发通知，通知等待中的线程继续执行。


## JUC

### 1、进程、线程和协程

- **进程：** 操作系统进行资源分配和调度的基本单位，它拥有独立的地址空间和系统资源。
- **线程：** CPU 调度的基本单位，它被包含在进程之中，是进程中的实际运作单位。一个进程内可以包含多个线程，同一进程中的多个线程共享该进程中的全部系统资源，如虚拟地址空间，文件描述符和信号处理等等。
- **协程（适合IO密集）：** 用户态的轻量级线程，不受内核调度。它是一种异步机制，可以在单线程中实现并发执行；

### 2、创建线程的三种方式对比

- 采用实现 ==Runnable== 或 ==Callable== 接口的方式创建多线程：
  - **优势是：** 线程类只是实现了 Runnable 接口或 Callable 接口，还可以继承其他类。
  - **劣势是：** 编程稍微复杂，如果要访问当前线程，则必须使用 Thread.currentThread() 方法。
  - **区别：** Runnable 的 run 方法只能抛出运行时异常，且无法捕获处理；Callable 中 call 方法允许抛出异常，可以获取异常信息。

- 使用继承Thread类的方式创建多线程：
  - **优势：** 编写简单，如果需要访问当前线程，则无需使用 Thread.currentThread() 方法，直接使用 this 即可获得当前线程。
  - **劣势**： 线程类已经继承了 Thread 类，所以不能再继承其他父类
- 线程池 [[人生启示录#JUC#【补充】如何创建线程池]]

> 注：Callalbe 接口需要调用 futureTask.get() 得到返回结果，此方法会==阻塞==主进程继续往下执行，如果不调用不会阻塞。

### 3、如何实现线程安全

- 互斥同步：synchronized 和 ReentrantLock
- 非阻塞同步：CAS，原子操作类
- 无同步：栈封闭，例如方法中的局部变量；线程本地存储，将数据的可见范围限制在一个线程内部，例如 ThreadLocal

### 18、ThreadLocal 是什么？

ThreadLocal，即本地线程变量。如果创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的一个本地副本

（每个线程内部维护了一个 ==ThreadLocalMap==，ThreadLocal 作为 ==key== 是弱引用，==value== 则是实际存储的值，是强引用），

多个线程操作这个变量的时候，实际是操作自己本地内存里面的副本变量，从而起到线程隔离的作用，避免了线程安全问题。

- **ThreadLocal 的应用场景** 线程间数据隔离，数据库连接， ==Session 会话管理==

- **使用的时候要避免内存泄露： ** `ThreadLocal` 是一个==弱引用==，当为 `null` 时，会被当成垃圾回收 。但此时 ThreadLocalMap 生命周期和 Thread 的一样，它不会回收，这时候就出现了一个现象：ThreadLocalMap 的 key 没了，但是 value 还在，这就造成了内存泄漏。

- **解决办法：**使用完 `ThreadLocal` 后，执行 `remove` 操作，避免出现内存泄漏情况。

### 补充：Java 线程和操作系统的线程有什么区别
JDK1.2 之后 Java 线程改为基于原生线程（Native Threads）实现，即 JVM 直接使用操作系统原生的内核级线程（内核线程）来实现 Java 线程，由操作系统内核进行线程的调度和管理。

> 用户线程：由用户空间程序管理和调度的线程，运行在用户空间（专门给应用程序使用）。
> 内核线程：由操作系统内核管理和调度的线程，运行在内核空间（只有内核程序可以访问）。
> zongjei: 用户线程创建和切换成本低，但不可以利用多核。内核态线程，创建和切换成本高，可以利用多核。

JDK21 提供轻量级的==虚拟线程==，在不需要对原有代码做大的修改下提高系统的并发能力。

### 4、Java 线程的生命周期和状态
Java 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态：

- **NEW ==初始状态==：** 线程被创建出来但没有被调用 `start()` 。

- **RUNNABLE 运行状态：** 线程被调用了 `start()` 等待运行的状态。~~在操作系统层面，线程有 READY 和 RUNNING 状态；而在 JVM 层面，只能看到 RUNNABLE 状态~~
- **BLOCKED ==阻塞状态==：** 当线程进入 `synchronized` 方法/块或调用 `wait` 后（被 `notify`）重新进入 `synchronized` 方法/块，但是锁被其它线程占有，这个时候线程就会进入阻塞状态。
- **WAITING ==等待状态==：** 当线程执行  `wait()` 方法或其他线程 `join()` 之后，线程进入等待状态。进入等待状态的线程需要依靠其他线程的通知 notify()/notifyAll() 或 join 的线程执行完毕才能够返回到运行状态（需抢占到资源）。
- **TIME_WAITING ==超时等待状态==：** 可以在指定的时间后自行返回而不是像 WAITING 那样一直等待。相当于在等待状态的基础上增加了超时限制，比如通过 `sleep（long millis）` 方法或 `wait（long millis）` 方法可以将线程置于超时等待状态。当超时时间结束后，线程将会返回到 RUNNABLE 状态。
- **TERMINATED ==终止状态==：** 线程在执行完了 `run()` 方法之后将会进入到终止状态。

<img src="https://java-1259004241.cos.ap-shanghai.myqcloud.com/typora/202310191556830.png" alt="Java 线程状态变迁图" style="zoom: 67%;" />


### 5、为什么不能直接调用run()方法？

new 一个 Thread 对象，线程进入了==新建状态==：

- 调用 start() 会启动一个线程并执行相应准备工作，然后自动执行 run() 方法，当分配到时间片后就开始运行。这是真正的多线程工作。
- 直接执行 run() 方法，会把 run() 方法当成主线程下的普通方法去执行，并不会在某个线程中执行它，这并不是多线程工作。 

**调用 start() 方法方可启动线程并进入就绪状态，而 run() 方法只是 thread 类的一个普通方法调用，还是在主线程执行。**

### 6、中断线程的几种方式

- 调用 interrupt() 方法，可以中断处于阻塞、无限等待、期限等待状态中的线程，抛出异常从而中断线程；
- 调用 interruptd() 方法可以判断线程是否被中断，从而进行中断逻辑处理；
- 调用线程池的 shutdown() 方法，等待所有线程执行完后关闭线程池；调用 shutdownNow() 方法，相当于调用所有线程的 interrupt 方法。

### 7、什么是线程死锁？如何避免？

**死锁：** 多个线程同时被阻塞，他们中的一个或全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。

**造成死锁必须具备以下四个条件：** 

- **互斥条件：** 该资源任意一个时刻只由一个线程占用。
- **请求与保持条件:** 一个线程因请求资源而阻塞时，对已获得的资源保持不放。
- **不可剥夺条件:** 线程已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
- **循环等待条件:** 若干线程之间形成一种头尾相接的循环等待资源关系。

**如何避免死锁**

只要破坏产生死锁的四个条件中的其中一个就可以了

- **破坏请求与保持条件：**一次性申请所有的资源。
- **破坏不可剥夺条件：**占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放已占有的资源。
- **破坏循环等待条件：**按某一顺序申请资源，释放资源则反序释放。
- **==锁排序法==:**  **`（必须回答出来的点）`** 通过指定锁的获取顺序，比如规定，只有获得A锁的线程才有资格获取B锁，~~同时获得A锁和B锁，~~才能对某资源进行操作。按顺序获取锁就可以避免死锁。这通常被认为是解决死锁很好的一种方法。
- 使用显式锁中的 ReentrantLock.try(long,TimeUnit) 来申请锁

### 8、公平锁和非公平锁的区别

- 公平锁：获取锁时按照申请顺序来，先申请的先获得锁，性能较差
- 非公平锁：获取锁时随机或者按优先级来，性能较好，但有可能出现有的线程永远拿不到锁的情况

### 9、什么是可重入锁

也称递归锁，指的是在一个线程中可以多次获取同一把锁。比如 ==synchronized 和 ReentrantLock==

比如： 一个线程在执行一个带锁的方法，该方法中又调用了另一个需要相同锁的方法，则该线程可以直接执行调用的方法，而无需重新获得锁， 两者都是同一个线程，每进入一次，锁的计数器都自增 1，所以要等到锁的计数器下降为 0 时才能释放锁。

### 10、乐观锁和悲观锁

- 悲观锁：认为访问资源时总是会有其他线程进行修改，会将资源进行加锁，适用于==写操作较多==的场景，例如 synchronized
- 乐观锁：认为访问资源时不会出现问题，在执行结束前进行验证，如果验证通过则修改成功否则失败重试，适用于==写操作较少==的场景，例如 CAS

==乐观锁的实现：==

- 版本号：在修改时会比对版本号是否一致，不一致则失败
- CAS：比较与交换，判断内存某个位置的值是否为预期值，如果是则更改为新的值，否则不进行任何操作。这个过程是原子的。

### 11、CAS 及存在的问题

CAS 即比较并替换（Compare And Swap)，是实现并发算法时常用到的一种技术。

CAS 操作包含三个操作数——内存位置的值、预期原值及新值。执行 CAS 操作的时候，将内存位置的值与预期原值比较，如果相匹配，那么 CPU 会自动将该位置值更新为新值，否则，处理器不做任何操作。

==CAS存在的问题==

- **ABA 问题：**并发环境下，假设初始条件是 A，去修改数据时，发现是 A 就会执行修改。但是看到的虽然是A，中间可能发生了 A 变 B，B 又变回 A 的情况。此时 A 已经非彼 A，数据即使成功修改，也可能有问题
  - 可以通过 AtomicStampedReference **解决 ABA 问题**，这是一个带有标记的原子引用类，通过控制变量值的版本来保证 CAS 的正确性。
- **失败重试开销大：**CAS 经常会用到自旋操作来进行重试，也就是不成功就一直循环执行直到成功。如果长时间不成功，会给 CPU 带来非常大的执行开销。

- **只能保证一个共享变量的原子操作：**CAS 保证的是对一个变量执行操作的原子性，如果对多个变量操作时，CAS 目前无法直接保证操作的原子性的
  - 可以通过使用互斥锁来保证原子性 
  - **或**将多个变量封装成对象，通过 AtomicReference 来保证原子性

### 12、volatile关键字

- 可见性：将变量声明为 volatile，在 java 中表示这个变量是共享且不稳定的（**可理解为多线程环境下使用 volatile 修饰的变量的值一定是最新的**）
- 禁止指令重排：volatile 可以禁止 JVM 指令重排，<u>在读写变量时会插入特定的内存屏障来实现</u>（**volatile 的原理**）
- 仅保证单次读写操作的原子性

**注： ** 指令重排是 CPU 和编译器为了提升程序执行的效率，会按照一定的规则允许进行指令优化，在某些情况下，这种优化会带来一些执行的逻辑问题，主要的原因是代码逻辑之间是存在一定的先后顺序，在并发执行情况下，会发生==二义性==，即按照不同的执行逻辑，会得到不同的结果信息。

###  13、synchronized关键字

同步锁，被它修饰的方法和代码块在同一时刻只能有一个线程执行

- 修饰实例方法：给当前对象实例加锁，进入同步代码前要获得 **当前对象实例的锁** 。
- 修饰静态方法：给当前类加锁，会作用于类的所有对象实例 ，进入同步代码前要获得 **当前 class 的锁**
- 修饰代码块：对括号里指定的对象/类加锁

构造方法无法被修饰，因为构造方法本身就是线程安全的

==synchronized 底层原理==

每个对象都会关联一个 monitor 监视器对象，monitor 监视器对象在同一时间只能被一个线程所获取，内部有一个计数器，当计数器为 0 时表示锁可以被获取；线程获取锁或者重入锁时都会使计数器+1，释放锁时就减 1，当减到 0 就表示这个锁被释放了可以被其他线程获取

### 14、synchronized性能较差有什么优化方法

由于 monitor 对象实现依赖于操作系统的互斥量，每次竞争锁都要切换到内核态，开销较大。在 jdk1.6 引入了许多针对 synchronized 的优化：

- **偏向锁：** 适用于单线程即没有锁竞争的场景，减少不必要的 CAS 操作
- **轻量级锁：** 轻量级锁是由==偏向锁==升级而来，当存在第二个线程申请同一个锁对象时，偏向锁就会立即升级为==轻量级锁==。注意这里的第二个线程只是申请锁，不存在两个线程同时竞争锁，可以是一前一后地交替执行同步块。
- **适应性自旋锁：** 当 CAS 获取轻量级锁失败时，会进行一定的自旋重试，到达一定失败次数后才升级为==重量级锁==
- **锁消除：** 在 JIT 编译时，对运行上下文进行扫描，去除不可能存在竞争的锁。
- **锁粗化：** 通过扩大锁的范围，避免反复加锁和释放锁

==自旋锁：== 如果持有锁的线程能在短时间内释放锁资源，那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞状态，它们只需要 **等待一段时间后再次尝试获取** (自旋)，当持有锁的线程释放锁之后即可获取，这样就避免了用户进程和内核切换的消耗。

### 15、synchronized 和 volatile 有什么区别？

- `volatile` 解决的是内存可见性问题，会使得所有对 `volatile` 变量的读写都直接写入主存，即 **保证了变量的可见性**。
- `synchronized` 解决的是执行控制的问题，它会阻止其他线程获取当前对象的监控锁，这样一来就让当前对象中被 `synchronized` 关键字保护的代码块无法被其他线程访问，也就是无法并发执行。

**两者的区别主要有如下：**

1. volatile 本质是在告诉 JVM 当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取； synchronized 则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。
2. volatile **仅能使用在变量级别**；synchronized 则可以使用在 **变量，方法和类级别** 。
3. volatile 仅能实现变量的修改可见性，**不能保证原子性**；而synchronized 则可以 **保证变量的修改可见性和原子性** 。
4. volatile **不会造成线程的阻塞**；synchronized **可能会造成线程的阻塞** 。
5. volatile 标记的变量不会被编译器优化；synchronized 标记的变量可以被编译器优化。

### 16、synchronized和Lock有什么区别？

- synchronized 可以给类，方法和代码块加锁；而 lock 只能给代码块加锁。
- synchronized 不需要手动获取锁和释放锁，使用简单，发生异常会自动释放锁，不会造成死锁； lock 需要自己加锁和释放锁，如果使用不当没有 unLock()  去释放锁就会造成死锁。
- 通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。
**补充：** Lock 是一个接口实现，底层是CAS乐观锁，依赖AbstractQueuedSynchronizer类，把所有的请求线程构成一个CLH队列。而对该队列的操作均通过Lock-Free（CAS）操作。

###  17、synchronized 和 ReentrantLock 有什么区别

-  两者都是可重入锁
-  synchronized 依赖于 JVM，许多优化都是在 JVM 层面进行的；ReentrantLock 实现于 API 层面

-  ReentrantLock具有许多高级功能：
   - 等待可中断：提供一个方法，可以在等待获取锁时中断等待，去做别的事情
   - 可实现公平锁：默认非公平锁，可以支持非公平锁
   - 可以绑定多个通知条件（Condition）

-  **使用选择**
   - 除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。
   - synchronized 是 JVM 实现的一种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放

### 19、为什么要使用线程池

线程池提供了一种限制和管理资源（包括执行一个任务）的方法。 每个线程池还维护一些基本统计信息，例如已完成任务的数量。

使用线程池的好处：

- **降低资源消耗。** 通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- **提高响应速度。** 当任务到达时，任务可以不需要等待线程创建就能立即执行。
- **提高线程的可管理性。** 线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

==线程池核心参数==

- **corePoolSize**： 核心线程大小。线程池一直运行，核心线程就不会停止。
- **maximumPoolSize**：任务队列中存放的任务达到队列容量的时候，当前可运行的线程数量变为最大线程数。
- **workQueue**：阻塞队列。新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。
- keepAliveTime ：非核心线程的心跳时间。如果非核心线程在keepAliveTime内没有运行任务，非核心线程会消亡。
- RejectedExecutionHandler ：==默认饱和策略==。如果当前同时**运行的线程数量达到最大线程数量并且队列也已经被放满**了任务时，`ThreadPoolTaskExecutor` 定义一些策略:
  - AbortPolicy ： 将新的任务丢弃并报错。默认饱和策略。
  - DiscardPolicy ： 将新的任务直接丢弃不报错。
  - DiscardOldestPolicy ： 将workQueue**队首任务丢弃**，将最新线程任务重新加入队列执行。
  - CallerRunsPolicy ：调度任务的线程自己调用run方法执行。该策略保证任务不会被丢弃，但是可能会导致任务执行的时间变长
- ThreadFactory ：线程工厂。新建线程工厂。

==**线程池执行流程：**==

1）如果workerNum < 核心线程数 ，则核心线程执行提交的任务 
2）如果workerNum >= 核心线程数 && 阻塞队列未满，则添加至阻塞队列，等待后续线程来执行提交地任务
3）如果workerNum >= 核心线程数 && 阻塞队列已满 && workerNum < 最大线程数，则创建非核心线程执行提交的任务
4）如果workerNum >= && 阻塞队列已满 最大线程数，则执行饱和策略

==**线程池是非公平的**==
排队任务调度策略：当等待队列已满，再提交的任务，会创建非核心线程去执行新提交的任务，那么就产生一种结果，在等待队列中的任务是先提
交的任务，反而没有在此时提交的任务先执行。**任务的执行顺序和任务的提交顺序不一致，如果业务需求的任务是有先后依赖关系的，就会降低线程的调度效率**

### 【补充】如何创建线程池

在JAVA中主要是使用 ==ThreadPoolExecutor类== 来创建线程池，并且 JDK 中也提供了 ==Executors== 工厂类来创建线程池（不推荐使用）

- ==**Executors 类，**== 虽然便捷但有OOM的风险（使用==无界队列==，最大Integer.MAX_VALUE，导致创建非常多的线程）
  - newFixedThreadPool(int num)	创建固定大小的线程池
  - newSingleThreadExecutor() 创建只有一个线程的线程池
  - newCachedThreadPool() 创建一个不限线程数上限的线程池，任何提交的任务都将立即执行
- ==**ThreadPoolExecutor 类**==  需要设置主要的线程池参数，但线程池配置可控

### 20、线程池执行任务的流程

1. 线程池执行 execute/submit 方法向线程池添加任务，当任务小于核心线程数 corePoolSize，线程池中可以创建新的线程。
2. 当任务大于核心线程数 corePoolSize，就向阻塞队列添加任务。
3. 如果阻塞队列已满，需要通过比较参数 maximumPoolSize，在线程池创建新的线程，当线程数量大于maximumPoolSize，说明当前设置线程池中线程已经处理不了了，就会执行饱和策略。

### 21、execute()方法和submit()方法的区别

- **`execute()` 方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否；**

- **`submit()`**方法用于提交需要返回值（线程任务需要实现==Callable接口==）的任务。线程池会返回一个 ==future== 类型的对象，通过 future 对象可以判断任务是否执行成功，并且可以通过 future 的 get() 方法来获取返回值，get() 方法会==阻塞==当前线程直到任务完成，而使用 `get（long timeout，TimeUnit unit）`方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。

## JVM

### 1、JVM内存结构

- **程序计数器** 线程私有的，一块很小的内存空间，作为当前线程执行字节码的行号指示器。字节码解释器通过改变程序计数器依次读取下一条要执行的指令，从而实现代码的流程控制，并且在CPU 切换线程时 **记录当前线程的执行位置。**
  它的生命周期随着线程的创建而创建，随着线程的死亡而结束。

- **虚拟机栈** 线程私有的，每一次方法调用都会有一个对应的栈帧被压入栈中（ ==栈由一个个栈帧组成== ），每一个方法调用结束后，都会有一个栈帧被弹出。栈帧中包含以下内容：

  - 局部变量表： 存放编译期可知的各种数据类型（boolean、byte、char、short、int、float、long、double）和对象引用（reference 类型）；
  - 操作数栈**：** 用于存放方法执行过程产生的中间计算结果以及临时变量；
  - 动态链接： 用于将符号引用转换为方法的直接引用；
  - 方法返回地址： 方法退出或异常退出的地址

  栈中可能发生的异常：
  - **StackOverFlowError：** 当栈的内存大小不支持动态扩展时，在当线程请求栈的深度达到最大值就发生栈溢出异常。
  - **OutOfMemoryError**： 当栈的内存大小可以动态扩展时， 如果虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出该异常。

  ==区别：== 两个都是由于内存不足导致的。OOM是因为栈的大小不足，想要继续扩展的时候，但是由于JAVA虚拟机的可用内存不足导致的。SOF是因为方法执行的时候，创建新的栈帧，但是虚拟机栈的内存不足以放下新的栈帧导致的。

- **本地方法栈** 线程私有的，保存的是native方法的信息。与虚拟机栈功能类似，区别是虚拟机栈为虚拟机==执行 Java 方法== （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 ==Native 方法==服务（Native 方法是其他语言 **如C、C++** 编写的方法）。

- **堆** 所有线程共享的一块内存，几乎所有==对象的实例==和==数组==都要在堆上分配内存，因此该区域经常发生==垃圾回收==的操作；（新生代[新,小对象]、老生代[大对象]、永久代）

- **方法区** 线程共享，存储已被虚拟机加载的 **类信息、字段信息、方法信息、常量、静态变量、即时编译器编译后的代码缓存等数据。** 即实现为永久代。

  在jdk1.8中方法区被元空间取代，元空间使用本地内存来存储类的元数据信息，具有更高的灵活性和可扩展性，可以避免方法区中常常出现的内存溢出等问题

### 2、JVM中的常量池

JVM常量池主要分为Class文件常量池、运行时常量池，全局字符串常量池，以及基本类型包装类对象常量池。

- **Class文件常量池：** class文件是一组以字节为单位的二进制数据流，在java代码的编译期间，我们编写的java文件就被编译为.class文件格式的二进制数据存放在磁盘中，其中就包括class文件常量池。

- **运行时常量池**： 运行时常量池相对于class常量池一大特征就是具有动态性，java规范并不要求常量只能在运行时才产生，也就是说运行时常量池的内容并不全部来自class常量池，在运行时可以通过代码生成常量并将其放入运行时常量池中，这种特性被用的最多的就是 String.intern()。

- **字符串常量池**： 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。

  在HotSpot 虚拟机中，它是一个叫做StringTable的全局表（底层C++实现就是一个Hashtable），保存的是==字符串（key）和 字符串对象的引用（value）的映射关系==，字符串对象的引用指向堆中的字符串对象。

- **基本类型包装类对象常量池：** java中基本类型的包装类的大部分都实现了常量池技术（==对象缓存==），这些类是Byte,Short,Integer,Long,Character,Boolean,另外两种浮点数类型的包装类则没有实现。另外上面这5种整型的包装类也只是在对应值小于等于127时才可使用对象池，也即对象不负责创建和管理大于127的这些类的对象。

### 3、堆和栈的区别（内存泄漏）

堆（Heap）是用于动态分配内存的区域，而栈（Stack）是用于存储局部变量和函数调用信息的区域。

**堆（Heap）：** 堆是计算机内存中的一块较大的区域，用于存储动态分配的内存。堆中的数据可以在程序的任何地方被访问，而且在程序执行期间保持有效。在堆中，内存的分配和释放是==由程序员手动控制==，且堆的大小可以调整，但是如果没有正确释放内存，可能会导致==内存泄漏==。

**栈（Stack）：** 栈是计算机内存中的一块较小的区域，==由系统自动分配==，用于存储函数调用时的局部变量和函数调用信息。栈采用先进后出（LIFO）的原则，当一个函数被调用时，其局部变量和函数调用信息被压入栈中，当函数执行完毕后，这些数据会被自动释放。

### 4、强、软、弱、虚引用的区别

- 强引用（Strong Reference），就是普通的对象引用关系，收集器不会将其回收，内存不足时报错。

  ```java
  String strongRef = new String("StrongReference")
  ```

- 软引用（SoftReference），用于维护一些可有可无的对象。只有在内存不足时，系统则会回收软引用对象，如果回收了软引用对象之后仍然没有足够的内存，才会抛出内存溢出异常。

  ```java
  SoftReference<Object> softRef = new SoftReference<>(new Object());
  ```

- 弱引用（WeakReference），相比软引用来说，要更加无用一些，它拥有更短的生命周期，当 JVM 进行垃圾回收时，无论内存是否充足，都会回收被弱引用关联的对象。

  ```java
  WeakReference<Object> weakRef = new WeakReference<>(new Object());
  ```

- 虚引用（PhantomReference）是一种形同虚设的引用，在现实场景中用的不是很多，它主要用来跟踪对象被垃圾回收的活动。

> **被引用的对象一定能存活吗？**
>
> 不一定，看 Reference **引用**类型，弱引用在 GC 时会被回收，软引用在内存不足的时候，即 OOM 前会被回收，但如果没有在 Reference Chain 中的对象就一定会被回收。

### 5、JVM 内存模型

**Java 内存模型**（ **JMM**）就是在底层处理器内存模型的基础上，定义的多线程语义。它明确指定了一组排序规则（==Happens-Before==），来保证线程间的可见性。

（单线程、监视器锁定、volatile变量、线程start、线程join、传递性等规则）

Java 内存模型描述的是 **多线程对共享内存修改后彼此之间的可见性** ，另外，还确保正确同步的 Java 代码可以在不同体系结构的处理器上正确运行。

### 6、对象的创建过程

**1、类加载检查** 首先检查 new 对象的参数是否能在常量池中定位到这个类的符号引用，并且检查该引用代码的类是否被加载，如果没有则执行类的加载过程。

**2、分配内存** 虚拟机为新的对象==分配内存==，分配方式有 **指针碰撞和空闲列表** 两种，使用哪种方式取决于当前==堆内存是否规整== （取决于 GC 收集器的算法是"标记-清除"，还是"标记-整理"）。
> 虚拟机采用两种方式来保证线程安全：
> - **CAS+失败重试：** CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。**虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。**
> - **TLAB：** 为每一个线程预先在 Eden 区分配一块内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配。

**3、初始化内存地址** 内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（ **不包括对象头** ），这一步操作保证了对象的实例字段不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。

**4、执行init() 方法** 执行 new 指令之后会接着执行 `<init>` 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。

**注意：** 对象头包括两部分信息1）自身运行时数据：对象的 hash 值，对象的 GC 生代年龄信息；2）类型指针：指向类元数据的指针。

### 7、什么是Java类加载，过程如何

Java类加载的主要是 虚拟机把描述类的数据加载到内存里面，并对数据进行校验、解析和初始化，最终变成可以被虚拟机直接使用的class对象；

~~类的整个生命周期包括~~：==加载==（Loading）、==验证==（Verification）、==准备==(Preparation)、==解析==(Resolution)、==初始化==(Initialization)、使用(Using)和卸载(Unloading)7个阶段。其中准备、验证、解析3个部分统称为连接（Linking）。

**类加载过程如下：**

- 加载：加载分为三步： 1、通过类的~~全限定性~~类名获取该类的二进制流； 2、将该二进制流的静态存储结构转为方法区的运行时数据结构； 3、在堆中为该类生成一个class对象；
- 验证：验证该class文件中的字节流信息符合虚拟机的要求，不会威胁到 JVM 的安全；
- 准备：为 class 对象的静态变量分配内存，初始化其初始值；
- 解析：该阶段主要完成符号引用转化成直接引用；（**顺序可能变化**，在某些情况下可以在初始化阶段之后再开始，这是为了支持Java语言的==运行时绑定==）
- 初始化：到了初始化阶段，才开始执行类中定义的java代码；初始化阶段是调用类构造器的过程；

### 8、什么是类加载器，常见的有哪些

类加载器是指：通过一个类的全限定性类名获取该类的二进制字节流叫做类加载器；类加载器分为以下四种：

- 启动类加载器（BootStrapClassLoader）：用来加载java核心类库，无法被java程序直接引用；
- 扩展类加载器（Extension ClassLoader）：用来加载java的扩展库，java的虚拟机实现会提供一个扩展库目录，该类加载器在扩展库目录里面查找并加载java类；
- 系统类加载器（AppClassLoader）：它根据java的类路径来加载类，一般来说，java应用的类都是通过它来加载的；
- 自定义类加载器：由java语言实现，继承自ClassLoader；

### 9、什么是双亲委派模型？有什么作用

当一个类加载器收到一个类加载的请求，它首先不会尝试自己去加载，而是将这个请求委派给父类加载器去加载，只有父类加载器在自己的搜索范围类查找不到给类时，子加载器才会尝试自己去加载该类；

为了防止内存中出现多个相同的字节码；因为如果没有双亲委派的话，用户就可以自己定义一个java.lang.String类，那么就无法保证类的唯一性。

补充：**那怎么打破双亲委派模型**？

自定义类加载器，继承ClassLoader类，重写loadClass方法和findClass方法。**例如Tomcat中**，类加载器优先自行加载应用目录下的 class，只有当加载不了才委派给父加载器。主要是为了==各个web文件的相互隔离==和==热部署==

### 【补充】JVM 垃圾回收机制
在JVM中，有一个垃圾回收线程，它是低优先级的，在正常情况下是不会执行的，只有在虚拟机==空闲==或者当前==堆内存不足==时，才会触发执行，扫描那些没有被任何引用的对象，并将它们添加到要回收的集合中，进行回收。

### 10、Java 中的垃圾回收算法有哪些

java中有四种垃圾回收算法，分别是标记清除法、标记整理法、复制算法、分代收集算法；

> **标记清除法：** 
>
> - 第一步，利用可达性==（一个对象是否可以通过引用链路（如变量、字段、数组元素等）被访问到）==去遍历内存，把存活对象和垃圾对象进行标记；
> - 第二步，再遍历一遍，将所有标记的垃圾对象回收掉； 
>
> - **特点：** 效率不行，标记和清除的效率都不高；标记和清除后会产生大量的不连续的空间分片，可能会导致之后程序运行的时候需分配大的对象而找不到连续分片，然后再次触发一次GC；

> **标记整理法**：
>
> - 第一步，利用可达性去遍历内存，把存活对象和垃圾对象进行标记； 
> - 第二步：将所有的存活的对象向一端移动，将端边界以外的对象都回收掉；
> -  **特点：** 适用于存活对象多，垃圾少的情况；需要整理的过程，好处是不会产生空间碎片；

> **复制算法**： 
>
> - 将内存按照容量大小分为大小相等的两块，每次只使用一块，当一块使用完了，就将存活的对象移到另一块上，然后再把使用过的内存空间移除； 
> - **特点：** 不会产生空间碎片；内存使用率极低；

> **分代收集算法：**
>
> - 根据内存对象的存活周期不同，将内存划分成几块，java虚拟机一般将内存分成新生代和老年代：
>
>   在==新生代中==，有大量对象死去和少量对象存活，所以采用复制算法，只需要付出少量存活对象的复制成本就可以完成收集；
>
>   ==老年代==中因为对象的存活率极高，没有额外的空间对他进行分配担保，所以采用标记清理或者标记整理算法进行回收；

### 11、有哪些常见的垃圾回收器

垃圾回收器主要有以下几种：Serial、ParNew、Parallel Scavenge、Parallel Old、==CMS==、==G1==，ZGC；

- Serial: 基于复制算法，单线程的收集器，收集垃圾时需要对所有正在执行的线程暂停（面向==客户端的默认GC方式==）。
- ParNew: Serial收集器的多线程版本，也需要暂停所有执行线程。
- Serial Old: Serial 收集器的老年代版本，单线程收集器，使用标记整理算法。
- Parallel Scavenge: 基于标记复制算法实现的多线程收集器，（==JDK8默认在==新生代使用），目标是达到一个可控的吞吐量，和ParNew的最大区别是GC自动调节策略；虚拟机会根据系统的运行状态收集性能监控信息，动态设置这些参数，以提供最优停顿时间和最高的吞吐量；
- Parallel Old：是Parallel Scavenge收集器的老年代版本，基于标记整理算法实现。
- **CMS:** 基于标记清除算法实现的，
  - 是一种以获得最短回收停顿时间为目标的收集器，
  - 运行过程：初始标记，并发标记，重新标记，并发清除。
  - 收集结束会产生大量空间碎片；

- **G1：** 基于标记整理算法实现，
  - G1将整个堆分为大小相等的多个Region（区域），G1跟踪每个区域的垃圾大小，在后台维护一个优先级列表，每次根据允许的收集时间，优先回收价值最大的区域，实现在有限时间内获取尽可能高的回收效率；
  - 运作流程主要包括以下：初始标记，并发标记，最终标记，筛选回收。
  - 不会产生空间碎片，可以精确地控制停顿；

### 12、CMS 的回收过程

CMS(Concurrent Mark Sweep，并发标记清除) 收集器是以获取最短回收停顿时间为目标的收集器（追求低停顿），它在垃圾收集的时候，用户线程和 GC 线程并发执行，因此在垃圾收集过程中用户也不会感到明显的卡顿。

**CMS 回收过程主要分为四步：**

1. 初始标记 （CMS initial mark)：主要是标记 ==GC根节点（被直接或间接引用的对象）== 开始的下一级对象，这个过程会==暂停所有运行线程==（STW），但是跟 GC根节点 直接关联的下级对象不会很多，因此这个过程其实很快。
2. 并发标记 (CMS concurrent mark)：根据上一步的结果，继续向下标识所有关联的对象，直到这条链上的最尽头。这个过程是多线程的，虽然耗时理论上会比较长，但是其它工作线程并不会阻塞，没有 STW。
3. 重新标记（CMS remark）：就是要再标记一次。因为上一步并没有阻塞其它工作线程，其它线程在标识过程中，很有可能会产生新的垃圾
4. 并发清除（CMS concurrent sweep）：清除阶段是清理掉标记阶段认为已经死亡的对象，由于不需要移动存活对象，所以这个阶段也是可以与用户线程同时并发进行的。

**CMS 的问题：**

- **并发回收导致CPU资源紧张：**因为占用了一部分线程而降低程序总吞吐量
- **无法清理浮动垃圾**：因为没有阻塞正在运行的用户线程，就会导致正在标记清理的时候还会伴随新的垃圾对象产生，（总有漏网之鱼）。
- **内存碎片问题：** 由于是基于“==标记清除==”算法实现的回收器，这意味着回收结束时会有内存碎片产生。往往会出现老年代还有很多剩余空间，但就是无法找到足够大的连续空间来分配当前对象（大对象），而不得不提前触发一次 Full GC 的情况。

### 13、G1的回收过程

G1（Garbage First）回是一种面向局部收集的思路设计的回收器（基于Region的内存布局形式，主要面向服务端应用 ==JDK9之后默认回收器==）。G1从整体来看是基于 标记-整理 算法实现的回收器，但从局部（两个Region之间）上看又是基于 标记-复制 算法实现的。

**G1 的回收过程大致可分为四个步骤：**

1. 初始标记（会STW）：主要是标记一下 **GC 根节点** 能直接关联到的对象， ~~并且修改TAMS指针的值~~，让下一阶段用户线程并发运行时，能正确地在可用的 Region 中分配新对象。这个阶段要停顿线程，但耗时很短，~~借用进行 Minor GC 时同步完成，所以 G1 收集器在这个阶段并没有额外停顿。~~
2. 并发标记：从 GC根节点 开始对堆中对象进行可达性分析，递归扫描整个堆里的对象图，找出要回收的对象，这阶段耗时较长，但可与用户程序并发执行。当对象图扫描完成以后，还要重新处理在并发时有引用变动的对象。
3. 最终标记（会STW）：对用户线程做短暂的暂停，处理并发阶段结束后仍有引用变动的对象。
4. 清理阶段（会STW）：更新Region的统计数据，对各个Region的回收价值和成本进行排序，然后制定回收计划。可以自由选择任意多个Region构成回收集，然后把决定回收的那一部分Region的存活对象复制到空的Region中，再清理掉整个旧Region的全部空间。这里的操作涉及存活对象的移动，必须暂停用户线程，由多条回收器线程并行完成的

### 14、Java对象什么时候会回收

1. 当对象==不再被引用==时，即没有任何变量指向该对象时，对象就会被标记为垃圾，等待垃圾回收器进行回收。

2. 当对象的==引用超出作用域==时，即当对象的引用超出了其声明的作用域范围时，对象就会被标记为垃圾。

3. 当程序主动调用 ==System.gc()== 方法时，可以建议垃圾回收器对没有引用的对象进行回收。但垃圾回收器不一定会立即执行回收操作。

4. 当对象的 ==finalize()== 方法被调用时，该对象会被标记为垃圾，并在稍后的某个时间由垃圾回收器进行回收。finalize() 方法是在对象被回收之前的一个清理方法，可以在该方法中进行资源释放等操作。

~~但是Java的垃圾回收是 JVM 自动进行的，具体的回收时间由垃圾回收器决定，而不是由开发人员控制。~~

### 补充 TODO: ZGC JDK11 新增
ZGC也采用标记-复制算法，不过ZGC对该算法做了重大改进：ZGC在标记、转移和重定位阶段几乎都是并发的，这是ZGC实现停顿时间小于10ms目标的最关键原因。

ZGC只有三个STW阶段：**初始标记**，**再标记**，**初始转移**。
1、其中，初始标记和初始转移分别都只需要扫描所有GC Roots，其处理时间和GC Roots的数量成正比，一般情况耗时非常短；
2、再标记阶段STW时间很短，最多1ms，超过1ms则再次进入并发标记阶段。即，ZGC几乎所有暂停都只依赖于GC Roots集合大小，停顿时间不会随着堆的大小或者活跃对象的大小而增加。
3、与ZGC对比，G1的转移阶段完全STW的，且停顿时间随存活对象的大小增加而增加。

[新一代垃圾回收器ZGC的探索与实践 - 美团技术团队 (meituan.com)](https://tech.meituan.com/2020/08/06/new-zgc-practice-in-meituan.html)

JDK21 中，对 ZGC 进行优化，增加分代

### JVM 重要参数

- 显式指定堆内存`–Xms`和`-Xmx`  根据应用程序要求初始化堆内存，即指定最小和最大堆大小 -Xms256m -Xmx512m
- 指定新生代内存 `-Xmn256m`

GC 调优策略中很重要的一条经验总结是这样说的：
> 将新对象预留在新生代，由于 Full GC 的成本远高于 Minor GC，因此尽可能将对象分配在新生代是明智的做法，实际项目中根据 GC 日志分析新生代空间大小分配是否合理，适当通过“-Xmn”命令调节新生代大小，最大限度降低新对象直接进入老年代的情况。

### GC 日志
需要配置上输出 GC 日志的参数，便于分析 GC 相关的问题。
```python
-XX:+PrintGCDetails # 打印基本 GC 信息 
-XX:+PrintGCDateStamps 
-XX:+PrintTenuringDistribution  # 打印对象分布 
-XX:+PrintHeapAtGC  # 打印堆数据 
-XX:+PrintReferenceGC  # 打印Reference处理信息 # 强引用/弱引用/软引用/虚引用/finalize 相关的方法
-XX:+PrintGCApplicationStoppedTime # 打印STW时间 
```

### 处理 OOM

对于 OOM 排查，可以将发生错误时的堆内存信息输出进行查看：
```sh
-XX:+HeapDumpOnOutOfMemoryError # 指示 JVM 遇到 OOM 错误时将 heap 转储到物理文件中。
-XX:HeapDumpPath=./java_pid<pid>.hprof # 表示要写入文件的路径
-XX:OnOutOfMemoryError="< cmd args >;< cmd args >" # 用于发出紧急命令，以便在内存不足的情况下执行
-XX:+UseGCOverheadLimit 
```

### 线上监控工具 Arthas

通过全局视角（观察者，不影响程序正常运行）实时查看应用 load、内存、gc、线程的状态信息，并能在不修改应用代码的情况下，对业务问题进行诊断，
包括查看方法调用的出入参、异常，监测方法执行耗时，类加载信息等，大大提升线上问题排查效率。



## 常见问题实践

### 1、某个接口访问速度很慢，如何排查

对于特定接口的访问速度慢问题，可以从代码逻辑，业务逻辑==，线程池，数据库，和缓存这几个方面去考虑

- ==**代码逻辑：**==  

  - 比如在循环里调用逻辑相同的代码（读取每月数据），可以使用addBatch()批处理代替，或者这次操作涉及到几个表的查询，但之间没有关联，考虑使用多线程。
  - **锁设计不合理。** 比如在读远远多于写的场景下，可以加读写锁的时候，使用了互斥锁，效率会极大降低。 还有==锁过粗==，把锁包裹的范围过大，加锁时间会过长。

- ==**业务逻辑：**== 接口完成对应的代码逻辑后，还需要依赖调用其他的接口再最终返回，而这个被依赖的接口自身很慢，就会导致当前接口需要等待。可以考虑使用异步执行依赖接口调用，当执行好本身的逻辑后返回临时结果，最后根据依赖接口执行相关操作。

- **==线程池设计不合理==** 因为很多业务共用一个线程池，导致其他任务占满了线程池，因此考虑根据业务拆分线程池。

- **==数据库：==** 

  - 查询的表数据确实太大导致查询缓慢，考虑分库分表。

  - 调用的表没有加索引，或者索引失效，可以使用==explain 对语句进行分析==，然后加索引或者修改查询语句

  - 查询语句发生深度分页。比如使用limit 语句查出来1000020条数据，抛弃1000000条，太多无用的数据被查询，导致缓慢，可以考虑增加查询条件

    ```mysql
    -- 查询数据过大
    select name,code from student limit 1000000,20;
    -- 限制条件
    select name,code from student where id>1000000  limit 20
    ```

  - join关联的表过多，且数据很大（==join优于子查询==）。一般join都是在内存完成，当join的数据量比较大的时候，mysql会采用在硬盘上创建临时表的方式进行多张表的关联匹配，磁盘的IO相对很慢。**解决方法是在业务层适当进行关联表的拆分然后分别查询，再将数据拼接。**

  - 查看==慢查询日志==

    ```mysql
    -- 开启查询日志，以慢查询为例 (查询日志 general_log)
    SET GLOBAL slow_query_log = 1;
    -- SET GLOBAL slow_query_log_file = '/path/to/mysql-slow.log';  -- 替换为你希望存储慢查询日志的路径
    SET GLOBAL long_query_time = 1;  -- 设置慢查询的时间阈值，单位为秒，例如1秒
    -- 慢查询日志
    SHOW VARIABLES LIKE 'slow_query_log';
    -- 查看日志内容
    SELECT * FROM mysql.slow_query_log;
    ```

- **==缓存==** 接口自身的局限性，考虑空间换时间，加本地或者redis缓存，让查询数据走缓存

### 2、线上故障排查思路

当项目上线遇到问题，可以从下面几个方向进行故障排查：

- **==服务器==**

  - **磁盘：** 1）利用 `df -h` 获取磁盘空间状态；2）利用 `ls -lh` 查看当前路径的文件大小 ；3）利用 `du  -h` 查看当前文件夹内所有文件的大小
  - **CPU：** 
    - 利用 `top` 查看进程状态。主要获取 CPU/内存使用频率最高的==进程== PID、启动命令等信息。
    - 利用 `top -H` 查看线程状态。获取 CPU/内存使用频率最高的==线程==信息。
    - 通过命令查找指定程序的进程情况，以 mysql 为例 `ps -ef |grep python`  ~~-e 等价于 -a ，表示列出全部的进程~~
  - **内存：** 1）利用 `free -h` 查看内存使用情况。

- ==**Java 应用**==

  - **线程：** 利用 jstack~~（jvm 自带的 Java 堆栈跟踪工具）~~ 查看 jvm 线程运行信息。

  - **JVM：** 

    - 指定合适的内存容量，如 -Xmn（新生代内存大小）、Xms（初始堆内存大小）、Xmx（堆内存最大值）。

    - OOM 时自动 dump 内存快照，用于分析导致内存溢出的原因

      ```bash
       # OOM的时候自动dump内存快照出来
       -XX:+HeapDumpOnOutOfMemoryError
       # 把内存快照放到哪儿去
       -XX:HeapDumpPath=/usr/local/app/oom
      ```

    - 利用 jmap 查询 jvm 内存使用信息，包括1）`jmap -heap` 查看堆区域统计信息；2）`jmap -dump` 导出内存镜像。

  - **GC：**

    - 选择合适的垃圾回收器 CMS、G1、ZGC、...
    - 利用 GC 日志查询 GC 信息，命令 `-XX:+PrintGCDetails -Xloggc:/temp/gc.txt` 。
    - `jstat -gcutil` 动态查看 GC 情况。

- **==数据库==**

  - **慢查询：** 
    - 查看慢查询日志，是否开启： `show variables like "slow_query_log";` 查看内容： `select * from slow_log;`
    - 利用 ==explain== 执行计划优化SQL
    - ？？ 利用 `show processlist`，然后 kill 以终结`慢 SQL`。
  - **连接过多：** 1）`set global max_connections` 增大连接数；2）利用 `show processlist`，然后 kill 以结束过多的连接。
  - **死锁：** 1）事务隔离级别（默认==可重复读==）；2）死锁分析 TODO

- ==**Redis**==

  - 内存不足：

    - 设置内存淘汰机制
    - 查找大 key，比如 redis-cli 中使用 `--bigkeys` 或使用 Rdbtools 工具将大于10kb 的 key 输出为文件。**RESP 客户端**。
    - 增加内存，命令 `config set maxmemory 800m`

  - 连接数过多：

    - config set maxclient 临时增加最大连接数。
    - 限制客户端最大连接数。

  - 慢查询分析： config set slowlog-log-than 设置慢命令阈值，config set slowlog-max-len 设置最大慢命令记录保存数，利用slowlog get 查询慢命令。

    ```python
    config set slowlog-log-slower-than 1000	# 设置慢命令阈值 单位/微秒
    config set slowlog-max-len 1200	# 设置最大慢命令记录保存数
    config rewrite # 将慢查询日志持久化到配置文件（可选）
    slowlog get 3	# 获取 3 条慢查询日志
    ```

  - **查询网络延迟：** `redis-cli -latency` 查询延迟信息。

- **==网络==** 利用 `netstat` 查询统计网络状态。

- **==业务异常==** 从业务日志中分析

### JDK21 新特性
- 虚拟线程：之前 Java 中的线程是基于操作系统的平台线程，21 版本中由 JDK 提供轻量级的虚拟线程，在不需要对原有代码做大的修改下提高系统的并发能力。
	在Java以前的版本（包括预览版），线程的创建是内核态的，非常的占用资源。来到虚拟线程，切换到用户态，极大降低了消耗，提高了速度。
	> ==内核态==（Kernel Mode）：也被称为系统模式，这是计算机系统中最高的权限级别。在这个模式下，程序可以访问计算机的硬件设备，如CPU、内存、硬盘等，并可以对这些设备进行控制和管理。比如，操作系统就运行在内核态，它可以管理系统中的各种资源，包括处理任务、分配内存、管理设备等。 
	> ==用户态==（User Mode）：也被称为用户级别模式，这是计算机系统中较低的权限级别。在这个模式下，程序只能访问和操作特定的用户数据，不能直接访问硬件设备和其他重要的系统资源。用户程序运行在用户态，比如你的文档编辑器、游戏、浏览器等都运行在用户态。
- Generational ZGC（分代式 ZGC）：增加了对分代的支持，提高垃圾回收的性能。命令 `-XX:+ZGenerational`
- 序列集合接口SequencedCollection Interface：为我们执行一些顺序性操作比如获取头尾值提供了各类接口方法
- 向量API的优化：从 JDK16 开始孵化，最新版本包括性能增强和错误修复。

## 操作系统
### CPU 缓存
CPU 缓存是位于 CPU 与内存之间的临时存储器，它的容量比内存小，但数据读取速度比内存快。在缓存中的数据是内存中的一小部分，但这一小部分是短时间内CPU即将访问的，当CPU调用大量数据时，就可避开内存直接从缓存中调用，从而加快读取速度。

### 【补充】进程间有哪些通信方式

- **管道：** 管道传输数据是单向的，如查找运行中的MySQL进程的命令 `ps auxf | grep mysql` ，| 就是一个==匿名管道==（**通信范围是存在父子关系的进程**），用完就会销毁。
  ~~==a==表示显示所有进程，==u==表示显示进程的用户信息，==x==表示显示没有控制终端的进程，==f==选项表示使用完整格式显示进程信息。~~
  通过命令 **mkfifo myPipe** 可以创建一个用于相互通信的==命名管道==，但**这种通信方式效率低，不适合进程间频繁地交换数据**。

- **消息队列：** 即**保存在内核中的消息链表**，由于在内核中每个消息体都有一个最大长度的限制，**消息队列不适合比较大数据的传输**
- **共享内存：** 共享内存的机制，就是在进程中拿出一块**虚拟地址空间来，映射到相同的物理内存中**。一个进程写入的东西，另外一个进程马上就能看到了，避免了拷贝的过程，能够提高进程间通信的效率。
- **信号量：** 信号量是共享内存机制的一个补充，通过 PV（P- V+）实现互斥信号量，保证共享内存在任何时侯只有一个进程在访问，避免了内存冲突。（多个进程同时修改，内容被覆盖）
- **信号：** 进程间通信机制中==唯一的异步通信机制==，因为可以在任何时候发送信号给某一进程，一旦有信号产生，进程就会执行对应的操作。
- **Socket：** 之前的都是同一主机进行进程通信，==Socket== 用于**跨网络与不同主机上的进程之间通信**。

**线程通信方式：** 同个进程下的线程之间都是共享进程的资源，只要是共享变量都可以做到线程间通信，比如全局变量，所以线程间通信更多关注的是多线程竞争共享资源的问题，比如信号量实现在线程间实现互斥与同步：

- 互斥的方式，可保证任意时刻只有一个线程访问共享资源；
- 同步的方式，可保证线程 A 应在线程 B 之前执行；


## 计算机网络

### 1、计算机网络的各层协议及作用

TCP/IP 四层网络体系结构各层的主要功能：

- **应用层（软件应用）：**专注于为用户提供应用功能，比如HTTP、FTP、Telnet、DNS、SMTP等。应用层是不用去关心数据是如何传输的，且工作在操作系统中的用户态，传输层及以下则工作在内核态。

- **传输层（加上TCP头）：**为应用层提供数据传输服务，应用层的数据包会传给传输层（**实现应用到应用的通信**）。该层由两个传输协议，分别是TCP和UDP：

  - TCP：提供面向连接的、可靠的数据传输服务；
  - UDP：提供无连接的、尽最大努力的数据传输服务，但不保证数据传输的可靠性。

- **网络层（加上IP头）：**选择合适的路由和交换结点，确保数据及时传送。主要包括IP协议。就是负责将数据从一个设备传输到另一个设备，即承担实际的数据传输功能。

  **IP 协议的寻址作用是告诉我们去往下一个目的地该朝哪个方向走，路由则是根据「下一个目的地」选择路径。寻址更像在导航，路由更像在操作方向盘**。

- **网络接口层（封装为数据帧）：**在 IP 头部的前面加上 MAC 头部，并封装成数据帧（Data frame）发送到网络上。

### 2、TCP 和UDP 的区别？

|              | UDP                                                          | TCP                                                       |
| ------------ | ------------------------------------------------------------ | --------------------------------------------------------- |
| 是否连接     | 无连接                                                       | 面向连接                                                  |
| 是否可靠     | 不可靠传输，不使用流量控制和拥塞控制                         | 可靠传输，使用流量控制和拥塞控制                          |
| 是否有序     | 无序                                                         | 有序，消息在传输过程中可能会乱序，TCP 会重新排序          |
| 传输速度     | 快                                                           | 慢                                                        |
| 连接对象个数 | 支持一对一，一对多，多对一和多对多交互通信                   | 只能是一对一通信                                          |
| 传输方式     | 面向报文                                                     | 面向字节流                                                |
| 首部开销     | 首部开销小，仅8字节                                          | 首部最小20字节，最大60字节                                |
| 适用场景     | 适用于实时应用（DNS、TFTP文件传输、IP电话、视频会议、直播等） | 适用于要求可靠传输的应用，例如电子邮件、HTTP、FTP文件传输 |

### 3、TCP 的三次握手机制？

- **第一次握手：**客户端请求建立连接，向服务端发送一个**同步报文（SYN=1）**，同时选择一个随机数seq=x 作为**初始序列号**，并进入**SYN_SENT 状态**，等待服务器确认
- 第二次握手：服务端收到连接请求报文后，向客户端发送**同步确认报文（SYN=1，ACK=1）**，**确认号为 ack = x + 1**，同时选择一个随机数 seq = y 作为**初始序列号**，此时服务器进入**SYN_RECV状态**。
- **第三次握手：** 客户端收到服务端的确认后，向服务端发送一个**确认报文（ACK=1）**，**确认号为ack=y+1**，**序列号为seq=x+1**，客户端和服务端进入**ESTABLISHED 状态**，完成三次握手。

理想状态下，TCP连接一旦建立，在通信双方中的任何一方主动关闭连接之前，TCP 连接都将被一直保持下去。

### 4、不是两次握手 和四次握手的原因

- 「两次握手」：无法防止==历史连接==的建立，会造成双方资源的浪费，也无法可靠的==同步双方序列号==；
- 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。

### 5、TCP 的四次挥手过程？

- **第一次挥手：**客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态

- **第二次挥手：** 服务端收到该报文后，向客户端发送 `ACK ` 应答报文，接着服务端进入 `CLOSE_WAIT` 状态，客户端收到服务端的 `ACK` 应答报文后，进入 `FIN_WAIT_2` 状态
- **第三次挥手：**服务端传输完数据后，会向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态
- **第四次挥手：**  客户端收到服务端的 `FIN` 报文后，发送 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态

服务端收到了 `ACK` 应答报文后，进入 `CLOSE` 状态，至此服务端已经完成连接的关闭，

客户端在经过 **2MSL** 的时间后，自动进入 `CLOSE` 状态，至此客户端也完成连接的关闭

### 6、第二次和第三次为什么不合并

因为数据可能还没有处理完，当服务端收到客户端的连接断开请求时，先回复ACK确认收到了请求。等处理完数据再发送FIN报文，请求断开连接。

**什么情况会出现三次挥手：**

当被动关闭方（即服务端）在 TCP 挥手过程中，「**没有数据要发送」并且「开启了 TCP 延迟确认机制」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。**

### 7、建立连接后 客户端出现故障怎么办

通过定时器+超时重试机制，尝试获取确认，直到最后自动断开连接。

### 8、TCP如何保证可靠传输

1. 校验和：通过检验和的方式，接收端可以检测出来数据是否有差错和异常，假如有差错就会直接丢弃TCP段，重新发送。
2. 序列号和确认应答，序列号保证数据有序，确认应答确保数据完整接收
3. 流量控制，TCP使用==滑动窗口==来调节数据发送的速率，从而避免了发送方发送过多的数据而导致接收方无法正常处理的异常。
4. 拥塞控制，TCP有几种方式来进行拥塞控制，包括：慢启动，拥塞避免，拥塞发生以及快速恢复，从而避免网络拥塞
5. 重传机制：TCP中经常需要一端发送请求报文后，另一端发送应答报文，如果中间数据发生丢失，那么TCP的重传机制可以解决这个问题

### 9、什么是TCP 的滑动窗口？

滑动窗口左边的是**已发送并且被确认**的分组，滑动窗口右边是**还没有轮到**的分组。

滑动窗口里面也分为两块，一块是**已经发送但是未被确认**的分组，另一块是窗口内**等待发送**的分组。随着已发送的分组不断被确认，窗口内等待发送的分组也会不断被发送。整个窗口就会往右移动，让还没轮到的分组进入窗口内。

~~滑动窗口起到了一个限流的作用，也就是说当前滑动窗口的大小决定了当前 TCP 发送包的速率，而滑动窗口的大小取决于拥塞控制窗口和流量控制窗口的两者间的最小值。~~

### 10、ping的工作原理

~~ping命令利用了ICMP协议的查询类型报文，~~执行ping命令时，源主机会构建一个回送请求消息包，包含序号和发送时间，然后发送给目标主机，目标主机收到会会构建一个回送响应，标识目标地址可达。如果在规定时间内源主机都没有收到回复，则认为目标主机不可达.

### 11、HTTP 常见状态码有哪些

- 200：服务器已成功处理了请求。 通常，这表示服务器提供了请求的网页。
- 301 ： (永久移动) 请求的网页已永久移动到新位置。 服务器会自动将请求者转到新的地址（==项目部署HTTP 301转到HTTPS==）。
- 302：(临时移动) 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。
- 400 ：客户端请求有语法错误，不能被服务器所理解。
- 403 ：服务器收到请求，但是拒绝提供服务。
- 404 ：(未找到) 服务器找不到请求的网页。
- 500： (服务器内部错误) 服务器遇到错误，无法完成请求。

### 12、GET 和 POST 区别

**使用上的区别**：

- GET 一般对资源进行访问，使用 URL 或 Cookie 传参；而 POST 一般用于对资源进行处理，将数据放在 Body 中，这个是 HTTP 协议用法的约定。
- GET 方式提交的数据有长度限制，而 POST 的数据则可以非常大，这个是因为它们使用的操作系统和浏览器设置的不同引起的区别。
- POST 比 GET 安全，因为数据在地址栏上不可见。

**本质区别：** 

GET 和 POST 最大的区别是 GET 请求是==幂等性==的，POST 请求不是。这个是它们本质区别。

~~幂等性是指一次和多次请求某一个资源应该具有同样的副作用。简单来说意味着对同一URL的多个请求应该返回同样的结果~~

### 【补充】Http 报文格式

==请求报文== HTTP 请求报文由**请求行**、**请求头**、空行和**请求包体**(body)组成。
- 请求行：主要说明客户端想要如何操作服务端的资源，包含请求方法，请求目标（请求资源的URL）和 HTTP 版本号。
- 请求头：报文头包含若干个属性，格式为“属性名:属性值”，服务端据此获取客户端的信息。
- 请求体：HTTP 要传输的内容，HTTP 可以承载很多类型的数字数据:图片、音频、视频、HTML 文档等。

==响应报文== HTTP 响应报文由**状态行**、**响应头部**、空行和**响应包体**(body)组成。
- 状态行：包含协议版本、状态码以及状态描述（状态码的补充，更详细描述）。
- 响应头：由键值对组成，响应头允许服务器传递不能放在状态行的附加信息。
- 响应体：服务器返回给浏览器的响应信息，常见数据格式有：text/html、application/json 等。

### 13、Http 和 Https 的区别？

1. Http 是明文传输的，而 Https 是加密的；
2. Http 建立连接的过程相对简单，而 Https 在 TCP 层与 Http 层之间增加了 SSL/TSL 层，连接建立相对复杂；
3. Http 的默认端口是 80，Https 的默认端口是 443
4. Https 需求申请数字证书从而保证服务是可信的

### 【重点】HTTPS 的加密过程 (RSA 算法)

加密过程如下：

1. 客户端请求 HTTPS 网址，然后连接到服务器的 443 端口 (HTTPS 默认端口，类似于 HTTP 的80端口)。

2. 服务器响应客户端请求，将机构颁发的证书传递给客户端，证书包含公钥和其他信息，~~比如证书颁发机构信息，公司信息和证书有效期等。~~

3. 客户端解析证书并对其进行验证。如果不是有效的证书，~~如果证书不是可信机构颁布，或者证书中的域名与实际域名不一致，或者证书已经过期，~~ 就会向访问者发出警告，由其选择是否还要继续通信。

   如果证书没有问题，客户端就会从服务器证书中取出服务器的公钥。

4. 客户端会生成一个 ==随机码 Key== ，然后使用服务器证书中的公钥对 随机码 KEY 进行加密，再发送给服务器，作为后面==对称加密的密钥==。

5. 服务器在收到随机码 KEY 之后会使用私钥将其解密。

6. 这个时候客户端和服务器就建立了安全连接，~~解决了对称加密的密钥泄露问题，接下来就可以用对称加密进行通信。~~

7. 后续的数据传输过程，服务器使用密钥 (随机码 KEY )对数据进行对称加密并发送给客户端，客户端使用相同的密钥 (随机码 KEY )解密数据。

注：采用 HTTPS 协议的服务器必须要有一套数字 ==CA(Certification Authority) 证书==。颁发证书的同时会产生一个私钥和公钥。

私钥由服务端自己保存，不可泄漏。公钥则是附带在证书的信息中，可以公开的。证书本身也附带一个证书电子签名，这个签名用来验证证书的完整性和真实性，可以防止证书被篡改。

### 14、【重点】输入网址后执行的全部过程

1. 域名解析（通过DNS映射, 将域名变为 ip 地址）。
2. 发起 tcp 的三次握手，建立 tcp 连接。浏览器会以一个随机端口（1024-65535）向服务端的 web 程序 **80** 端口发起 tcp 的连接。
3. 建立 tcp 连接后发起 http 请求。
4. 服务器响应 http 请求，客户端得到 html 代码。服务器 web 应用程序收到 http 请求后，就开始处理请求，处理之后就返回给浏览器 html 文件。
5. 浏览器解析 html 代码，并请求 html 中的资源。
6. 浏览器对页面进行渲染，并呈现给用户。

### 15、什么是Cookie 和Session

- **Cookie（存储在客户端）**

  是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。因此可以用来告诉服务器两个请求是否来自同一浏览器，如保持用户的登录状态。Cookie 使基于无状态的 HTTP 协议记录稳定的状态信息成为了可能。

  Cookie 主要用于以下三个方面：

  - 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）
  - 个性化设置（如用户自定义设置、主题等）
  - 浏览器行为跟踪（如跟踪分析用户行为等）

- **Session（存储在服务端）** 

  Session 是服务器和客户端一次会话的过程。主要存储用户会话所需的属性及配置信息。比如网页跳转的时候，存储在 Session 对象中的变量也不会丢失，而是在整个用户会话中一直存在下去。当客户端关闭会话，或者 Session 超时失效时会话结束。

- Cookie 和Session 的区别？
  - 作用范围不同，Cookie 保存在==客户端==（浏览器），Session 保存在==服务器端==。
  - 存取方式的不同，Cookie 只能保存 ASCII，Session 可以存任意数据类型，一般在 Session 中保存一些常用变量信息，比如说 UserId 等。
  - 有效期不同，Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般有效期较短，客户端关闭或者 Session 超时都会失效。
  - 隐私策略不同，Cookie 存储在客户端，比较容易遭到不法获取；Session 存储在服务端，安全性相对 Cookie 要好一些。
  - 存储大小不同， 单个 Cookie 保存的数据不能超过 4K，Session 可存储数据远高于 Cookie。

- **Cookie 和Session 是如何配合的** 

  **用户第一次请求服务器的时候**，服务器根据用户提交的相关信息，创建对应的 Session ，请求返回时将此 Session 的唯一标识信息 `SessionID` 返回给浏览器，浏览器接收到服务器返回的 SessionID 信息后，会将此信息存入到 Cookie 中，同时 Cookie 记录此 SessionID 属于哪个域名。

  **当用户第二次访问服务器的时候，**请求会自动判断此域名下是否存在 Cookie 信息，如果存在会将 Cookie 信息发送给服务端，服务端会从 Cookie 中获取 SessionID，再根据 SessionID 查找对应的 Session 信息，如果没有找到说明用户没有登录或者登录失效，如果找到 Session 证明用户已经登录可执行后面操作。

### 16、什么是SQL注入，如何避免SQL 注入？

**SQL注入主要有以下 4 点**

- 恶意拼接查询
- 利用注释执行非法命令
- 传入非法参数
- 添加额外条件

**避免SQL注入的一些方法**：

- 限制数据库权限，给用户提供仅仅能够满足其工作的最低权限。
- 对进入数据库的特殊字符（’”\尖括号&*;等）转义处理。
- 提供参数化查询接口，不要直接使用原生SQL。（`$`拼接导致SQL注入，应该使用`#`预编译）



## MySQL

### 数据库三范式
- **第一范式：** 属性（对应于表中的字段）不可以再拆分，~~唯一性原则，也就是这个字段只能是一个值。~~
- **第二范式：** 表中任意一个主键或任意一组联合主键，可以确定除该主键外的所有的非主键值。~~即一张表只用来描述一件事。~~
- **第三范式：** 在任一主键都可以确定所有非主键字段值的情况下，不能存在某非主键字段 A 可以获取 某非主键字段 B。~~即消除传递依赖。~~

### JDBC连接到MySQL的过程

- **最基本的步骤：**

  1、导包 java.sql.Connection 和 java.sql.DriverManager;

  2、加载 MySQL JDBC 驱动程序，Class.forName("com.mysql.cj.jdbc.Driver");

  3、配置数据库连接参数，数据库地址和名称，用户名和密码 Connection connection = DriverManager.getConnection(jdbcUrl, username, password);

  4、执行编写好的 SQL 语句

- Spring框架使用连接池 hikari

  1、添加 HikariCP 和 MyBatis-Plus 的依赖

  2、配置数据源，核心参数如下

  ```yaml
  spring.datasource.hikari.minimum-idle=5		# 最小空闲连接数量
  spring.datasource.hikari.idle-timeout=180000	# 空闲连接存活最大时间，默认600000（10分钟）
  spring.datasource.hikari.maximum-pool-size=10	# 连接池最大连接数，默认是10
  spring.datasource.hikari.auto-commit=true	# 此属性控制从池返回的连接的默认自动提交行为,默认值：true
  spring.datasource.hikari.pool-name=MyHikariCP	# 连接池名称
  spring.datasource.hikari.max-lifetime=1800000	# 连接的最长生命周期，值0表示无限生命周期，默认1800000即30分钟
  spring.datasource.hikari.connection-timeout=30000	# 数据库连接超时时间,默认30秒，即30000
  ```

  3、配置 MyBatis-Plus ，在配置类添加 `@MapperScan` 注解来扫描 Mapper 接口所在的包。

  4、创建对应数据库表的 ==DO类== 和相应的 Mapper 接口，接口继承 MyBatis-Plus 提供的 `BaseMapper` 接口，或者使用 `@Mapper` 注解标记。

  5、在 Service 层调用创建的 Mapper 接口实现数据库操作。

### update 语句执行过程

具体更新一条记录 UPDATE t_user SET name = 'Jeff' WHERE id = 1; 的流程如下:

1、执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录：

2、执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：

- 如果一样的话就不进行后续更新流程；
- 如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；

3、开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log

4、InnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。

5、在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。

6、然后事务提交「两阶段提交」，执行就好了。

### 1、MySQL执行流程

1. 连接器：基于TCP与MySQL进行连接
2. 查询缓存：查询SQL语句是否具有缓存（8.0好像取消了）
3. 解析SQL：词法分析与语法分析，判断SQL语句是否有误
4. 执行SQL：预处理、优化、执行

### 2、InnoDB和MylSAM的区别

- ==支持事务==——不支持事务
- count()会扫描全文统计——记录count
- 支持外键——不支持外键
- 支持行级锁——不支持行级锁

### 3、索引的分类

- 数据结构角度：B+索引，Hash索引，全文（full-text）索引
- **物理存储角度** ：主键索引（==聚簇索引==），二级索引（==辅助索引==）
- 字段特性角度：主键索引，唯一索引（UNIQUE 字段），普通索引，前缀索引（根据某个字段的前几个字符建立索引）
- 字段个数角度：单列索引，联合索引

【补充】  **主键索引和二级索引的区别** 

- 主键索引的 B+Tree 的叶子节点存放的是实际数据，即完整的用户记录；

- 二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。

  所以，在查询时使用了二级索引，如果查询的数据能在二级索引里查询的到，那么就不需要回表，这个过程就是==覆盖索引==。

  如果查询的数据不在二级索引里，会先检索二级索引，找到对应的叶子节点获取主键值，然后再通过主键索引查询数据，这个过程就是==回表==。

### 4、索引优化的方式

1. 前缀索引优化：使用字符字段前几个字符作为索引，可以节省空间，但无法排序、覆盖索引
2. 覆盖索引优化：使用==联合索引来避免回表==
3. 使用自增主键：在插入新数据的时候减少调整操作（==页分裂==）
4. 使用 NOT NULL：null 值会使索引变得更加复杂，并且占用空间
5. 防止索引失效（==最左匹配原则==）

### 5、为什么MySQL用B+树作为索引

主要总述： B+ 树是一种多叉树结构，相比于二叉树，树的高度会小很多，大大减少了对磁盘的访问次数。

B+ 树只在**叶子节点存储数据，非叶子节点存储索引**，在相同的数据量下，B+ 的非叶子节点可以存储更多数据，从而进一步==减少树的高度==；

B+ 树的非叶子节点不存储数据，其实都是冗余节点，这种结构使得 ==B+ 树在插入和删除时比 B 树方便许多==；

B+ 树中所有的数据都存储在叶子节点，并且使用双向链表连接，更有利于范围查询。

### 6、索引什么时候会失效

1. 使用左或者左右模糊查询：B+树为有序结构，单前缀不明确时，无法进行比较
2. 使用函数表达式：使用了函数后索引列的值发生变化，自然无法使用索引
3. 对字段进行计算：原理于函数一样
4. 隐式类型转换：当查询字段为字符串，而查询条件输入为数字，MySQL 自动将字符串字段转为数字，相当于使用了函数
5. 联合查询非最左匹配：使用联合查询时，按照最左优先的原则对联合索引进行组合，如果最左字段不匹配，则索引失效
6. 使用 or ：使用 or 表示多个条件满足一个就行，那么只有一个条件是索引是没有意义的

### 【补充】explain 性能分析

EXPLAIN 命令可用于查看查询优化器如何执行查询的语句。在查询前添加 explain 关键字即可。

重要的几个查询信息字段：

- **select_type** : SELECT 查询的类型。（列举常见的几个）
  - SIMPLE，表示此查询不包含 UNION 查询或子查询，即普通查询语句。
  - PRIMARY，表示此查询是最外层的查询。
  - UNION表示此查询是 UNION 的第二或随后的查询
- **table** : 查询涉及的表或衍生表
- **type** : 提供了判断查询是否高效的重要依据依据。通过 `type` 字段, 可以判断此次查询是 ==全表扫描== 还是 ==索引扫描== 。
  - `system`: 表中只有一条数据. 这个类型是特殊的 `const` 类型.
  - `const`: 针对主键或唯一索引的等值查询扫描, 最多只返回一行数据。 const 查询速度非常快, 因为它仅仅读取一次即可。
  - `ref`: 此类型通常出现在多表的 join 查询, 针对于非唯一或非主键索引。eq_ref 表示前表的每一个结果只能匹配后表的一行结果。
  - `range`: 表示使用索引范围查询, 通过索引字段范围获取表中部分数据记录。
  - `index`: 表示全索引扫描(full index scan), 只不过 ALL 类型是全表扫描, 而 index 类型则仅仅扫描所有的索引, 而不扫描数据。
  - `ALL:` 表示全表扫描, 这个类型的查询是性能最差的查询之一。
- **possible_keys** : 此次查询中可能选用的索引。即使有些索引在 `possible_keys` 中出现, 但是并不表示此索引会真正地被 MySQL 使用到. MySQL 在查询时具体使用了哪些索引, 由 `key` 字段决定。
- **key** : 当前查询时所真正使用到的索引。
- **rows** : 查询优化器根据统计信息，==估算== SQL 要查找到结果集需要扫描读取的数据行数。原则上 rows 越少越好。
- extra：很多额外的信息会在 Extra 字段显示, 常见的有以下几种内容:
  - Using filesort：表示 MySQL 需额外的排序操作, 不能通过索引顺序达到排序效果。
  - Using index： 覆盖索引扫描，表示查询在索引树中就可查找所需数据，不用扫描表数据文件（回表）。
  - Using temporary： 查询有使用临时表, 一般出现于排序，分组和多表 join 的情况（查询效率不高，建议优化）。



### 【补充】回滚、重做 、归档日志

- **undo log（回滚日志）：** Innodb 存储引擎层生成的日志，实现了事务中的 ==原子性==，主要用于 **事务回滚和 MVCC** 。
- **redo log（重做日志）：** Innodb 存储引擎层生成的日志，实现了事务中的==持久性==，主要用于 **掉电等故障恢复**；
- **binlog （归档日志）：** Server 层生成的日志，主要用于 **数据备份和主从复制**；

### 7、【基础】事务有哪些特性

- 原子性：指一个事务中的所有操作要么全部执行，要么全部不执行。若在事务中某个操作执行失败，则事务回滚到初始状态
- 一致性：指事务前后，数据满足完整性约束，数据库保持一致性状态
- 隔离性：数据库支持多个事务对数据库进行操作，各个事务有自己的隔离空间， 互相不干扰
- 持久性：事务对数据的修改是永久的

InnoDB 引擎通过以下技术来==保证事务==的这四个特性：

- 持久性是通过 ==redo log== （**重做日志**）来保证的；
- 原子性是通过 ==undo log==（**回滚日志**） 来保证的；
- 隔离性是通过 ==MVCC（多版本并发控制）== 或==锁机制==（next-key lock：记录锁+间隙锁）来保证的；
- 一致性则是通过**持久性+原子性+隔离性**来保证；

**事务的隔离性**是重点，也是面试时最常问的知识点。

### 8、并行事务会引发什么问题

- **脏读：**如果一个事务「读到」了另一个**「未提交事务修改过的数据」**，就意味着发生了脏读现象。
- **不可重复读：**在一个事务内多次读取同一个数据，如果出现 **前后两次读到的数据不一致** ，就意味着发生了不可重复读现象。
- **幻读：**在一个事务内多次查询某个符合条件的==记录数量==（结果集），前后两次查询到的记录数量（结果集）不一致，则发生了幻读现象。

### 9、四种隔离级别

SQL 标准提出了四种隔离级别来规避这些现象，隔离级别越高，性能效率就越低，这四个隔离级别如下：

- 读未提交（read uncommitted），指一个事务还没提交时，它做的变更就能被其他事务看到；
- 读提交（read committed），指一个事务提交之后，它做的变更才能被其他事务看到；
- 可重复读（repeatable read），指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，==InnoDB 引擎的默认隔离级别==；
- 串行化（serializable）；会对记录加上==读写锁==，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。

### 10、【重点】MVCC是怎样实现的（保证隔离性，解决幻读）

MVCC 是通过 read view 和 undo log（==回滚日志==）来实现的

Read View是一个==快照==，其中主要保存了当前事务的序号，目前正在活跃的事务序号列表，还有最小活跃事务序号和下一个事务序号。而行记录中有两个隐藏字段，一个用于记录最近对记录进行改动的事务序号，还有一个用来指向旧版本记录形成历史版本记录的链表

对于读已提交隔离级别：事务开始时会生成read view，并且事务在每次读取数据时都会重新创建Read View

对于可重复读隔离级别：事务开始时生成read view，直到事务结束都使用这个版本

当读取数据时，数据中有隐藏信息包括：最近修改该记录的事务id，指向上一个版本记录的指针（形成历史版本链），事务会判断该记录的版本是否符合要求，如果不符合就追溯历史版本链找到合适的记录进行读取

### 11、可重复读如何避免幻读问题

对于快照读（普通 select 语句）：通过==并行版本控制==MVCC来避免幻读，每次读取都是事务开启时的数据版本，其他事务新插入的记录无法查到。

对于当前读（select ... for ==update== 等语句）：进行当前读时会加上记录锁和间隙锁，其他事务操作时会堵塞，直到加锁的事务结束释放。

~~出现幻读的情况~~：先进行快照读，此时读到的是历史数据，再进行当前读，此时读到的是最新数据，之后再进行快照读，记录变成了最新版本。

### 12、MySQL有哪些锁

按锁的范围可以分为：

- 全局锁：对整个数据库进行加锁，语句 `Flush tables with read lock`，一般用于全库逻辑备份。
- 表级锁：开销小，加锁快，==**不会出现死锁**==；锁粒度大，发生锁冲突的概率最高，并发度最低。
  - 表锁：对整个表加锁，加共享/独占锁 `lock tables t_student read/write;`，释放当前的表锁 `unlock tables;`
  - 元数据锁（MDL）：对表数据==记录操作==会自动加上 ==MDL 读锁==，防止其他线程更改表结构；同理对==表结构更改==会加上 ==MDL 写锁==。
  - 意向锁：InnoDB 向某些记录加共享/独占锁前，先加一个表级别的意向共享/独占锁，**实现快速判断表里是否有记录被加锁**。
  - AUTO-INC 锁：通常用来实现主键自增过程的加锁。
- **行级锁：** 加锁慢、开销大，容易发生死锁现象；锁粒度小，发生锁冲突的概率也最低、并发度最高。
  - 记录锁：锁的是记录本身
  - 间隙锁：锁的就是两个值之间的空隙，以防止其他事务在这个空隙间插入新的数据，从而避免幻读现象。
  - 临键锁==next-key lock==：记录锁+间隙锁，左开右闭 （**用来解决「可重复读」隔离级别下的幻读问题**）
  - 插入意向锁：当事务要添加的记录被其他事务的间隙锁堵塞，就会生成一个插入意向锁，等待其他事务结束

### 13、什么是MySQL死锁，如何避免

查看当前语句==执行过程==加的锁：`select * from performance_schema.data_locks\G;`

原因：由于间隙锁是共享的，当两个事务获取到相同范围的间隙锁，且两个事务往范围内插入记录，就会相互等待间隙锁释放而全部阻塞，形成死锁。

避免：1）设置事务等待锁的超时时间，超时就回滚事务；2）开启主动检测死锁，检测到了就回滚死锁链条中的某一个事务。

（死锁的四个必要条件：**互斥、占有且等待、不可强占用、循环等待**）

### 14、【补充】关于 update 和 next-key lock

当执行 select ... for update 语句的时候，会加上 next-key lock，其他事务在 next-key lock 锁范围内插入记录就会被阻塞。

执行 update 语句时，如果没有使用索引，就可能会给全表记录~~（取决于优化器选择的是索引扫描还是全表扫描）~~加上 next-key 锁， 那么锁就会持续很长一段时间，直到事务结束，而这期间除了 `select ... from`语句，其他语句都会被锁住不能执行。


## Redis

### 1、什么是Redis？

Redis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成的，因此**读写速度非常快**，常用于**缓存，消息队列，分布式锁等场景。**

### 2、为什么用Redis 作为MySQL 的缓存？

主要是因为 Redis 具备「==高性能==」和「==高并发==」两种特性

MySQL 是从磁盘中读取数据，而操作 Redis 缓存就是直接操作内存，所以速度相当快。

Redis 单机的 QPS 能轻松破 10w，而 MySQL 单机的 QPS 很难破 1w。

### 3、Redis 常见的数据类型及使用场景

Redis 提供了丰富的数据类型，常见的有五种数据类型：String（字符串），Hash（哈希），List（列表），Set（集合）、Zset（有序集合）。

- String （**存储字符串、整数或浮点数**）：缓存对象、常规计数、分布式锁、共享 session 信息等。

  > String 类型的底层的数据结构实现主要是 SDS（简单动态字符串）。

- List（**链表，每个节点包含一个字符串**）：消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。

  > List 类型的底层数据结构是由**双向链表或压缩列表**实现的
  >
  > Redis 3.2之后的版本中，**List 数据类型底层数据结构就只由 quicklist 实现了，替代了双向链表和压缩列表**。

- Set（**包含字符串的无序集合**）：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。

  > Set 类型的底层数据结构是由**哈希表或整数集合**实现的：
  >
  > - 如果集合中的元素都是整数且个数小于 512 （默认值，set-maxintset-entries配置）个，Redis 会使用**整数集合**作为 Set 类型的底层数据结构；
  > - 如果集合中的元素不满足上面条件，则 Redis 使用**哈希表**作为 Set 类型的底层数据结构。

- Hash（**包含键值对的无序散列表**）：缓存对象、购物车等。

  > Hash 类型的底层数据结构是由**压缩列表或哈希表**实现的（==Redis 7.0之前==）：
  >
  > - 如果哈希类型元素个数小于 512 个（默认值，可由 hash-max-ziplist-entries 配置），所有值小于 64 字节（默认值，可由 hash-max-ziplist-value 配置）的话，Redis 会使用**压缩列表**作为 Hash 类型的底层数据结构；
  > - 如果哈希类型元素不满足上面条件，Redis 会使用**哈希表**作为 Hash 类型的底层数据结构。
  >
  > ==Redis 7.0之后的版本中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。==

- Zset（用于存储键值对，==带分数==）：排序场景，比如排行榜、电话和姓名排序等。

  > Zset 类型的底层数据结构是由**压缩列表或跳表**实现的（Redis 7.0之前）：
  >
  > - 如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用**压缩列表**作为 Zset 类型的底层数据结构；
  > - 如果有序集合的元素不满足上面的条件，Redis 会使用**跳表**作为 Zset 类型的底层数据结构；
  >
  > ==Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。==

后续版本支持的四种数据类型的应用场景：

- BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等；
- HyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等；
- GEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车；
- Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列。

### 4、Redis 采用单线程为什么还这么快？

Redis 采用单线程（**网络 I/O 和执行命令**）那么快，有如下几个原因：

- Redis 的大部分操作**都在内存中完成**，并且采用了高效的数据结构，因此 Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU，**既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了；**
- Redis 采用单线程模型**避免了多线程之间的竞争**，省去了==多线程切换==带来的时间和性能上的开销，而且也不会导致==加锁解锁==问题。
- Redis 采用了 **I/O 多路复用机制**处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。

### 5、缓存雪崩

原因：当**大量缓存数据在同一时间过期（失效）**或者 **Redis 故障宕机**时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃

解决：

- 设置过期时间的时候加一些随机值，避免数据在同一时间过期；
- 后台更新缓存，即更新缓存的工作交由后台线程定时更新。
- 服务熔断（暂停业务应用对缓存的访问，直接返回错误）或请求限流机制（只发送少部分请求到数据库处理，其他请求直接拒绝服务）
- 设置高可用Redis集群

### 6、缓存击穿

**原因：**缓存中的**某个热点数据过期**了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮

**解决方案：**

- 互斥锁方案，保证**同一时间**只有**一个业务线程**去构建缓存，当构建完成后再释放锁。未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值（**互斥锁最好设置超时时间，避免该请求拿到锁后，因为某种意外一直不释放锁，导致阻塞**）。
- 不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；

### 7、缓存穿透

**原因：**用户访问的数据，**既不在缓存中，也不在数据库中**，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，**没办法构建缓存数据，来服务后续的请求。**那么当有大量这样的请求到来时，数据库的压力骤增。

**解决方案：**

- 加强格式检查，拦截无效请求
- 不存在的数据缓存空值或默认值，后续请求就可以从缓存中读取到空值或者默认值，返回给应用，避免查询数据库；
- 使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在；

**注意：** *查询布隆过滤器说数据存在，并不一定证明数据库中存在这个数据，但是查询到数据不存在，数据库中一定就不存在这个数据*（基于哈希函数，可能存在哈希冲突）。

### 8、数据库和缓存如何保证一致性？

不论是先更新数据库还是先更新缓存，在并发场景下都可能发生数据不一致的问题；可以使用**先更新数据库再删除缓存，可以保证数据一致**（出现数据不一致的概率很小，因为缓存的写入通常要远远快于数据库的写入），但会导致缓存命中率降低。

**注意：**这里有新的问题，更新数据库和删除缓存是两个操作，如何保证都执行成功呢？

**答：**我们提供两种解决方法（都是**异步操作**）：

- **重试机制**。通过引入**消息队列**，将第二个删除缓存操作的数据加入到消息队列，如果删除缓存成功，就把数据从消息队列中移除，否则从消息队列读取数据重试。
- **订阅MySQL binlog，再操作缓存。**通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 Canal 中间件就是基于这个实现的。

> 为什么是删除缓存，而不是更新缓存呢？

删除一个数据，相比更新一个数据更加轻量级，出问题的概率更小。在实际业务中，缓存的数据可能不是直接来自数据库表，也许来自多张底层数据表的聚合。

### 9、Redis 如何实现数据不丢失？

Redis 实现了数据持久化的机制，这个机制会把数据存储到磁盘，这样在 Redis 重启就能够从磁盘中恢复原有的数据。Redis 共有三种数据持久化的方式：

- **AOF 日志**：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里；
- **RDB 快照**：将某一时刻的内存数据，以二进制的方式写入磁盘；
- **混合持久化方式**：Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点；

### 10、AOF日志是怎么工作的

开启AOF日志后（默认关），在进行写操作时，先执行写操作命令，然后会将该命令以追加的方式写入AOF 日志文件缓存，再写入硬盘持久化，这些操作都是在主线程进行的。

先执行操作命令再写入日志的==好处==：

- **避免额外的检查开销：**先执行操作命令会进行语法检查再执行，如果语法有误，也就不会记录到日志中，避免额外检查开销。
- **不会阻塞当前操作命令的执行。**

==也有坏处==：

- 有数据丢失风险：可能执行操作命令后但没来得及写入日志，此时服务器宕机了
- 可能阻塞其他操作命令

Redis 提供了 3 种将AOF日志写回硬盘的策略：

- **Always：**每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；高安全性
- **EverySec（默认）：**每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘（异步执行）；折中
- **No**：不控制，交给操作系统决定何时将缓冲区内容写入磁盘；高性能

### 11、RDB 快照是如何实现的？

RDB存储的是记录本身，相较于AOF日志（记录操作），恢复数据的速度更快；RBD可以通过save（主进程调用）和bgsave（子进程调用）执行，也可以设置自动执行；RBD为全数据保存，因此对性能影响较大，通常设置5分钟保存一次

RDB执行快照时是否可以修改数据：

- 如果在主进程调用，则主进程其他操作会被堵塞；
- 如果在子进程调用，那么主进程写操作时会触发写时复制，不过期间主线程的操作不会被RDB快照记录

### 12、AOF 和RDB混合持久化

RDB 的优点是数据恢复速度快，但快照频率太低，丢失的数据就会比较多，频率太高，就会影响性能。

AOF 的优点是丢失数据少，但数据恢复慢。

Redis 4.0 提出了**混合使用 AOF 日志和内存快照**，也叫**混合持久化**，既保证了 Redis 重启速度，又降低数据丢失风险。

**混合持久化：**在AOF 日志重写时，重写子进程会将与主线程共享的内存数据（**已有的内存数据**）以RDB 快照写入到AOF 文件，在此期间主线程的写操作会被记录在重写缓冲区，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。

综上，使用了混合持久化，AOF 文件的**前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据**。

### 13、什么是大Key ，会导致什么？

- 大 key 并不是指 key 的值很大，而是 key 对应的 value 很大。一般而言，下面这两种情况被称为大 key：
  - String 类型的值大于 10 KB；
  - Hash、List、Set、ZSet 类型的元素的个数超过 5000个；
- 大Key对==持久化的影响==
  - 大key会增加AOF文件大小，从而导致更快的触发AOF重写，影响性能
  - 在重写AOF和保存RDB时，要复制页表，此阶段会发生堵塞，另外在重写和保存期间，主线程对大key进行了修改也会触发复制导致阻塞
- 大key 会==造成==什么问题（**重点**）
  - **客户端超时阻塞**。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。
  - **引发网络阻塞**。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。
  - **阻塞工作线程**。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。
  - **内存分布不均**。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。
- 如何==删除大Key==
  - 采用**异步删除**法，**用 unlink 命令代替 del 来删除**。这样 Redis 会将这个 key 放入到一个异步线程中进行删除，这样不会阻塞主线程。

### 14、Redis过期删除策略

主要有三种过期删除策略，分别是：

- **定时删除：**在设置key 的过期时间时，同时创建一个定时事件，当事件到达后，由事件处理器自动执行key 的删除操作。**优缺点：**该策略能尽快释放占用内存，对内存友好，但删除大量的过期key 会占用cpu 资源，因此对cpu 不友好。
- **惰性删除：**不主动删除过期的key，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key，然后返回**null**。**优缺点：**该策略对CPU 时间最友好，但过期的key 未被查询时一直会占用内存。
- **定期删除：**每隔一段时间（==每秒10次==）「随机」从数据库中取出一定数量（==20个==）的 key 进行检查，并删除其中的过期key。是对上述两种策略的折中。

Redis 选择「==惰性删除+定期删除==」这两种策略配和使用，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。

### 15、Redis 内存淘汰策略有哪些？

Redis 内存淘汰策略共有八种，这八种策略大体分为「不进行数据淘汰」和「进行数据淘汰」两类策略。使用 `config get maxmemory-policy` 命令查看

- 不进行数据淘汰的策略：**noeviction**（Redis3.0之后，默认的内存淘汰策略） ：当运行内存超过最大设置内存时，不淘汰任何数据，仍然可以正常查询或删除操作；但是如果有新的数据写入，则会触发 OOM。
- 进行数据淘汰的策略：
  - 在设置了过期时间的数据中进行淘汰：

    - **volatile-random**：随机淘汰设置了过期时间的任意键值；
    - **volatile-ttl**：优先淘汰更早过期的键值。
    - **volatile-lru**（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值；
    - **volatile-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值；
  - 在所有数据范围内进行淘汰：
    - **allkeys-random**：随机淘汰任意键值;
    - **allkeys-lru**：淘汰整个键值中最久未使用的键值；
    - **allkeys-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。

### 16、LRU 算法和 LFU 算法有什么区别？

- **==LRU==** 全称是 Least Recently Used 翻译为**最近最少使用**，会选择淘汰最近最少使用的数据。
红黑树
  - **通常实现：**传统 LRU 算法的实现是基于「链表」结构，链表中的元素按照操作顺序从前往后排列，最新操作的键会被移动到表头，当需要内存淘汰时，只需要删除链表尾部的元素即可，因为链表尾部的元素就代表最久未被使用的元素。

  - **Redis 实现**：在对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间。当进行内存淘汰时，会使用**随机采样的方式来淘汰数据**，它是随机取 5 个值（此值可配置），然后**淘汰最久没有使用的那个**。

  - **优点是** 1）不需要为所有数据维护一个大链表，节省内存占用；2）不用每次数据访问时移动链表项，提升了缓存性能。

  - **缺点是** 无法**解决缓存污染问题**，比如大量数据被缓存，但这些缓存数据只被读取一次，便存留在缓存中很长一段时间，造成缓存污染。

- **==LFU==** 全称是 Least Frequently Used 翻译为**最近最不常用**，LFU 算法是根据数据访问次数来淘汰数据的，它的核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。
  - **Redis实现：**相比于 LRU 算法的实现，多记录了「数据的访问频次」的信息， 即LFU 算法是根据**访问频次**来淘汰数据的，而不只是访问次数。
  - 具体的，**在 LFU 算法中**，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，低 8bit 存储 logc(Logistic Counter)。**在每次 key 被访问时，**对于 logc（**访问频次，初始为5**） 是这样变化的：先按照上次访问距离当前的时长，来对 logc 进行衰减；然后，再按照一定概率增加 logc 的值

### 17、主从复制

- **全量复制** 是主从服务器间的第一次同步，其过程可分为三个阶段：
  - **建立连接，协商同步：**从库向主库发送数据同步请求，主库收到请求会发送响应命令返回给对方。
  - **主库同步数据给从库：**主库执行 bgsave 命令开启子进程来生成 RDB 快照，然后把文件发送给从服务器。（在`生成RDB文件`，`发送RDB文件给从库`，`从库加载RDB文件`这三个期间，主库会将收到的写操作命令写入到**replication buffer 缓冲区**）
  - **主库发送新写操作命令发送给从库：**从库将收到的RDB 文件载入到内存后，向主库发送同步完成的消息；主库收到后，将缓冲区中的写操作命令发送给从库，从库接收后执行同步，此时**第一次同步完成**，主从数据一致。
- **基于长连接的命令传播：** 主从服务器在完成第一次同步后，双方之间就会维护一个 TCP 连接，后续主服务器可以通过这个连接继续将写操作命令传播给从服务器。
- **增量复制** 在==网络中断后恢复时==使用，主服务器会有一个环形缓冲区，在每次命令传输时，主服务器会把命令记录到这个缓冲区，并使用一个偏移量记录写入的位置，从服务器同步命令时也会用偏移量记下读的位置。当网络中断恢复后，从服务会向主服务发送请求，同时携带偏移量，主服务器收到请求后，会拿着偏移量在环形缓冲区比对：
  - 如果存在：则返回读写偏移量之间的增量命令给从服务进行同步
  - 如果不存在：那么说明缺少的数据已经不在环形缓冲区，进行全量复制

- **Redis如何判断节点是否可用：** 通过互相的 ping-pong 心跳检测机制，如果有一半以上的节点去 ping 一个节点的时候没有 pong 回应，集群就会认为这个节点挂掉了，会断开与这个节点的连接。
  - 主节点：默认每隔10s ping一次从节点
  - 从节点：每隔1s 就向主节点发送请求同时带上偏移量，检查是否有数据 丢失，如果有就同步数据

- **主从复制中如何处理过期key**  主节点处理了 一个key 或通过淘汰算法淘汰了一个key，此时主节点模拟一条del 命令发送给从节点，从节点收到命令后进行删除key 的操作。
- **是同步复制还是异步复制** Redis 主节点每次收到写命令后，先写到内部的缓冲区，然后异步发送给从节点。
- **如何应对主从数据不一致** 因为主从节点间的命令复制是异步进行的，所以无法保证强一致性（从主数据时时刻刻保持一致），只能尽量保证一致性：
  - 尽量保证主从节点间的网络连接稳定，避免主从节点在不同的机房
  - 通过外部程序来监控主从节点的复制进度。这个程序读取主服务器写操作的进度（master_repl_offset）以及从服务器同步的进度（slave_repl_offset），然后对比两者的进度差，设置一个阈值，如果进度差高于这个阈值，那么说明从服务与主服务器的数据一致性非常差，则禁止客户端访问这个从服务器读取数据，从而避免读到太过时的数据

### 18、什么是哨兵机制

哨兵是一个运行在特殊模式下的 Redis 进程，所以它也是一个节点。它相当于是一个“观察者节点”（==一般为3个==），观察对象是主从节点，主要负责三件事情：**监控、选举、通知**。

**哨兵（Sentinel）机制**，它的作用是实现**主从节点故障转移**。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。

### 19、如何判断主节点故障

**主观下线：**哨兵会每隔一秒给所有的主从节点发送ping 命令。当主从节点在规定时间内（配置参数**down-after-milliseconds**，单位毫秒）向哨兵返回响应命令，就判断他们在正常运行，否则标记为主观下线。

**客观下线：**客观下线是只针对主节点的，指的是主节点自身并没有发生故障，但是因为主节点的系统压力比较大或网络阻塞，导致没有在规定时间内响应哨兵的ping 命令。为了减少误判的情况，一般会设置多个哨兵节点（**3个**）组成哨兵集群。当某个哨兵节点认为主节点下线后，会询问其他哨兵节点进行投票，如果投票超过一定数量（一般是哨兵节点数量/2+1），就将主节点标记为客观下线。

### 20、哨兵集群中哪个哨兵节点进行主从故障转移呢？

哨兵集群会选出一个leader来进行主从切换。当哨兵节点判断主节点客观下线后，自己会成为leader候选者，此时所有哨兵节点进行投票，如果票数超过半数并且票数超过设定值，该哨兵节点当选leader

因为投票机制，所以哨兵一般至少三个以上，票数要求设置为总数的一半+1

### 21、主从故障转移的过程是怎样的？

在哨兵集群中通过投票的方式，选举出了哨兵 leader 后，就可以进行主从故障转移，主要分为四个步骤：

- 第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。选择新主节点的原则是**先排除网络状况不好的从节点**，然后按以下依次筛选：
  - 节点的优先级更高（按服务器的性能提前设置）
  - 节点的复制进度最多
  - 当优先级和复制进度都相同，则选择节点的id 较小的
- 第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；
- 第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；
- 第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；

### 22、哨兵集群是如何组成的

通过配置哨兵信息来搭建哨兵集群，只需要填写以下几个参数：设置主节点名字、主节点的 IP 地址和端口号以及 quorum 值。

**哨兵节点之间是通过 Redis 的发布者/订阅者机制来相互发现的。**

主节点知道所有「从节点」的信息，所以哨兵会每 10 秒一次的频率向主节点发送 INFO 命令来获取所有「从节点」的信息。

**简述：**通过 Redis 的发布者/订阅者机制，哨兵之间可以相互感知，然后组成集群，同时，哨兵又通过 INFO 命令，在主节点里获得了所有从节点连接信息，于是就能和从节点建立连接，并进行监控了。


### 【补充】Elasticsearch

Elasticsearch 让你可以快速、实时地存储、搜索和分析大量数据 使用IK分词器替换默认的分词插件

- 基础    
    1. ElasticsearchES中的index相当于mysql的db，一个mysql可以有多个db，类似的，
    2. 一个ES集群可以有多个index。
    3. ES中的type相当于mysql中的某个表，mysql中的某个db可以有多个表，在某个表中存储我们的某一类数据。
    4. ES中的type对应的mapping，相当于mysql中的表结构，定义了不同字段的数据类型。
    
- 倒排索引
    1. 倒排索引是一种==数据结构==，用于优化文本搜索。一般的检索是对文章，逐个遍历找到对应关键词的位置。而倒排索引，是通过分词策略，形成了词和文章的映射关系表，这种词典+映射表即为倒排索引。有了倒排索引，就能实现O（1）时间复杂度的效率检索文章了，极大的提高了检索效率。

## RabbitMQ

### 为什么使用消息队列

使用MQ的场景很多，主要有三个：解耦、异步、削峰。

- **解耦：**假设现在，日志不光要插入到数据库里，还要在硬盘中增加文件类型的日志，同时，一些关键日志还要通过邮件的方式发送给指定的人。那么，如果按照原来的逻辑，A可能就需要在原来的代码上做扩展，除了B服务，还要加上日志文件的存储和日志邮件的发送。但是，如果你使用了MQ，那么，A服务是不需要做更改的，它只需要将消息放到MQ 中即可，其它的服务，无论是原来的B服务还是新增的日志文件存储服务或日志邮件发送服务，都直接从MQ中获取消息并处理即可。这就是解耦，它的**好处是提高系统灵活性，扩展性。**
  
- **异步：**可以将一些非核心流程，如日志，短信，邮件等，通过MQ的方式异步去处理。这样做的好处是缩短主流程的响应时间，提升用户体验。
  
- **削峰：**MQ的本质就是业务的排队。所以，面对突然到来的高并发，MQ也可以不用慌忙，先排好队，不要着急，一个一个来。**削峰的好处就是避免高并发压垮系统的关键组件，如某个核心服务或数据库等。**
  

### 消息队列的缺点

- **系统可用性降低：**系统引入的外部依赖越多，越容易挂掉。
  
- **系统复杂度提高：**加入了消息队列，要多考虑很多方面的问题，比如：一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等。因此，需要考虑的东西更多，复杂性增大。
  
- **一致性问题：**A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，这就数据不一致了。
  

### RabbitMQ 是什么？

RabbitMQ 是实现了高级消息队列协议（AMQP）的开源消息代理软件（亦称面向消息的中间件）。RabbitMQ服务器是用Erlang语言编写的，而群集和故障转移是构建在开放电信平台框架上的。所有主要的编程语言均有与代理接口通讯的客户端库。

### RabbitMQ的核心概念

- 生产者和消费者
  
- 消息队列：存放消息的数据结构。多个消费者可以订阅同一队列，这时队列中的消息会被平摊（轮询）给多个消费者进行处理。
  
- 交换机：负责将消息路由到消息队列，当路由不到时，则返回给生产者或直接丢弃。
  

### 交换机有哪些类型

- fanout：消息会转发到所有绑定的队列上
  
- direct：只有RoutingKey和BindingKey完全一样，才会转发到队列
  
- topic：RoutingKey和BindingKey位以"."分隔的字符串，可以用“*”代替一个分隔字符串，用“#”代替多个分隔字符串，从而实现模糊匹配
  
- headers：根据消息中的headers属性信息来进行匹配，该方式性能差
  

### AMQP是什么

一个消息队列协议，RabbitMQ支持并实现了该协议，该协议分为三层：

- Moudle Layer：协议最高层，主要定义了一些客户端调用的命令，客户端可以用这些命令实现自己的业务逻辑。
  
- Session Layer：中间层，负责客户端发送命令给服务端，服务端再返回结果给客户端，提供可靠性同步机制和错误处理
  
- Transport Layer：最底层，主要传输二进制数据流，提供帧的处理、信道服用、错误检测和数据表示等。
  

**AMQP 的模型架构 和 RabbitMQ 的模型架构是一样的，生产者将消息发送给交换器，交换器和队列绑定 。**

### 什么是死信队列，如何导致

当一个消息变成死信后，会将该消息发送到死信交换机，与该交换机绑定的队列就是死信队列

导致死信的几种原因：

- 消息被拒
  
- 消息TTL过期
  
- 消息队列满了
  

### 什么是延迟队列？RabbitMQ 怎么实现延迟队列？

延迟队列指的是，当消息被发送到队列时，无法立即取出，而是过一段设定的时间后才能被取出；有两种实现方式：

- 利用死信队列：设定TTL时间，到时间后被发送到死信队列，消费者从死信队列中消费信息
  
- 使用插件
  

### RabbitMQ 有哪些工作模式？

- 简单模式：没有交换机，一对一
  
- 工作模式：没有交换机，一对多，争抢消息
  
- 发布/订阅模式：有交换机，且fanout类型
  
- 路由模式：有交换机，且directl类型
  
- 主题模式：有交换机，且topic类型
  

### 消费者接收消息过程

1. `Producer`先连接到`Broker`（可以看做RabbitMQ的服务节点。一个Broker可以看做一个RabbitMQ服务器。）,建立连接`Connection`,开启一个信道(`Channel`)。
   
2. 向`Broker`请求消费响应的队列中消息，可能会设置响应的回调函数。
   
3. 等待`Broker`回应并投递相应队列中的消息，接收消息。
   
4. 消费者确认收到的消息,`ack`。
   
5. `RabbitMq`从队列中删除已经确定的消息。
   
6. 关闭信道。
   
7. 关闭连接。
   

### 生产者消息运转的流程

1. `Producer`先连接到Broker,建立连接Connection,开启一个信道(Channel)。
   
2. `Producer`声明一个交换器并设置好相关属性。
   
3. `Producer`声明一个队列并设置好相关属性。
   
4. `Producer`通过路由键将交换器和队列绑定起来。
   
5. `Producer`发送消息到`Broker`,其中包含路由键、交换器等信息。
   
6. 相应的交换器根据接收到的路由键查找匹配的队列。
   
7. 如果找到，将消息存入对应的队列，如果没有找到，会根据生产者的配置丢弃或者退回给生产者。
   
8. 关闭信道。
   
9. 关闭连接
   

### 生产者如何将消息可靠投递到RabbitMQ?

1. Client发送消息给MQ
   
2. MQ将消息持久化后，发送Ack消息给Client，此处有可能因为网络问题导致Ack消息无法发送到Client，那么Client在等待超时后，会重传消息；
   
3. Client收到Ack消息后，认为消息已经投递成功。
   

### RabbitMQ如何将消息可靠投递到消费者？

1. MQ将消息push给Client（或Client来pull消息）
   
2. Client得到消息并做完业务逻辑
   
3. Client发送Ack消息给MQ，通知MQ删除该消息，此处有可能因为网络问题导致Ack失败，那么Client会重复消息，这里就引出消费幂等的问题；
   
4. MQ将已消费的消息删除。
   

### RabbitMQ如何保证消息不丢失（可靠性）

主要从生产者向队列投递消息、消息持久化和消费者消费消息这三个方面来保证消息的可靠性：

- **消息持久化：** RabbitMQ可以设置Exchange和Queue的==持久化参数为true==。当消息发送到RabbitMQ服务器时，消息就会持久化。

- **生产者到MQ：** 生产者发送消息到MQ，无法确保发送的消息成功的到MQ服务器。

  - ==事务机制（不推荐）==。在一条消息发送之后会使发送端阻塞，等待RabbitMQ的回应，之后才能继续发送下一条消息。性能差。

  - ==生产者消息确认机制==，只要消息成功发送到交换机之后，RabbitMQ就会发送一个ack给生产者（~~即使消息没有Queue接收，也会发送ack~~）。如果消息没有成功发送到交换机，就会发送一条nack消息，提示发送失败。

  - **注意：** ACK机制只能保证消息成功发送到交换机，从交换机路由到队列失败的消息，会被丢弃掉。可通过==Return消息机制==和==备份交换机==解决：
    **1）Return消息机制：** 提供了回调函数 ==ReturnCallback==，当消息从交换机路由到Queue失败就会回调这个方法。需要将`spring.rabbitmq.template.mandatory` 设置为 `true` ，才能监听到路由不可达的消息。
    **2）备份交换机：** 额外的一个普通交换机，当发送到交换机的消息没有路由到目标队列，就会自动转移到备份交换机对应的队列。

- **MQ到消费者：** RabbitMQ默认是自动ack，消费者收到消息后自动通知MQ Server消息被处理，MQ 就会移除这条消息。
  因此采用消费者手动ACK，消费者完成业务逻辑之后，手动发送Ack消息给MQ，然后删除消息。**若失败则发送nack，消息重新入队或者进入死信队列。**

- ~~【可忽略】ACK机制（不可以和Confirm一起使用）~~： 为了保证消息从队列可靠地达到消费者，RabbitMQ提供了消息确认机制 （Message Acknowledgement）。消费者在订阅队列时，可以指定autoAck参数来开启==消息确认机制==。当 autoAck参数等于false时，RabbitMQ会等待消费者显式地回复确认信号后才从内存（或者磁 盘）中移除消息（实际上是先打上删除标记，之后在删除）。当autoAck参数等于true时， RabbitMQ会自动把发送出去的消息置为确认，然后从内存（或者磁盘）中删除，而不管消费者 是否真正地消费到了这些消息。
  

### 如何保证 RabbitMQ 消息的顺序性

- 拆分许多的队列， 一个消费者，这样每个队列中都是保证顺序的
  
- 就用一个队列和一个消费者，消费者可以使用多线程处理，然后在代码层面维护顺序
  

### 如何保证RabbitMQ高可用

采取集群，有两种模式：

- 普通模式：队列本身不进行同步，配置信息会同步，当访问某个节点式，可以找到对应队列所在的节点进行转发
  
- 镜像模式：队列本身进行了同步，访问任意节点都能进行完整的操作，操作完要进行所有节点的同步，对网络性能要求较高

## SpringBoot

### 1、Spring Boot 的优点

- 开箱即用，快速构建项目
- 提供默认配置，减少重复开发
- 通过Spring Boot Starter 配置，自动管理依赖关系
- 内嵌Tomcat 服务器，可以方便的开发和测试web 应用
- Spring Boot项目可以打包成**jar** 文件，使用`java -jar` 命令作为独立的Java 应用程序运行
- 提供许多有用的非功能特性，例如安全和健康检查

### 【补充】 Spring 框架中用到了哪些设计模式

**工厂设计模式** : Spring 使用工厂模式通过 `BeanFactory`、`ApplicationContext` 创建 bean 对象。

**代理模式** : Spring AOP 功能的实现。代理模式使得对实际对象的访问由代理对象控制，这对于实现访问控制、延迟加载和其他额外逻辑非常有用。

**单例模式** : Spring 中的 Bean 默认都是单例的。 `ConcurrentHashMap` 作为单例注册表的特殊方式实现单例模式

- 非单例的 **prototype** : 每次获取都会创建一个新的 bean 实例。也就是说，连续 `getBean()` 两次，得到的是不同的 Bean 实例。

  ```java
  // 通过 ConcurrentHashMap（线程安全） 实现单例注册表
  private final Map<String, Object> singletonObjects = new ConcurrentHashMap<String, Object>(64);
  ```

**模板方法模式** : Spring 中 `jdbcTemplate` 这种以 Template 结尾的类，就使用到了模板模式（定义一个操作的骨架，而将一些步骤延迟到子类中）。

**观察者模式:** Spring 事件驱动模型（事件监听）就是观察者模式很经典的一个应用。它定义了一种一对多的依赖关系，当一个对象的状态发生变化时，所有依赖于它的对象都会得到通知并自动更新。

**装饰者模式** : 装饰者模式可以动态地给对象添加一些额外的属性或行为。 Spring 中配置 DataSource 可能是多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。

**适配器模式** : Spring AOP 的增强或通知 (`AdvisorAdapter 接口`) 使用到了适配器模式、spring MVC 中也是用到了适配器模式适配，`DispatcherServlet` ~~（处理客户端请求并将其分发给相应的处理器Controller进行处理）~~通过适配器获取 `Controller`，而避免直接获取需要自行判断类型。

### 【补充】 Spring 对事务的支持

- 编程式事务管理：通过编程的方式管理事务（推荐 `TransactionTemplate` 类实现），这种方式带来了很大的灵活性，但很难维护。
- 声明式事务管理：可以将事务管理和业务代码分离。只需要通过注解（`Transactional`）或者XML配置管理事务。 若要感知业务代码的==事务状态==，可使用事务同步器，他是异步的，在事务提交前后通知到你，只要继承抽象类 `TransactionSynchronizationAdapter` ，重写 afterCommit() 或 afterCompletion(int status) 方法。
	- ==实现原理：== 通过 Spring AOP 内置了一个切面，并且在事务方法前后织入了事务管理的操作，比如开启事务，提交，回滚。TransactionInterceptor 就是Spring内部定义的一个处理数据库事务的切面，拦截到 @Transaction 注解的方法时，会触发 invokeWithinTransaction 方法执行，通过try catch 执行回滚或者提交本次事务。

### 拓展：事务失效的情况
- 没有指定监听的 Exception（默认只 RuntimeException），一般使用 roobackFor属性指定需要捕获的异常。
- 内部调用：使用一个没有事务的方法调用一个有事务的方法，失败后不会进行回滚。
- 方法内部异常被捕获没有抛出。
- 被注解的方法非 public：这是因为在 `AbstractFallbackTransactionAttributeSource` 类的 `computeTransactionAttribute` 方法中有个判断，如果目标方法不是 public，则`TransactionAttribute` 返回 null （空) ，即不支持事务。
- 方法对应的类未被 Spring 管理：Spring在依赖查找的时候，是从BeanFactory中取出需要被代理的类，也就是说，事务生效的前提是，对象要被Spring管理。我们通过可以使用`@Service`、`Component`、`@Repository`等来实现Bean的依赖注入。
- 跨线程调用：当两个方法在不同的线程中，那么它们获取到的数据库连接也是不一样的，这就导致，这两个方法在不同的事务中。

- 事务传播规则
	- PROPAGATION_REQUIRED: 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。
	- PROPAGATION_SUPPORTS: 支持当前事务，如果当前没有事务，就以非事务方式执行。
	- PROPAGATION_MANDATORY: 支持当前事务，如果当前没有事务，就抛出异常。
	- PROPAGATION_REQUIRES_NEW: 新建事务，如果当前存在事务，把当前事务挂起。
	- PROPAGATION_NOT_SUPPORTED: 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。
	- PROPAGATION_NEVER: 以非事务方式执行，如果当前存在事务，则抛出异常。
	- PROPAGATION_NESTED: 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与 PROPAGATION_REQUIRED 类似的操作。
- 基础：事务的特性（事务定义：定义一系列操作，这些操作要么全部完成，要么全部失败）
	- 原子性：指一个事务中的所有操作要么全部执行，要么全部不执行。若在事务中某个操作执行失败，则事务回滚到初始状态。
	- 一致性：指事务前后，数据满足完整性约束，数据库保持一致性状态。
	- 隔离性：数据库支持多个事务对数据库进行操作，各个事务有自己的隔离空间， 互相不干扰。
	- 持久性：事务对数据的修改是永久的。

### 2、SpringBoot的启动流程

总体分为两个阶段：

- 构造SpringApplication 的实例：
  1. 将启动类添加到SpringApplication的属性当中
  2. 获取应用类型并判断是否是web工程，设置到属性中
  3. 创建并初始化所有的初始化器，添加到initializers属性中
  4. 创建并初始化所有的监听器，添加到listeners属性中
  5. 初始化主类mainApplicationClass
- 调用run 方法：
  1. 获取监听器及参数配置，并启动
  2. 打印banner信息
  3. 创建并初始化容器
  4. 监听器发送通知告知启动完成

### 【重点】 SpringBoot 循环依赖

循环依赖是指在Spring Boot ，两个或多个类之间存在彼此依赖的情况，形成一个循环依赖链。

在这种情况下，当一个类在初始化时需要另一个类的实例，而另一个类又需要第一个类的实例时，就会出现循环依赖问题。这会导致应用程序无法正确地初始化和运行，因为Spring Boot 无法处理这种循环依赖关系。

在2.6.0之前，Spring Boot会自动处理循环依赖的问题。2.6.0及之后的版本会默认检查循环依赖，存在该问题则会报错

**解决办法是三级缓存机制：** 当**A**的**bean**需要**B**的**bean**的时候，提前将**A**的**bean**放在缓存中（实际是将**A**的**ObjectFactory**放到三级缓存），然后再去创建**B**的**bean**，但是**B**的**bean**也需要**A**的**bean**，那么这个时候就去缓存中拿**A**的**bean**，**B**的**bean**创建完毕后，再回来继续创建**A**的**bean**，最终完成循环依赖的解决。

注：**ObjectFactory** 是一个接口，通过getObject() 方法间接调用createBean() 返回一个对象实例。

### 3、Spring Boot Starters

Starters可以理解为启动器，它包含了一系列可以集成到应用里面的依赖包，属于依赖关系的集合，例如spring-boot-statrs-web，包含了springMVC、Tomcat、Jackson等依赖，解决了依赖配置复杂的问题

其他还有：spring-boot-statrs-jdbc、spring-boot-statrs-test、spring-boot-statrs-security

### 4、Spring Boot Starter 的工作原理是什么【自动装配过程】

Spring Boot 在启动的时候会干这几件事情：

- Spring Boot 在启动时会去依赖的 Starter 包中寻找 resources/META-INF/spring.factories 文件，然后根据文件中配置的 Jar 包去扫描项目所依赖的 Jar 包。
- 根据 spring.factories 配置加载 AutoConfigure 类
- 根据 @Conditional 注解的条件，进行自动配置并将 Bean 注入 Spring Context

总结一下，其实就是 Spring Boot 在启动的时候，按照约定去读取 Spring Boot Starter 的配置信息，再根据配置信息对资源进行初始化，并注入到 Spring 容器中。这样 Spring Boot 启动完毕后，就已经准备好了一切资源，使用过程中直接注入对应 Bean 资源即可

### 5、Spring Boot 的核心注解是哪个？它主要由哪几个注解组成的？

核心注解是启动类上面的`@SpringBootApplication`，主要组合包含了以下 **3** 个注解：

- `@SpringBootConfiguration`：组合了 @Configuration 注解，实现配置文件的功能。
- `@EnableAutoConfiguration`：打开自动配置的功能，也可以关闭某个自动配置的选项，如关闭数据源自动配置功能： @SpringBootApplication(exclude = { DataSourceAutoConfiguration.class })。
- `@ComponentScan`：扫描该所在包下的所有组件

### 【补充】常用注解


### 6、Spring Boot 中如何实现对不同环境的属性配置文件的支持？

Spring Boot支持不同环境的属性配置文件切换，通过创建`application-{profile}.properties`文件，其中{`profile`}是具体的环境标识名称，例如：application-dev.properties用于开发环境，application-test.properties用于测试环境，application-uat.properties用于uat环境。如果要想使用application-dev.properties文件，则在`application.properties`文件中添加`spring.profiles.active=dev`。

### 7、Spring 、Spring Boot 和 Spring Cloud 的关系?

Spring 两大最核心的功能是Spring IoC 和Spring AOP

Spring Boot 是基于约定大于配置的理念，简化Spring 的开发，避免复杂的依赖配置

Spring Cloud 是一系列框架的有序集合。她利用Spring Boot 的开发便利性巧妙地简化了分布式系统设施的开发，如**服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控**等，都可以用Spring Boot 的开发风格做到一键启动和部署。

Spring Cloud 是为了解决微服务架构中服务治理而提供的一系列功能的开发框架，并且 Spring Cloud 是完全基于 Spring Boot 而开发，Spring Cloud 利用 Spring Boot 特性整合了开源行业中优秀的组件，整体对外提供了一套在微服务架构中服务治理的解决方案。

### 8、什么是Spring IoC？

**IoC（Inversion of Control:控制反转）** 是一种设计思想，而不是一个具体的技术实现。IoC 的思想就是将原本在程序中手动创建对象的控制权，交由 Spring 框架来管理。

- 控制：指的是对象创建（实例化、管理）的权力
- 反转：将控制权交给外部环境（Spring 框架、IoC 容器）

**作用：**将对象之间的相互依赖关系交给IoC 容器来管理，并由IoC 容器完成对象的注入。即创建一个对象的时候，只需要配置好配置文件/注解即可，完全不用考虑对象是如何被创建出来的。从而简化应用的开发

### 9、什么是Spring AOP？

AOP 表示面向切面编程，将那些与业务无关，却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来，从而降低模块间的耦合度，并有利于未来的可拓展性和可维护性。

Spring AOP 是基于动态代理实现的，如果要代理的对象，实现了某个接口，那么 Spring AOP 会使用 **JDK Proxy** 去创建代理对象，而对于没有实现接口的对象， Spring AOP 会使用 **CGlib** 生成一个被代理对象的子类来作为代理

**【补充】如何使用AOP**

**使用方法一** ：==通过自定义注解==

1、创建自定义注解（例如 public @interface ApiOperationLog）。用于标记需要进行AOP处理的方法或类。注解可以包含一些描述信息。

2、创建AOP切面，加上@Aspect @Component注解。通过注解==@Pointcut(xxx.ApiOperationLog)==定义一个切点方法MyPoint()。选择在切点前@Before，切点后@After或者环绕（切点前后都执行）@Around使用对应注解实现方法的切面逻辑。

3、在需要AOP的方法或类上使用自定义注解（@ApiOperationLog）~~（SpringBoot会默认启用AOP，启动类上使用@EnableAspectJAutoProxy开启AOP）~~

使用方法二：==指定包中的所有方法==

1、创建一个切面类（@Aspect @Component），比如定义一个切点前方法织入代码逻辑，通过注解@Before("execution(* com.example.service.*.*(..))")

2、指定包中的所有方法执行前都会执行织入的代码逻辑。

### 10、什么是Spring Bean？

Bean 代指的就是那些被 IoC 容器所管理的对象（类，方法）

**Bean 是线程安全的吗？**

对于`prototype` 作用域下，每次获取都会创建一个新的Bean 实例，不存在资源竞争问题，是线程安全的。

`singleton`作用域下，大部分情况下Bean 都是**无状态**的（即没有定义可变的成员变量，比如Dao、Service），此时Bean 是线程安全的。

对于**有状态的单例Bean**的线程安全问题，常见有两种解决方案：

- 在Bean 中尽量避免定义可变的成员变量
- 在类中定义一个**ThreadLocal**成员变量来保存变量**（==推荐！！==）**

### 11、一个类声明为Bean 的注解有哪些？

- `@Component`：通用的注解，可标注任意类为 `Spring` 组件。如果一个 Bean 不知道属于哪个层，可以使用`@Component` 注解标注。
- `@Repository` : 对应持久层即 Dao 层，主要用于数据库相关
- `@Service` : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao 层
- `@Controller` : 对应 Spring MVC 控制层，主要用于接受用户请求并调用 `Service` 层返回数据给前端页面。

### 12、@Componet 和@Bean 的区别是什么？

- `@Component` 注解作用于类，而`@Bean`注解作用于方法

- `@Component`通过类路径扫描自动装配到容器中，而`@Bean`一般在方法中自定义产生bean然后提交给容器
- 有些场景，比如引用第三方库中的类需要装配到Spring 容器时，只能通过`@Bean`实现 

### 13、Bean 的作用域有哪些?

Spring 中 Bean 的作用域通常有下面几种：

- **singleton** : IoC 容器中只有唯一的 bean 实例。Spring 中的 bean 默认都是单例的，是对单例设计模式的应用。
- **prototype** : 每次获取都会创建一个新的 bean 实例。也就是说，连续 `getBean()` 两次，得到的是不同的 Bean 实例。
- **request** （仅 Web 应用可用）: 每一次 HTTP 请求都会产生一个新的 bean（请求 bean），该 bean 仅在当前 HTTP request 内有效。
- **session** （仅 Web 应用可用） : 每一次来自新 session 的 HTTP 请求都会产生一个新的 bean（会话 bean），该 bean 仅在当前 HTTP session 内有效。
- **application/global-session** （仅 Web 应用可用）：每个 Web 应用在启动时创建一个 Bean（应用 Bean），该 bean 仅在当前应用启动时间内有效。
- **websocket** （仅 Web 应用可用）：每一次 WebSocket 会话产生一个新的 bean

### 14、Bean 的生命周期了解吗？

1、Bean 容器找到配置文件中Spring Bean 的定义，并利用反射创建实例
2、根据涉及的对象属性调用方法（如`set()`）设置属性值
3、检查实现的相关`*.Aware` 接口（如`BeanNameAware`，调用`setBeanName()`）调用相应的方法设置依赖
4、调用BeanPostProcess的前置初始化方法postProcessBeforeInitialization，主要作用是在Spring完成实例化之后，初始化之前，对Spring容器实例化的Bean添加自定义的处理逻辑。有点类似于AOP。
5、如果实现`InitializingBean`接口的afterPropertiesSet方法，做一些属性被设定后的自定义的事情。 
6、检查是否配置了Bean的inti-method方法并执行去做一些初始化相关的工作
7、调用`BeanPostProcessor`的后置初始化方法，做一些bean初始化之后的自定义工作。
8、完成以上创建之后就可以在应用里使用这个Bean。
9、当Bean不再用到，便要销毁 1）若实现了DisposableBean接口，则会调用destroy方法； 2）若配置了destry-method属性，则会调用其配置的销毁方法

### 15、什么是MVC

一种设计思想。模型、视图、控制器的缩写。其核心思想是将业务逻辑、数据、显示进行分离

Spring MVC 是一款MVC 框架，Spring MVC下我们一般把后端项目分为 Service 层（处理业务）、Dao 层（数据库操作）、Entity 层（实体类）、Controller 层(控制层，返回数据给前台页面)。

### 16、Spring MVC 的核心组件有哪些？

- **`DispatcherServlet`**：**核心的中央处理器**，负责接收请求、分发，并给予客户端响应。
- **`HandlerMapping`**：**处理器映射器**，根据 uri 去匹配查找能处理的 Handler，并会将请求涉及到的拦截器和Handler 一起封装。
- **`HandlerAdapter`**：**处理器适配器**，根据 `HandlerMapping` 找到的 `Handler` ，适配执行对应的 `Handler`；
- **`Handler`**：**请求处理器**，处理实际请求的处理器。
- **`ViewResolver`**：**视图解析器**，根据 `Handler` 返回的逻辑视图 / 视图，解析并渲染真正的视图，并传递给 `DispatcherServlet` 响应客户端

### 17、Spring MVC 工作原理
流程说明（重要）：
1、客户端（浏览器）发送请求，直接请求到 `DispatcherServlet`。
2、`DispatcherServlet` 根据请求信息调用 `HandlerMapping`，解析请求对应的 `Handler`。
3、解析到对应的 `Handler`（也就是我们平常说的 `Controller` 控制器）后，开始由 `HandlerAdapter` 适配器处理。
4、`HandlerAdapter` 会根据 `Handler`来调用真正的处理器开处理请求，并处理相应的业务逻辑。
5、处理器处理完业务后，会返回一个 `ModelAndView` 对象，`Model` 是返回的数据对象，`View` 是个逻辑上的 `View`。
6、`ViewResolver` 会根据逻辑 `View` 查找实际的 `View`。
7、`DispaterServlet` 把返回的 `Model` 传给 `View`（视图渲染）。
8、把 `View` 返回给请求者（浏览器）

### 拦截器和过滤器的区别
过滤器和拦截器在功能上有一定的重叠，==过滤器（Filter）==可以处理任何 Web 应用的请求，不局限于 Spring。==拦截器（Interceptor）==更紧密地集成在 Spring MVC 中，实际使用中在==实现方式==，==处理层级==和==使用场景==上有所不同。
**实现方式：**
- 过滤器需要实现 javax.servlet.Filter 接口，并实现 init、doFilter 和 destroy 方法。
- 拦截器需要实现 HandlerInterceptor 接口（对于请求拦截）或 ClientHttpRequestInterceptor 接口（对于客户端请求拦截）。

**处理层级：**
- 过滤器基于 Java Servlet 规范，在 Servlet 容器级别处理请求。在请求到达 Spring 应用的任何其他组件之前，都会先经过过滤器处理。
- 拦截器是 Spring MVC 的一部分，用于处理 Spring 应用中接收到的请求。拦截器在 Spring 处理请求的过程中起作用，位于过滤器之后。

**使用场景：**
- 过滤器用于实现通用的、与框架无关的功能，如身份验证、授权、日志记录、请求和响应的数据转换等。
- 拦截器通常用于实现与 Spring 框架相关的功能，如验证用户身份、授权、请求参数处理、异常处理等。

## 项目

### 技术栈
SpringBoot，SpringCloud，MySQL，MyBatis-Plus，Redis，MinIO，XXL-JOB，RabbitMq，Elasticsearch
- **parent** 项目对依赖版本统一控制
- **base** 项目提供公用的工具类、架构基础类库（包括异常处理器，日期格式配置）
- **api** 模块为接口工程，对外提供访问接口
- **service** 模块为业务工程，处理业务
- **model** 模块为数据模型工程，提供存储数据模型类（PO）,数据传输模型类（DTO）

### 微服务远程调用
**Feign** 
1、以内容服务为例，在运行类中添加 Feign 注解
```java
@EnableFeignClients(basePackages={"com.xuecheng.content.feignclient"});
```

2、创建 MediaServiceClient 接口，在接口中与 Controller 一样编写请求方法。并添加注解
```java
@FeignClient(value = "media-api",fallbackFactory = MediaServiceClientFallbackFactory.class)
public interface MediaServiceClient {  
    @RequestMapping(value = "/media/upload/coursefile", consumes = MediaType.MULTIPART_FORM_DATA_VALUE)  
    public String upload(@RequestPart("filedata") MultipartFile filedata,  
                                      @RequestParam(value = "objectName", required = false) String objectName) throws IOException;   
}
```
3、熔断降级
- 熔断：当下游服务异常而断开与上游服务的交互，它就相当于保险丝，下游服务异常触发了熔断，从而保证上游服务不受影响。
- 降级：当下游服务异常触发熔断后，上游服务就不再去调用异常的微服务而是执行了降级处理逻辑，这个降级处理逻辑可以是本地一个单独的方法。

上述接口注解内指定 `fallbackFactory`，定义如下：
```java
@Component
public class MediaServiceClientFallbackFactory implements FallbackFactory<MediaServiceClient> {
    @Override
    public MediaServiceClient create(Throwable throwable) {
        return new MediaServiceClient(){
            @Override
            public String uploadFile(MultipartFile upload, String folder, String objectName) {
                log.error("远程调用媒资管理服务熔断异常：{}",throwable);
                return null;
            }
        };
    }
}
```
对于触发熔断，上游服务调用降级逻辑：
```java
public class MediaServiceClientFallback implements MediaServiceClient {   
    @Override  
    public String upload(MultipartFile filedata, String objectName) throws IOException {  
        return null;  
    }  
}
```

### 全局异常处理
```java
@Slf4j
@ControllerAdvice  // 增强控制器，用于处理全局数据
public class GlobalExceptionHandler {
   @ResponseBody
   @ExceptionHandler(XueChengPlusException.class)  // 用来表明方法的处理异常类型
   @ResponseStatus(HttpStatus.INTERNAL_SERVER_ERROR)  // 用状态代码和应返回的原因标记方法或异常类
   public RestErrorResponse customException(XueChengPlusException e) {
      log.error("【自定义异常】{}",e.getErrMessage(),e);
      return new RestErrorResponse(e.getErrMessage());
   }

   @ResponseBody
   @ExceptionHandler(Exception.class)
   @ResponseStatus(HttpStatus.INTERNAL_SERVER_ERROR)
   public RestErrorResponse exception(Exception e) {
      log.error("【系统异常】{}",e.getMessage(),e);
      return new RestErrorResponse(CommonError.UNKOWN_ERROR.getErrMessage());
   }
}
```


### 【重点1】第三方认证登录（OAuth2+JWT）
### ===============

**负责第三方认证登录模块的开发，基于OAuth2 协议实现微信扫码认证，简化了用户注册和登录的操作流程。**

**OAuth2：**是一种开放标准的授权协议，用于授权第三方应用程序访问受保护资源的权限。它允许用户在不直接向第三方应用程序共享凭据的情况下，通过令牌的方式授权第三方应用程序代表用户访问受保护的资源。

**JWT（JSON Web Token）：**JWT是一种使用JSON 格式传递数据的网络令牌技术。JWT 在不需要服务器端存储会话数据的情况下，实现无状态的身份验证和授权。

**实现流程**

1、浏览器生成二维码请求用户确认，用户扫码确认后，认证服务获得==微信授权码==。

2、认证服务使用获得的授权码，调用微信的接口（API）向微信开放平台申请令牌，微信根据授权码颁发令牌。

3、认证服务通过令牌从微信开放平台获取用户信息，然后将该信息保存在数据库（自动注册）。

4、用户自动登录后，同时会向服务端申请本网站的JWT 令牌。

5、服务端（认证服务）根据用户信息生成一个==本网站的JWT 令牌==返回给客户端。

6、客户端将JWT 令牌存储在本地，后续通过该令牌进行认证。

![image-20230817215841897](https://java-1259004241.cos.ap-shanghai.myqcloud.com/typora/202308172158981.png)



### 1.1 JWT 为什么可以防止篡改？

~~JWT是一种使用JSON 格式传递数据的网络令牌技术。JWT 在不需要服务器端存储会话数据的情况下，实现无状态的身份验证和授权。~~

JWT令牌由三部分组成，~~每部分中间使用点（.）分隔，比如：xxxxx.yyyyy.zzzzz~~

Header头部包括令牌的类型（即JWT）及使用的哈希算法（如==HMAC SHA256==或RSA）

Payload负载是一个json对象，它是==存放内容字段==的地方，比如：iss（签发者）,exp（过期时间戳）, sub（面向的用户）等，也可自定义字段。此部分用于解码还原原始内容，因此不要存放敏感信息。

Signature签名，zhe部分用于防止jwt内容被篡改。该部分使用签名算法对第一部分和第二部分的内容进行签名，常用的签名算法是 HS256。签名算法需要使用密钥进行签名，密钥不对外公开，并且签名是不可逆的，如果第三方更改了内容那么服务器验证签名就会失败，要想保证验证签名正确必须保证内容、密钥与签名前一致。

### 1.2 如何生成JWT令牌

**生成过程：**

1、通过JWT库（本项目是 jjwt，默认HMAC SHA256加密），创建一个 JWT 工具类，专门用于生成和验证 JWT 令牌

2、**在登录成功后**）生成令牌的时候需要设置签发人，密钥、过期时间，还有额外==存放的字段信息==（这里是用户名）。

3、使用生成器的 `signWith` 方法对JWT令牌进行签名，通常使用HMAC算法或RSA算法，然后返回给客户端。

> 用途不同：HMAC 主要用于验证消息的完整性和来源，而RSA 用于加密、解密、数字签名和密钥交换。
>
> 工作原理不同：HMAC 使用密钥对消息进行哈希，然后验证哈希值；RSA 使用一对公钥和私钥进行加密、解密和数字签名。
>
> 安全性不同：HMAC 的安全性依赖于密钥的保密性，RSA 的安全性基于数学问题的复杂性，要求足够长的密钥长度以保证计算的复杂性。

**验证过程：**

1、当服务器接收到JWT令牌后，使用JWT验证器来解析JWT令牌并验证其签名。这个过程包括以下步骤：

- 解析JWT令牌，将其拆分为头部、负载和签名部分。
- 使用相同的密钥（或公钥）和签名算法来验证签名是否匹配。

2、如果签名验证成功且令牌没有过期，服务器将信任令牌并允许访问受保护的资源。如果验证失败或令牌已过期，服务器将拒绝访问请求。

3、根据需要，还可以从JWT的负载中提取额外信息，例如用户名或其他信息，以便进行进一步的授权和身份验证。



### 【重点二】使用网关集中认证（Spring Gateway）
### ===============

负责网站认证授权模块的开发，通过构建认证授权分离的服务架构，确保非法请求在网关阶段被拦截，降低了下游服务的访问负担。

**实现流程**

1、**网站白名单维护：**针对不需要认证的URL全部放行（如课程信息、试学内容）

2、**校验JWT令牌的合法性：**在网关服务中配置认证过滤器，通过实现==GlobalFilter接口==（Spring Gateway中的接口，重写filter方法的拦截逻辑）完成白名单放行、令牌是否合法、是否过期。

3、**服务具体授权：**微服务会对每个==接口指定权限标识符==。认证服务在生成JWT令牌时会查询用户的权限，然后将对应的权限标识符写入令牌的负载（一个Json对象），当用户满足服务中接口的权限要求时，可正常访问，否则提示”无操作权限“。

```java
@ApiOperation("课程分页查询接口")
@PreAuthorize("hasAuthority('xc_teachmanager_course_list')")
@PostMapping("/course/list")
public PageResult<CourseBase> list(PageParams pageParams, @RequestBody(required=false) QueryCourseParamsDto queryCourseParamsDto) {
    ...
}
```

**用户授权** ：RBAC分为两种方式 ：

- 基于角色的访问控制（Role-Based Access Control）

- 基于资源的访问控制（Resource-Based Access Control）

我们这里是基于资源的访问控制进行授权的，这种授权方式是细粒度授权，后续的可扩展性好。具体实现是在各服务的接口处添加授权注解，指定该接口需要的权限级别，这里的权限级别是通过角色表，角色权限表，权限字典表进行维护的。



### 【重点三】文件管理模块开发（断点续传）
### ===============

负责文件管理模块的开发，针对视频大文件实现秒传、断点续传、分片上传的功能，改善用户在发生异 常情况下的传输体验。

**实现流程**

1、**检查分块：**前端（js代码）首先计算文件的md5值作为文件的唯一标识，然后将文件做一个分块并标记序号。完成分块后，前端首先会请求后端依次查询各个分块文件是否已经上传过了，后端会去MinIO中进行检查。

2、**上传分块：**如果分块已经被上传，那么前端就跳过这个分块的上传，如果没有上传的话就会上传该分块。后端接收到文件后，会对文件进行解析（存储在本地的临时路径下），根据MinIO的规则设置文件名和路径，然后调用MinIO的API进行文件的上传。

3、**合并分块：**当前端确认所有分块都已经上传成功后，就会向后端发送一个合并分块的请求。后端收到请求后，就会调用MinIO的API对分块文件进行合并。

4、**完整性校验：**合并完文件后计算md5值与前端传给我们的进行比较是否一致来确定文件是否完整，如果不完整则删除文件并抛出异常。



### 【重点四】MySQL 读写分离（主从复制+索引优化）
### ===============

 基于MySQL 的主从复制实现数据库的读写分离，并通过对部分数据表进行索引优化，极大提高了系统 整体的查询性能。

**实现流程**

1、配置主从数据库，通过命令开启从库对主库binlog 日志的接收，这里使用的是==半同步复制模式==（主库开启）。

2、**写入binlog：**MySQL 主库在收到客户端提交事务的请求之后，会先写入binlog 日志传给从库。主库收到从库复制成功响应，再提交事务返回客户端`操作成功`的响应。

3、**同步binlog：**从库会有一个专门的I/O线程去接收主库的binlog 日志，把binlog信息写入relay log的中继日志后，返回主库`复制成功`的响应。

4、**回放binlog：**从库通过一个专门的线程读取relay log 中继日志，然后回放binlog更新数据，最终实现主从的数据一致性。

5、完成主从复制之后，具体到服务就可以在写数据时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响读请求的执行。

![img](https://java-1259004241.cos.ap-shanghai.myqcloud.com/typora/202308181342717.jpeg)



### 【重点五】热点数据二级缓存（Redis+Caffeine）
### ===============
热点数据使用Redis+Caffeine 的两级缓存方案，解决了缓存击穿和穿透问题，本地缓存避免了请求Redis 的网络开销，查询速度进一步提高。

==缓存击穿：== `Caffeine`默认使用异步机制加载缓存数据，可有效防止缓存击穿（防止同一个key或不同key被击穿的场景）

==缓存穿透：== 对于不存在的key 缓存空值，~~或者使用布隆过滤器~~

**实现流程**

1、Spring中的`Cache `接口规范了缓存组件的定义，包括get、put、evict、clear等缓存的操作方法。我们创建一个**`DoubleCache`**类 继承`AbstractValueAdaptingCache `抽象类，然后实现对缓存的具体操作。

2、创建一个**`DoubleCacheManager`**类 实现`CacheManager接口`，用来管理缓存实例，根据不同的cacheName 生成对应的缓存对象。

3、当发出一个查询请求时，会先访问本地缓存，如果不存在则继续访问Redis缓存，如果还不存在则直接从数据库读取，再依次进行缓存；否则直接读取到缓存结果返回。

<font color = red>注意1：</font> ① AbstractValueAdaptingCache **实现了Cache 接口**，是对Cache 接口的封装

​		   ② 在get() 方法中通过==ReentrantLock==进行了加锁操作，确保在并发访问场景下缓存时不存在只进行一次更新。

<font color=red>注意3：</font>① 当数据更新后，采用==先更新数据库后删除缓存==的策略，以保证数据一致性，同时一定要给==缓存加过期时间==，避免后续的删除缓存未执行，读取的都是就缓存数据！

### 5.1 【补充】解决缓存击穿&缓存穿透

**==缓存击穿：==**

缓存中的**某个热点数据过期**了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮

**解决方案：**

- ==ReentrantLock==互斥锁方案，保证**同一时间**只有**一个业务线程**去构建缓存，当构建完成后再释放锁。未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值（**互斥锁最好设置超时时间，避免该请求拿到锁后，因为某种意外一直不释放锁，导致阻塞**）。
- 不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；

**==缓存穿透：==**

用户访问的数据，**既不在缓存中，也不在数据库中**，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，**没办法构建缓存数据，来服务后续的请求。**那么当有大量这样的请求到来时，数据库的压力骤增。

**解决方案：**

- 加强格式检查，拦截无效请求
- 不存在的数据缓存空值或默认值，后续请求就可以从缓存中读取到空值或者默认值，返回给应用，避免查询数据库；
- 使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在；

**注意：** *查询布隆过滤器说数据存在，并不一定证明数据库中存在这个数据，但是查询到数据不存在，数据库中一定就不存在这个数据*（基于哈希函数，可能存在哈希冲突）。

### 5.2 【难点】数据库和缓存如何保证一致性

由于引入了缓存，那么在数据操作时，就可能碰到数据库和缓存中的数据不一致的问题。

最开始采用的是==先更新数据库，再更新缓存==，代码写好后做压测发现QPS确实有几倍的提升，后来专门看了Redis 并发的内容，发现需要重点关注==并发问题==。

**可能的并发问题: ** 比如有A、B两个请求，同时更新「同一条」数据，A 请求先将数据库的数据更新为 1，然后在更新缓存前，B 请求将数据库的数据更新为 2，紧接着把缓存更新为 2，最后 A 请求更新缓存为 1，

这个时候数据库中的数据是 2，而缓存中的数据却是 1，**出现了缓存和数据库中的数据不一致的现象**。

**解决方案：** 然后比较推荐的方案是 ==旁路缓存策略==（Cache Aside），就是==先更新数据库，再删除缓存==，Cache Aside 主要分为读策略和写策略两种：

**读策略：** （比较简单）

- 如果读取的数据命中了缓存，则直接返回数据；
- 如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户。

**写策略：**

- 先更新数据库中的数据；
- 然后删除缓存中的数据。

因为缓存的写入要比数据库的写入快得多，所以理论上很少出现一个线程已经更新了数据库然后删除了缓存，另一个线程才更新完缓存的情况

### 5.3 【集群拓展】如何应对主从数据不一致

之所以会出现主从数据不一致的现象，是**因为主从节点间的命令复制是异步进行的**，所以无法实现强一致性保证（主从数据时时刻刻保持一致）。

具体解释： ~~主节点收到新的写命令后，会发送给从节点。但是，主节点并不会等到从节点实际执行完命令后，再把结果返回给客户端，而是主节点自己在本地执行完命令后，就会向客户端返回结果了。如果从节点还没有执行主节点同步过来的命令，主从节点间的数据就不一致了。~~

**应对方案：** 

- 第一种方法，将主从节点放在同一机房里，尽量保证主从节点间的网络连接状况良好。
- 第二种方法，通过监控主从节点间的复制进度，来决定是否从某一从节点读取数据：
  - Redis 的 INFO replication 命令可以查看主节点接收写命令的进度信息（master_repl_offset）和从节点复制写命令的进度信息（slave_repl_offset），通过计算主从节点的复制进度差值，如果进度差值大于设定的阈值，就暂时不从这个节点读取数据，这样能减少主从读取数据不一致的情况。


### 【补充】微服务基础

微服务架构主要是根据业务模块将原本的单体应用拆分为更加细粒度的服务，（~~所拆分的每一个服务都是一个独立的应用，这些应用对外提供公共的API，可以独立承担对外服务的职责~~)，从而降低系统的耦合性，并提供更加灵活的服务支持。

- **微服务架构的优点**
	- 面向特定业务开发：基于业务对系统进行拆分，使得每个微服务都专注于特定功能模块，并通过公共的 API 对外提供服务，不用考虑业务功能的交叉，提高开发效率。
	- 可独立部署：单个微服务应用有独立进程，当某个微服务发生变更，无需像单体应用编译、部署整个应用。
	- 容错性高：当某个业务服务发送故障，可通过服务熔断（Sentinel）将故障隔离在单个服务中，其他服务仍然可以对外提供访问，不至于让整个系统挂掉。
	- 提高对外服务能力：可根据业务的特点将微服务部署在不同规模的服务器上，有效提高服务器的使用效率和服务能力。
	- 技术选型灵活：每个微服务对应的团队可以根据业务特性和团队情况，选择合适的技术实现。（~~由于对整个系统进行拆分，对当前微服务进行技术升级的成本也更低~~）
- **缺点**
	- 增加系统的复杂性：虽然特定的微服务变得更简单，却要处理更加复杂的分布式系统，包括服务间的通信（Http，==Dubbo==->RPC），服务治理，分布式事务管理和数据一致性。
	- 增加测试和部署的难度：保证众多服务之间的依赖，需要对应人员有更高的技术水平。
	- 增加团队间的协作成本：因为各个微服务之间是交互的，因此需要对应的团队进行协调开发。
	- 增加服务器开销：每个微服务都运行在自己的 JVM 中，因此有额外的内存开销和网络传输开销。
- **微服务拆分**
	- 数据库拆分：数据库按照业务垂直拆分，也就是业务数据隔离，降低慢SQL影响整个系统的风险。
	- 应用拆分：应用按照业务功能垂直拆分。
	- 数据访问权限收口：数据权限按照各自业务领域，归属到各自的应用，将应用与数据库一一对应，禁止交叉访问。
- **微服务框架Spring Cloud Alibab 常用组件**
	- Nacos：动态服务发现、配置管理和服务管理平台。
	- Sentinel：以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保障系统稳定。
	- RocketMQ：阿里开源的分布式消息系统，提供低延迟、高可靠的消息发布与订阅服务。
	- Seata：分布式事务解决方案。
	- 非核心组件
	- OpenFeign：轻量级 Restful 的 Http 服务客户端，用于服务间远程调用。 [深入理解 OpenFeign 的架构原理 (qq.com)](https://mp.weixin.qq.com/s/7EJTSw5WGE5bYbo00nZ4jA)
	- GateWay：用于网关服务，实现请求的转发和路由。
	- Ribbon：用于客户端负载均衡和故障转移，将请求分发给不同微服务实例。（LoadBalancer，SpringCloud提供的负载均衡组件）

### 【补充】分布式CAP 理论

**==CAP 理论：==** 指的是在一个分布式系统中， Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可得兼。

- 一致性（C）：在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）
- 可用性（A）：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据更新具备高可用性）
- 分区容错性（P）：系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在 C 和 A 之间做出选择。

**一般分布式系统中，肯定是优先保证 P，剩下的就是 C 和 A 的取舍**

==**BASE 理论：**== Basically Available（基本可用）、Soft state（软状态）和 Eventually consistent（最终一致性）的简写。是对 CAP 中一致性和可用性权衡的结果，其核心思想是即使无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性。

==**Nacos 中关于CAP 的实现：**== Nacos保证了P，**官方推荐使用A，即AP，保证其高可用**，如果发现连接失败，则会自动切换至其他的节点，只要有一台还在，就能保证注册服务可用（保证可用性），只不过查到的信息可能不是最新的（不保证一致性）


###  【补充】分布式事务

- **本地消息表**
	本地消息表其实就是利用了 **各系统本地的事务** 来实现分布式事务。
	即在数据库中创建一张消息表，然后在执行业务的时候 **将每个业务的执行和对应的消息写表操作放在同一个事务中**，这样就能保证消息放入本地表中业务肯定是执行成功的。
	如果本次调用失败，再通过 **xxl-job 后台任务定时去读取本地消息表**，筛选出还未成功的消息再调用对应的服务，若业务代码执行成功了就变更对应消息的状态。
	否则重试，重试就得保证对应服务的方法是幂等的，重试超过最大次数可以记录下报警让人工处理。
	
	可以看到本地消息表其实实现的是**最终一致性**，容忍了数据暂时不一致的情况。

	- 本项目中的分布式事务方案：
		本项目在课程发布时，执行课程发布操作后要往MySQL、Redis、Elasticsearch、MinIO 写四份数据，在这个场景中我们优先选择AP！
		
		课程发布操作后，先更新数据库中的课程发布状态，更新后向redis、elasticsearch、MinIO写课程信息，只要在一定时间内最终向redis、elasticsearch、MinIO写数据成功即可。结合任务xxl-job 调度技术实现课程发布中的分布式事务控制，具体流程为：

		1、在内容管理服务的数据库中添加一个消息表，消息表和课程发布表在同一个数据库。
		2、点击课程发布通过本地事务向课程发布表写入课程发布信息，同时向消息表写课程发布的消息。通过数据库进行控制，只要课程发布表插入成功消息表也插入成功，消息表的数据就记录了某门课程发布的任务。
		3、启动任务调度系统定时调度内容管理服务去定时扫描消息表的记录。==通过== 任务处理类 CoursePublishTask（继承`MessageProcessAbstract抽象类`）中，`@XxlJob("CoursePublishJobHandler")` 注解指明任务调度的入口。
		4、当扫描到课程发布的消息时即开始完成向redis、elasticsearch、MinIO同步数据的操作。 
		5、同步数据的任务完成后删除消息表记录。

- **2PC**
	2PC（Two-phase commit protocol），中文叫二阶段提交，适用于**数据库层面的分布式事务场景**。 **二阶段提交是一种强一致性设计**，2PC 引入一个事务协调者的角色来协调管理各参与者（也可称之为各本地资源）的提交和回滚，二阶段分别指的是准备和提交（提交或回滚）两个阶段。
	
	1、**准备阶段** 协调者会给各参与者发送准备命令，这一阶段除了提交事务之外啥事都做完了。同步等待所有资源的响应之后就进入第二阶段即提交阶段。
		第一阶段有一个参与者返回失败，那么协调者就会向所有参与者发送回滚事务的请求，即分布式事务执行失败。
	2、**提交阶段** 协调者向所有参与者发送提交事务命令，然后等待所有事务都提交成功之后，返回事务执行成功。
		第二阶段提交失败的话：
		1）第一种是**第二阶段执行的是回滚事务操作**，不断重试，直到所有参与者都回滚了，不然那些在第一阶段准备成功的参与者会一直阻塞着。
		2）第二种是**第二阶段执行的是提交事务操作**，也是不断重试，因为有可能一些参与者的事务已经提交成功了，不断的重试，直到提交成功，到最后真的不行只能人工介入处理。

- **3PC**
	相比于 2PC 它在**参与者中也引入了超时机制**，并且**新增了一个阶段**使得参与者可以利用这一个阶段统一各自的状态。3PC 包含了三个阶段，分别是**准备阶段、预提交阶段和提交阶段**。 

### 【补充】分布式锁
分布式锁的实现方法有很多，常见的有以下几种：

- 数据库锁：使用数据库中的行锁或表锁来实现分布式锁。
- 文件锁：使用文件来实现分布式锁。
- Zookeeper锁：使用Zookeeper来实现分布式锁。
- Redis锁：使用Redis来实现分布式锁。
- 消息队列锁：使用消息队列来实现分布式锁。

一些需要分布式锁的场景：

- 分布式数据库事务：在分布式系统中，通常需要使用分布式事务来保证数据的一致性。在分布式事务中，通常会使用分布式锁来保证事务的执行顺序。
- 分布式资源分配：在分布式系统中，通常需要使用分布式锁来分配共享资源。例如，在抢购场景中，需要使用分布式锁来保证同一商品只能被一个用户购买。
- 分布式数据同步：在分布式系统中，通常需要使用分布式锁来保证数据的同步。例如，在订单系统中，需要使用分布式锁来保证同一订单只能被一个系统修改。

Redisson 支持分布式锁，基于Java的Lock接口实现分布式锁，方便开发。

```java
// 1.构造redisson实现分布式锁必要的Config
Config config = new Config();
config.useSingleServer().setAddress("redis://127.0.0.1:5379").setPassword("123456").setDatabase(0);
// 2.构造RedissonClient
RedissonClient redissonClient = Redisson.create(config);
// 3.获取锁对象实例（无法保证是按线程的顺序获取到）
String lockKey = "courseQueryLock:" + courseId;
RLock rLock = redissonClient.getLock(lockKey);
try {
    // 4.尝试获取锁
    // waitTimeout 尝试获取锁的最大等待时间，超过这个值，则认为获取锁失败
    // leaseTime   锁的持有时间,超时锁会自动失效（默认30s）
    boolean res = rLock.tryLock((long)waitTimeout, (long)leaseTime, TimeUnit.SECONDS);
    if (res) {
        // 5.成功获得锁，在这里处理业务
    }
} catch (Exception e) {
    throw new RuntimeException("aquire lock fail");
}finally{
    // 6.释放锁
    rLock.unlock();
}
```

- **加锁机制：** 1）线程去获取锁，获取成功: 执行lua脚本，保存数据到redis数据库；2）若失败，循环重试直到超过最大等待时间，则认为获取锁失败。
lock() 或 tryLock() 获取锁，默认30s 有效：
- **WatchDog 看门狗机制自动延期：** 1）当服务器宕机，超过锁占有时间自动释放防止死锁；2）若业务执行完成，则启动一个 watchDog 后台线程自动续期。
- **lua 脚本保证原子性操作：** RedissonLock 中的异步方法执行 lua 脚本实现加锁、续期和解锁。通过线程 id 保证加锁和解锁是同一个线程，避免误解锁其他线程占有的锁。

[Redis分布式锁-这一篇全了解(Redission实现分布式锁完美方案)-CSDN博客](https://blog.csdn.net/asd051377305/article/details/108384490)
[【精选】Redis：Redisson分布式锁的使用（推荐使用）_redisson分布式锁使用_穿城大饼的博客-CSDN博客](https://blog.csdn.net/chuanchengdabing/article/details/121210426)

### 【重点六】订单模块异步优化（RabbitMQ）
### ===============

使用RabbitMQ 优化订单模块，将用户支付结果异步通知给其他服务，提高了支付响应速度。

**实现流程**

本项目中发布的课程有免费和收费两种，对于免费课程，用户选课后可以直接加入课程表进行学习；对于收费课程，用户选课后需要支付完成才可以加入课程表进行学习。

**下单执行流程：**

1、用户点击支付按钮后，前端请求学习中心服务创建选课记录，同时请求订单服务创建商品订单并生成支付二维码

2、用户扫码后，订单服务会请求第三方支付平台生成支付订单

3、第三方支付平台支付完成后回跳到指定的url，并通过POST请求的形式发起支付结果通知

4、订单服务接收支付结果通知，若支付成功，更新订单表和支付记录表，同时将支付结果异步通知给其他微服务

5、其他微服务收到支付结果，根据订单类型去更新自己的业务数据

**异步通知流程：**

1、将消息队列绑定到交换机（**Fanout广播模式**）

2、订单服务（**生产者**）创建支付结果通知到交换机

3、消息由交换机发送到队列

4、学习中心服务从队列中拿到消息，对属于自己的消息进行处理

### 6.1、RabbitMQ如何保证消息不丢失（可靠性）

主要从生产者向队列投递消息、消息持久化和消费者消费消息这三个方面来保证消息的可靠性：

- **消息持久化：** RabbitMQ可以设置Exchange和Queue的==持久化参数为true==。当消息发送到RabbitMQ服务器时，消息就会持久化。

- **生产者到MQ：** 生产者发送消息到MQ，无法确保发送的消息成功的到MQ服务器。

  - ==事务机制（不推荐）==。在一条消息发送之后会使发送端阻塞，等待RabbitMQ的回应，之后才能继续发送下一条消息。性能差。

  - ==生产者消息确认机制==，只要消息成功发送到交换机之后，RabbitMQ就会发送一个ack给生产者（~~即使消息没有Queue接收，也会发送ack~~）。如果消息没有成功发送到交换机，就会发送一条nack消息，提示发送失败。

  - **注意：** ACK机制只能保证消息成功发送到交换机，从交换机路由到队列失败的消息，会被丢弃掉。可通过==Return消息机制==和==备份交换机==解决：
    **1）Return消息机制：** 提供了回调函数 ==ReturnCallback==，当消息从交换机路由到Queue失败就会回调这个方法。需要将`spring.rabbitmq.template.mandatory` 设置为 `true` ，才能监听到路由不可达的消息。
    **2）备份交换机：** 额外的一个普通交换机，当发送到交换机的消息没有路由到目标队列，就会自动转移到备份交换机对应的队列。

- **MQ到消费者：** RabbitMQ默认是自动ack，消费者收到消息后自动通知MQ Server消息被处理，MQ 就会移除这条消息。
  因此采用消费者手动ACK，消费者完成业务逻辑之后，手动发送Ack消息给MQ，然后删除消息。**若失败则发送nack，消息重新入队或者进入死信队列。**

- ~~【可忽略】ACK机制（不可以和Confirm一起使用）~~： 为了保证消息从队列可靠地达到消费者，RabbitMQ提供了消息确认机制 （Message Acknowledgement）。消费者在订阅队列时，可以指定autoAck参数来开启==消息确认机制==。当 autoAck参数等于false时，RabbitMQ会等待消费者显式地回复确认信号后才从内存（或者磁 盘）中移除消息（实际上是先打上删除标记，之后在删除）。当autoAck参数等于true时， RabbitMQ会自动把发送出去的消息置为确认，然后从内存（或者磁盘）中删除，而不管消费者 是否真正地消费到了这些消息。


### 6.2 如何避免消息重复消费

消息重复的原因有两个：1.生产时消息重复，2.消费时消息重复。

生产者发送消息给MQ，在MQ确认的时候出现了网络波动，生产者没有收到确认，这时候生产者就会重新发送这条消息，导致MQ会接收到重复消息。

消费者消费成功后，给MQ确认的时候出现了网络波动，MQ没有接收到确认，为了保证消息不丢失，MQ就会继续给消费者投递之前的消息。这时候消费者就接收到了两条一样的消息。由于重复消息是由于==网络原因==造成的，无法避免。

解决方法：发送消息时让每个消息携带一个全局的唯一ID，在消费消息时先判断消息是否已经被消费过，保证消息消费逻辑的==幂等性==。具体消费过程为：

1. 消费者获取到消息后先根据id去查询redis/db是否存在该消息
2. 如果不存在，则正常消费，消费完毕后写入redis/db
3. 如果存在，则证明消息被消费过，直接丢弃


### 【补充】消息队列部分代码
**消息队列配置**
```java
@Configuration
public class PayNotifyConfig implements ApplicationContextAware {
    //交换机
    public static final String PAYNOTIFY_EXCHANGE_FANOUT = "paynotify_exchange_fanout";
    //支付结果通知消息类型
    public static final String MESSAGE_TYPE = "payresult_notify";
    //支付通知队列
    public static final String PAYNOTIFY_QUEUE = "paynotify_queue";
    //声明交换机，且持久化
    @Bean(PAYNOTIFY_EXCHANGE_FANOUT)
    public FanoutExchange paynotify_exchange_fanout() {
        // 三个参数：交换机名称、是否持久化、当没有queue与其绑定时是否自动删除
        return new FanoutExchange(PAYNOTIFY_EXCHANGE_FANOUT, true, false);
    }
    //支付通知队列,且持久化
    @Bean(PAYNOTIFY_QUEUE)
    public Queue course_publish_queue() {
        return QueueBuilder.durable(PAYNOTIFY_QUEUE).build();
    }
    //交换机和支付通知队列绑定
    @Bean
    public Binding binding_course_publish_queue(@Qualifier(PAYNOTIFY_QUEUE) Queue queue, @Qualifier(PAYNOTIFY_EXCHANGE_FANOUT) FanoutExchange exchange) {
        return BindingBuilder.bind(queue).to(exchange);
    }
    @Override
    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {
        // 获取RabbitTemplate
        RabbitTemplate rabbitTemplate = applicationContext.getBean(RabbitTemplate.class);
        //消息处理service
        MqMessageService mqMessageService = applicationContext.getBean(MqMessageService.class);
        // 设置ReturnCallback
        rabbitTemplate.setReturnCallback((message, replyCode, replyText, exchange, routingKey) -> {
            // 投递失败，记录日志
            log.info("消息发送失败，应答码{}，原因{}，交换机{}，路由键{},消息{}",
                    replyCode, replyText, exchange, routingKey, message.toString());
            MqMessage mqMessage = JSON.parseObject(message.toString(), MqMessage.class);
            //将消息再添加到消息表
         mqMessageService
             .addMessage(mqMessage.getMessageType(),mqMessage.getBusinessKey1(),mqMessage.getBusinessKey2(),mqMessage.getBusinessKey3());
        });
    }
}
```

**异步发送支付结果**
```java
public void notifyPayResult(MqMessage message) {
    //1、消息体，转json
    String msg = JSON.toJSONString(message);
    //设置消息持久化
    Message msgObj = MessageBuilder.withBody(msg.getBytes(StandardCharsets.UTF_8))
        .setDeliveryMode(MessageDeliveryMode.PERSISTENT)  // 持久化
        .build();
    // 2.全局唯一的消息ID，需要封装到CorrelationData(接受回调消息的对象)中
    CorrelationData correlationData = new CorrelationData(message.getId().toString());
    // 3.添加callback回调函数
    correlationData.getFuture().addCallback(
        result -> {
            if(result.isAck()){
                // 3.1.ack，消息成功
                log.debug("通知支付结果消息发送成功, ID:{}", correlationData.getId());
                //删除消息表中的记录
                mqMessageService.completed(message.getId());
            }else{
                // 3.2.nack，消息失败
                log.error("通知支付结果消息发送失败, ID:{}, 原因{}",correlationData.getId(), result.getReason());
            }
        },
        ex -> log.error("消息发送异常, ID:{}, 原因{}",correlationData.getId(),ex.getMessage())
    );
    // 发送消息
    rabbitTemplate.convertAndSend(PayNotifyConfig.PAYNOTIFY_EXCHANGE_FANOUT, "", msgObj,correlationData);
}
```

**接收支付结果**
```java
@RabbitListener(queues = PayNotifyConfig.PAYNOTIFY_QUEUE)
public void receive(Message message) {
    try {
        Thread.sleep(5000);
    } catch (InterruptedException e) {
        throw new RuntimeException(e);
    }
    byte[] body = message.getBody();
    String jsonString = new String(body);
    MqMessage mqMessage = JSON.parseObject(jsonString, MqMessage.class);
    // 解析消息内容
    String chooseCourseId = mqMessage.getBusinessKey1();
    String orderType = mqMessage.getBusinessKey2();
    if (orderType.equals("60201")) {
        boolean b = myCourseTablesService.saveChooseCourseSuccess(chooseCourseId);  // 保存选课成功记录
        if (!b) {
            // 抛出异常，消息处理失败
            XueChengPlusException.cast("保存选课记录状态失败");
        }
    }
}
```

### YBlog

一个前后端分离的博客，主要负责项目后端的开发，包括访客身份认证授权，博客内容管理，媒资文件管理，访客记录，数据可视化和配置中心等模块。目前已在腾讯云服务器进行容器化部署上线，博客后端代码托管在Gitee上，功能模板代码持续逐步完善中。访问链接 [https://yjf2021.asia](https://yjf2021.asia)

**IPv4存储**
MySQL 数据库自带函数 `INET_ATON` 和 `INET_NTOA` 进行转化：
```sql
SELECT INET_ATON('10.2.125.37');  -- 167935269 范围（16777216由8~10长度4294967295）
SELECT INET_NTOA(167935269); -- 10.2.125.37
```

Java 代码实现
```java
public static void main(String[] args) {  
    String ip = "10.2.125.37";  
    // step1: 分解IP字符串，并对应写对字节数组  
    byte[] ip1 = ipToBytes(ip);  
    // step2: 对字节数组里的每个字节进行左移位处理（<< 8位按位与0xFF00，分别对应到整型变量的4个字节 
    // int addr = bytes[3] & 0xFF;  
	// addr |= ((bytes[2] << 8) & 0xFF00); 
    int ip2 = bytesToInt(ip1);  
    System.out.println("整型ip ----> " + ip2);  
    // step3: 对整型变量进行右位移处理，恢复IP字符串  
    String ip3 = intToIp(ip2);  
    System.out.println("字符串ip---->" + ip3);   
}
```

**镜像运行**
- 创建Dockerfile文件
```dockerfile
# 选择的jdk 镜像版本，先执行docker search openjdk 查看可用的jdk 镜像
FROM  openjdk:11
# 镜像作者
MAINTAINER	yjf
# 镜像的工作目录
WORKDIR /ROOT
ADD yblog-web-0.0.1-SNAPSHOT.jar yblog-web-0.0.1-SNAPSHOT.jar
# 该容器启动时会运行的命令
CMD ["java", "-version"]
# 该容器启动时会运行的命令，可进行追加命令
ENTRYPOINT ["java", "-Dfile.encoding=utf-8", "-jar", "yblog-web-0.0.1-SNAPSHOT.jar"]
# 端口配置
EXPOSE 8081
```
- 创建镜像
```python
# 删除镜像
docker rmi 镜像名称
docker build -t yblog:1.5 .  
```
- 运行容器
```python
# 挂载宿主机目录
docker run -d -e TZ=Asia/Shanghai --name yblog -p 8081:8081 -v /home/yblog/source/:/home/yblog/source/ -idt yblog:1.5
# 查看容器日志
docker logs yblog
```
- 进入容器
```python
# 进入容器
docker exec -it yblog  bash
# 删除文件
rm -rf 文件名
docker cp /home/yblog/source/ yblog:/home/yblog/source/
```

## 常见设计模式

### SOLID: 面向对象设计的五个基本原则

**单一职责原则：** 一个类应该专注特定的职责，即有且仅有一个原因引起类的变更。

**开闭原则：** 软件实体（模块、类、函数等等）应该对扩展是开放的，对修改是关闭的。即尽量通过扩展软件实体来解决需求变化，而不是通过修改已有的代码来完成变化。

**里氏替换原则：** 在使用基类的这个方法中，可以用子类替换，确保不影响其他子类的实现。

**接口隔离原则：** 如果某个接口的一些方法只被部分调用者使用，那就应该将这部分接口方法隔离出来，单独给对应的调用者使用，而不是强迫其他调用者也依赖这部分不会被用到的接口方法。即==类间的依赖关系==应该建立在最小的接口上。

**依赖倒置原则：** 高层模块不应该依赖底层模块，二者都该依赖其抽象（高层和底层之间通过抽象建立连接）；抽象不应该依赖细节；细节应该依赖抽象；

本质就是通过抽象（接口或抽象类）使各个类或模块的实现彼此独立，互不影响，实现模块间的松耦合。

> [文章详情页 - YBlog (yjf2021.asia)](https://www.yjf2021.asia/#/article/detail?articleId=45)

### ==创建型设计模式：==

创建型模式的作用是提供一个通用的解决方案来创建对象，并隐藏创建的细节创建对象。

- 单例模式：保证一个类只有一个实例，并提供一个访问该实例的全局点。适用于管理一些全局的共享资源，避免多个实例之间的竞争和冲突，但是需要注意实现上的问题。
- 工厂模式：定义一个用于创建对象的接口，但让子类决定将哪一个类实例化。适用于具有相似性质的对象的创建，更加灵活。
- 生成器模式：将一个复杂对象的构建过程分成多个步骤来完成。适用于创建一些复杂的对象，方便代码的维护和扩展。
- 原型模式：利用拷贝对象的方法，减少一些复杂的创建过程。

### 简单工厂模式

简单工厂模式，又叫做静态工厂方法（Static Factory Method）模式。该模式通过引入一个工厂类，将对象的实例化过程封装起来。

只需要向工厂类提供必要的参数，工厂类就会根据这些参数来创建相应的对象。因此可以将对象的创建逻辑集中在一个地方，而不需要在每个需要使用该对象的地方都编写复杂的创建过程。

**优点：**

- 将创建实例的工作与使用实例的工作分开，使用者不必关心类对象如何创建，实现了解耦；
- 把初始化实例时的工作放到工厂里进行，使代码更容易维护。 更符合面向对象的原则 & 面向接口编程，而不是面向实现编程。

**缺点：**

- 违背“开放 - 关闭原则”，一旦添加新产品就不得不修改工厂类的逻辑，这样就会造成工厂逻辑过于复杂。
- 简单工厂模式由于使用了静态工厂方法，静态方法不能被继承和重写，会造成工厂角色无法形成基于继承的等级结构。

**使用场景：**

- 不想直接使用 new 关键字来创建对象。因为如果将来这个类发生变化，可能需要修改代码，而该类的对象已经被广泛使用。
- 这个类的对象的构建过程非常复杂，你不希望在需要使用该对象的地方重复编写这个复杂的构建过程。
- 在构建该类的对象时，它依赖于许多其他类，而你无法在调用的地方提供这些依赖。

**代码示例：**

```java
public class SimpleFactoryPattern {
    public static void main(String[] args) {
        // 4、使用简单工厂创建对象
        Product productA = SimpleFactory.createProduct("A");
        productA.operation();

        Product productB = SimpleFactory.createProduct("B");
        productB.operation();
    }
}

// 1、定义抽象产品基类
abstract class Product {
    // 抽象生产方法
    public abstract void operation();
}
// 2、定义具体的产品对象类
class ProductA extends Product {
    @Override
    public void operation() {
        System.out.println("这个工厂生产产品A");
    }
}
class ProductB extends Product {
    @Override
    public void operation() {
        System.out.println("这个工厂生产产品B");
    }
}
// 3、定义简单工厂方法类。使用一个静态工厂方法来根据不同的输入来产生不同的产品实例
class SimpleFactory {
    public static Product createProduct(String type) {
        Product product = null;
        switch (type) {
            case "A":
                product = new ProductA();
                break;
            case "B":
                product = new ProductB();
                break;
            default:
                break;
        }
        return product;
    }
}
```

### 抽象工厂模式

**抽象工厂模式** 是一种创建型设计模式， 它能创建一系列相关的对象， 而无需指定其具体类。

抽象工厂定义了用于创建不同产品的接口， 但将实际的创建工作留给了具体工厂类。 每个工厂类型都对应一个特定的产品变体。

通过使用抽象工厂模式，可以将客户端与具体产品的创建过程解耦，使得客户端可以通过工厂接口来创建一系列产品。

**优点：**

- 可以确保同一工厂生成的产品相互匹配。
- 可以避免客户端和具体产品代码的耦合。
- *单一职责原则*。 你可以将产品生成代码抽取到同一位置， 使得代码易于维护。
- *开闭原则*。 向应用程序中引入新产品变体时， 你无需修改客户端代码。

**缺点：**

- 由于采用该模式需要向应用中引入众多接口和类， 代码可能会比之前更加复杂。

**使用场景: **

- **如果代码需要与多个不同系列的相关产品交互，但是由于无法提前获取相关信息，或者出于对未来扩展性的考虑，你不希望代码基于产品的具体类进行构建。**
  - 抽象工厂提供了一个接口， 可用于创建每个系列产品的对象。 只要代码通过该接口创建对象， 那么你就不会生成与应用程序已生成的产品类型不一致的产品。
- **如果你有一个基于一组[抽象方法](https://refactoringguru.cn/design-patterns/factory-method)的类，且其主要功能因此变得不明确，那么在这种情况下可以考虑使用抽象工厂模式。**
  - 在设计良好的程序中， *每个类仅负责一件事*。 如果一个类与多种类型产品交互， 就可以考虑将工厂方法抽取到独立的工厂类或具备完整功能的抽象工厂类中。

**代码：**

```java

// 1、创建A、B产品的抽象产品接口
interface ProductA {
    void show();
}
interface ProductB {
    void show();
}
// 2、不同产品型号具体的生产方式实现类
// 具体产品A1
class ProductA1 implements ProductA {
    @Override
    public void show() {
        System.out.println("Product A1");
    }
}
// 具体产品A2
class ProductA2 implements ProductA {
    @Override
    public void show() {
        System.out.println("Product A2");
    }
}
// 具体产品B1
class ProductB1 implements ProductB {
    @Override
    public void show() {
        System.out.println("Product B1");
    }
}
// 具体产品B2
class ProductB2 implements ProductB {
    @Override
    public void show() {
        System.out.println("Product B2");
    }
}
// 3、创建上游的抽象工厂和具体产品型号的生产工厂，如==专门生产型号1的工厂1==
// 抽象工厂
interface AbstractFactory {
    ProductA createProductA();
    ProductB createProductB();
}
// 具体工厂1
class ConcreteFactory1 implements AbstractFactory {
    @Override
    public ProductA createProductA() {
        return new ProductA1();
    }
    @Override
    public ProductB createProductB() {
        return new ProductB1();
    }
}
// 具体工厂2
class ConcreteFactory2 implements AbstractFactory {
    @Override
    public ProductA createProductA() {
        return new ProductA2();
    }
    @Override
    public ProductB createProductB() {
        return new ProductB2();
    }
}
// 4、客户端根据不同产品需求的生产过程
public class Main {
    public static void main(String[] args) {
        // 创建具体工厂1
        AbstractFactory factory1 = new ConcreteFactory1();
        // 创建具体产品A1和B1
        System.out.println("具体工厂1开始生产产品");
        factory1.createProductA().show();
        factory1.createProductB().show();
        // 创建具体工厂2
        AbstractFactory factory2 = new ConcreteFactory2();
        // 创建具体产品A2和B2
        System.out.println("具体工厂2开始生产产品");
        factory2.createProductA().show();
        factory2.createProductB().show();
    }
}
```

### 单例模式

单例模式确保某个类只有一个实例，而且自行实例化并向整个系统提供这个实例。单例模式可以==避免多个实例状态不一致==的情况，因此普遍应用在计算机系统中，如线程池、缓存、日志对象等。实现单例模式主要有以下几个关键点：

- **构造函数为 private** ，这避免外部通过 new 创建实例；
- 通过一个**静态方法或者枚举返回单例类对象**；
- 考虑对象创建时的线程安全问题，确保单例类的对象**有且仅有一个**，尤其是在多线程环境下；
- 确保单例类对象在反序列化时不会重新构建对象。
- 考虑是否支持延迟加载；

**优点**

- 系统内存中该类只存在一个对象，节省了系统资源，对于一些需要频繁创建销毁的对象，使用单例模式可以提高系统性能。

**缺点**

- 单例对继承、多态特性的支持不友好。
- **单例类只能有一个对象实例**。但如果未来需要创建两个或多个实例，就需要对代码有比较大的改动。
- 单例不支持有参数的构造函数，如果想要传递参数，只能在 getInstance 方法中添加参数，或者定义方法传递参数。

**使用场景**

- 需要频繁的进行创建和销毁的对象；
- 创建对象时耗时过多或耗费资源过多，但又经常用到的对象；
- 工具类对象；
- 频繁访问数据库或文件的对象。

**代码：** 

**1、饿汉式（静态常量）：** 在类加载的时候就完成了实例化，避免了线程同步问题。

```java
public class Singleton {
    private static final Singleton instance = new Singleton();
    private Singleton() {}   
    public static Singleton getInstance() {
        return instance;
    }
}
```

**2、懒汉式（线程不安全）** 相对于饿汉式的优势是==支持延迟加载==，但只能在单线程中使用，多线程场景会导致产生多个实例，==线程不安全==。

```java
public class Singleton {
    private static Singleton instance;
    private Singleton() {}   
    public static Singleton getInstance() {
        if (instance == null) {
            instance = new Singleton();
        }
        return instance;
    }
}
```

**3、双重检查** 综和饿汉式、懒汉式单例模式的优缺点，提出既支持==延迟加载==、又支持==高并发==的双重检查实现方式。

```java
public class Singleton {
    private static volatile Singleton instance;
    private Singleton() { }
    public static Singleton getInstance() {
        if (instance == null) {
            synchronized (Singleton.class) {
                if (instance == null) {
                    instance = new Singleton();
                }
            }
        }
        return instance;
    }
}
```

**4、枚举** 枚举是单例最简单的实现方式，这种实现方式通过 Java 枚举类型本身的特性，不仅能保证线程安全，还能==防止反序列化==重新创建新的对象。

```java
public enum Singleton {
    INSTANCE;
}
```

### 生成器模式【建造者模式】

**生成器模式** 是一种创建型设计模式， 使你能够分步骤创建复杂对象。 与其他创建型模式不同， 生成器不要求产品拥有通用接口。 

**优点**

- 你可以分步创建对象， 暂缓创建步骤或递归运行创建步骤。
- 生成不同形式的产品时， 你可以复用相同的制造代码。
- ==单一职责原则==。 你可以将复杂构造代码从产品的业务逻辑中分离出来。

**缺点**

- 由于该模式需要新增多个类， 因此代码整体复杂程度会有所增加。

**使用场景**

- **使用生成器模式可避免”重叠构造函数“的出现，该模式可以分步骤生成对象， 而且允许你仅使用必须的步骤。**
  - 当构造函数中有十个可选参数， 那么调用该函数会非常不方便； 即使重载只有几个常用参数的构造函数，一般还是需调用主构造函数， 传递一些默认数值来替代省略掉的参数。
- **使用生成器构造组合树或其他复杂对象**
  - 生成器模式让你能分步骤构造产品。即使延迟执行某些步骤而不会影响最终产品，甚至可以递归调用这些步骤。

**代码：** 构建一个电脑对象为例。创建一个电脑类，它包含了一些可选属性，然后使用生成器模式逐步构建电脑对象。

```java
// 1、创建一个电脑产品类
class Computer {
    private String cpu;
    private String ram;
    private String storage;
    public Computer(String cpu, String ram, String storage) {
        this.cpu = cpu;
        this.ram = ram;
        this.storage = storage;
    }
    public String getCpu() {
        return cpu;
    }
    public String getRam() {
        return ram;
    }
    public String getStorage() {
        return storage;
    }
}

// 2、创建对应的生成器接口
interface ComputerBuilder {
    ComputerBuilder setCpu(String cpu);
    ComputerBuilder setRam(String ram);
    ComputerBuilder setStorage(String storage);
    Computer build();
}

// 3、创建具体的生成器类
class ConcreteComputerBuilder implements ComputerBuilder {
    private String cpu;
    private String ram;
    private String storage;

    @Override
    public ComputerBuilder setCpu(String cpu) {
        this.cpu = cpu;
        return this;
    }
    @Override
    public ComputerBuilder setRam(String ram) {
        this.ram = ram;
        return this;
    }
    @Override
    public ComputerBuilder setStorage(String storage) {
        this.storage = storage;
        return this;
    }
    @Override
    public Computer build() {
        return new Computer(cpu, ram, storage);
    }
}

// 4、建造者模式创建对象
public class Main {
    public static void main(String[] args) {
        ComputerBuilder builder = new ConcreteComputerBuilder();
        Computer myComputer = builder.setCpu("Intel i7").setRam("32 GB").setStorage("512GB SSD").build();
    }
}
// // 运行输出结果
CPU: Intel i7
RAM: 32 GB
Storage: 512GB SSD
```

### ==结构型设计模式：==

结构型模式的作用是提供一种组织对象的方式，以便实现对象之间的关系和交互。

- 适配器模式实现了类似“把鸡包装成鸭”的接口适配；

- 外观模式可以让客户端不需要关心实例化过程，只要调用需要的方法即可。

- 代理模式用来做方法的增强；

- 桥梁模式通过组合，实现系统的解耦；

### 适配器模式

适配器可担任两个对象间的封装器， 它会接收对于一个对象的调用， 并将其转换为另一个对象可识别的格式和接口。

适配器模式通过封装对象将复杂的转换过程隐藏于幕后。 被封装的对象甚至察觉不到适配器的存在。 例如， 你可以使用一个将所有数据转换为英制单位 （如英尺和英里） 的适配器封装运行于米和千米单位制中的对象。

**优点**

- ==单一职责原则==，你可以将接口或数据转换代码从程序主要业务逻辑中分离。
- ==开闭原则==。 只要客户端代码通过客户端接口与适配器进行交互， 你就能在不修改现有客户端代码的情况下在程序中添加新类型的适配器。

**缺点**

- 代码整体复杂度增加， 因为你需要新增一系列接口和类。 有时直接更改服务类使其与其他代码兼容会更简单。

**使用场景**

- **使用某个类时，但其接口与其他代码不兼容**
  - 适配器模式允许你创建一个中间层类， 其可作为代码与遗留类、 第三方类或提供怪异接口的类之间的转换器。
- **如果需要复用这样一些类**：他们处于同一个继承体系，并且他们又有了额外的一些共同的方法，但是这些共同的方法不是所有在这一继承体系中的子类所具有的共性。
  - 你可以扩展每个子类， 将缺少的功能添加到新的子类中。 但是， 你必须在所有新子类中重复添加这些代码，

### 外观模式

外观类为包含许多活动部件的复杂子系统（**程序库、 框架或其他复杂类**）提供一个简单的接口。 与直接调用子系统相比， 外观提供的功能可能比较有限， 但它却包含了客户端真正关心的功能。

如果你的程序需要与包含几十种功能的复杂库整合， 但只需使用其中非常少的功能， 那么使用外观模式会非常方便。

**优点**

- 可以让自己的代码独立于复杂子系统。

**缺点**

- 外观类可能成为与程序中所有类都发生耦合。

**使用场景**

- **如果你需要一个指向复杂子系统的直接接口，且该接口的功能有限，则可以使用外观模式。**
  - 子系统通常会随着时间的推进变得越来越复杂。 即便是应用了设计模式， 通常你也会创建更多的类。 尽管在多种情形中子系统可能是更灵活或易于复用的， 但其所需的配置和样板代码数量将会增长得更快。 为了解决这个问题， 外观将会提供指向子系统中最常用功能的快捷方式， 能够满足客户端的大部分需求。

- **当需要将子系统组织为多层结构**
  - 创建外观来定义子系统中各层次的入口。 你可以要求子系统仅使用外观来进行交互， 以减少子系统之间的耦合。

**代码：**

```java
// 1、首先定义CPU、Memory和Disk三个类，分别表示电脑的处理器、内存和硬盘。这些类可以包含一些基本的方法，例如启动和关闭等。
class CPU {
    public void start() {
        System.out.println("CPU 已启动");
    }
    public void stop() {
        System.out.println("CPU 已关闭");
    }
}
class Memory {
    public void start() {
        System.out.println("Memory 已启动");
    }
    public void stop() {
        System.out.println("Memory 已关闭");
    }
}
class Disk {
    public void start() {
        System.out.println("Disk 已启动");
    }
    public void stop() {
        System.out.println("Disk 已关闭");
    }
}

// 2、然后定义一个Computer类，它是一个外观类，用于封装电脑启动的过程。这个类包含了一个start方法，用于启动电脑。
class Computer {
    private CPU cpu;
    private Memory memory;
    private Disk disk;
    
    public Computer() {
        cpu = new CPU();
        memory = new Memory();
        disk = new Disk();
    }
    public void start() {
        cpu.start();
        memory.start();
        disk.start();
        System.out.println("Computer 成功启动");
    }
    public void stop() {
        disk.stop();
        memory.stop();
        cpu.stop();
        System.out.println("Computer 成功关闭");
    }
}

// 3、最后使用Computer类来启动电脑。
public class Facade {
    public static void main(String[] args) {
        Computer computer = new Computer();
        computer.start();
        System.out.println("使用电脑...");
        computer.stop();
    }
}

// 运行输出结果
// CPU 已启动
// Memory 已启动
// Disk 已启动
// Computer 成功启动
// 使用电脑...
// Disk 已关闭
// Memory 已关闭
// CPU 已关闭
// Computer 成功关闭
```

### ==行为型设计模式：==

行为型设计模式主要关注对象之间的通信和交互的方式和模式。

### 观察者模式

观察者设计模式是一种行为型设计模式，它定义了一种一对多的依赖关系，当一个对象的状态发生变化时，所有依赖于它的对象都会得到通知并自动更新。这种模式通常用于实现分布式事件处理系统，其中一个对象（称为主题或被观察者）维护一组依赖对象（观察者，需要==订阅主题==），当主题的状态发生变化时，观察者将被通知并执行相应的操作。

**优点**

- 开闭原则。 你无需修改发布者代码就能引入新的订阅者类 （如果是发布者接口则可轻松引入发布者类）。
- 可以在运行时建立对象之间的联系。

**缺点**

- 订阅者的通知顺序是随机的。

**使用场景**

- 当一个对象状态的改变需要改变其他对象，或实际对象是事先未知的或动态变化的时， 可使用观察者模式。
- 当应用中的一些对象必须观察其他对象时，可使用该模式。订阅列表是动态的， 因此订阅者可随时加入或离开该列表。

**代码：** 下面是一个简单的主题订阅发布的例子。

```java
// 1、主题，即被观察者，它维护一组观察者对象，并提供方法来注册、移除和通知观察者。
interface Subject {
    void registerObserver(Observer observer);
    void removeObserver(Observer observer);
    void notifyObservers();
}

// 2、具体主题（ConcreteSubject）：实现主题接口，维护状态，当状态变化时通知所有注册的观察者。
class ConcreteSubject implements Subject {
    private List<Observer> observers = new ArrayList<>();
    private String message;
    @Override
    public void registerObserver(Observer observer) {
        observers.add(observer);
    }
    @Override
    public void removeObserver(Observer observer) {
        observers.remove(observer);
    }
    @Override
    public void notifyObservers() {
        for (Observer observer : observers) {
            observer.update(message);
        }
    }
    public void setMessage(String message) {
        this.message = message;
        // 当状态变化时通知观察者
        notifyObservers();
    }
}

// 3、观察者（Observer）：定义了一个接口，包含一个更新方法，用于在主题状态发生变化时接收通知。
interface Observer {
    void update(String message);
}

// 4、具体观察者（ConcreteObserver）：实现观察者接口，实现更新方法以响应主题的通知。
class ConcreteObserver implements Observer {
    private String name;

    public ConcreteObserver(String name) {
        this.name = name;
    }
    @Override
    public void update(String message) {
        System.out.println(name + " 收到消息: " + message);
    }
}

// 5、观察者模式调用
public class ObserverPatternExample {
    public static void main(String[] args) {
        ConcreteSubject subject = new ConcreteSubject();
        ConcreteObserver observer1 = new ConcreteObserver("观察者1");
        ConcreteObserver observer2 = new ConcreteObserver("观察者2");
        ConcreteObserver observer3 = new ConcreteObserver("观察者3");
        // 观察者注册
        subject.registerObserver(observer1);
        subject.registerObserver(observer2);
        // 发布新消息，观察者将收到通知
        System.out.println("====== 新消息发布 =========");
        subject.setMessage("新消息发布");
        // 观察者移除 注册
        subject.registerObserver(observer3);
        subject.removeObserver(observer2);
        // 第二条消息发布
        System.out.println("====== 新消息发布 =========");
        subject.setMessage("第二条消息发布");
    }
}

// 运行输出结果
====== 新消息发布 =========
观察者1 收到消息: 新消息发布
观察者2 收到消息: 新消息发布
====== 新消息发布 =========
观察者1 收到消息: 第二条消息发布
观察者3 收到消息: 第二条消息发布
```

### 原型模式（创建型）

**原型模式** 是一种创建型设计模式， 使你能够复制已有对象， 而又无需使代码依赖它们所属的类。在某些情况下可以减少对象的创建成本。

**优点**

-  你可以克隆对象， 而无需与它们所属的具体类相耦合。
-  你可以克隆预生成原型， 避免反复运行初始化代码。
-  你可以更方便地生成复杂对象。
-  你可以用继承以外的方式来处理复杂对象的不同配置。

**缺点**

- 克隆包含循环引用的复杂对象可能会非常麻烦。

**适用场景**

-  **如果你需要复制一些对象， 同时又希望代码独立于这些对象所属的具体类， 可以使用原型模式。**
   - 这一点考量通常出现在代码需要处理第三方代码通过接口传递过来的对象时。 即使不考虑代码耦合的情况， 你的代码也不能依赖这些对象所属的具体类， 因为你不知道它们的具体信息。
   - 原型模式为客户端代码提供一个通用接口， 客户端代码可通过这一接口与所有实现了克隆的对象进行交互， 它也使得客户端代码与其所克隆的对象具体类独立开来。
-  **如果子类的区别仅在于其对象的初始化方式， 那么你可以使用该模式来减少子类的数量。 别人创建这些子类的目的可能是为了创建特定类型的对象。**
   - 在原型模式中， 你可以使用一系列预生成的、 各种类型的对象作为原型。客户端不必根据需求对子类进行实例化， 只需找到合适的原型并对其进行克隆即可。

## 常见排序算法
more [十大经典排序算法总结 | JavaGuide(Java面试 + 学习指南)](https://javaguide.cn/cs-basics/algorithms/10-classical-sorting-algorithms.html#%E7%AE%97%E6%B3%95%E5%88%86%E7%B1%BB)

### 冒泡排序（BubbleSort）

冒泡排序是一种简单的排序算法。它重复地遍历要排序的序列，依次比较两个元素，如果它们的顺序错误就把它们交换过来。遍历序列的工作是重复地进行直到没有再需要交换为止，此时说明该序列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢 “浮” 到数列的顶端。

**算法步骤：** 

1、比较相邻的元素。如果第一个比第二个大，就交换它们两个；

2、对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数；

3、针对所有的元素重复以上的步骤，除了最后一个；

4、重复步骤 1~3，直到排序完成。

**算法分析：** 

- **稳定性**：稳定；**排序方式**：In-place
- **时间复杂度**：最佳：O(n) ，最差：O(n2)， 平均：O(n2)；   **空间复杂度**：O(1)

```java
public static int[] bubbleSort(int[] arr) {  
    int[] nums = Arrays.copyOf(arr, arr.length);
    for (int i = 1; i < nums.length; i++) {  
        boolean flag = true;  
        for (int j = 0; j < nums.length - i; j++) {  
            if (nums[j] > nums[j + 1]) {  
                int temp = nums[j];  
                nums[j] = nums[j + 1];  
                nums[j + 1] = temp;  
                flag = false;  
            }  
        }  
        if (flag) {  
            break;  
        }  
    }  
  
    return nums;  
}
```

### 选择排序（Select Sort）

选择排序是一种简单直观的排序算法，无论什么数据进去都是 `O(n²)` 的时间复杂度。所以用到它的时候，数据规模越小越好。唯一的好处可能就是不占用额外的内存空间。

**算法步骤：**

1. 首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置
2. 再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。
3. 重复第 2 步，直到所有元素均排序完毕。

**算法分析：**

- **稳定性**：不稳定；**排序方式**：In-place
- **时间复杂度**：最佳：O(n2) ，最差：O(n2)， 平均：`O(n²)`；**空间复杂度**：O(1)

```java
public static int[] selectSort(int[] arr) {  
    int[] nums = Arrays.copyOf(arr, arr.length);  
    for (int i = 0; i < arr.length; i++) {  
        int min = i;  
        for (int j = i + 1; j < arr.length; j++) {  
            if (nums[min] > nums[j]) {  
                min = j;  
            }  
        }  
        if (min != i) {  
            int temp = nums[min];  
            nums[min] = nums[i];  
            nums[i] = temp;  
        }  
    }   
    return nums;  
}
```

### 插入排序（Insertion Sort）

插入排序是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。插入排序在实现上，通常采用 in-place 排序（即只需用到 `O(1)` 的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。

**算法步骤:** 

1. 从第一个元素开始，该元素可以认为已经被排序；
2. 取出下一个元素，在已经排序的元素序列中从后向前扫描；
3. 如果该元素（已排序）大于新元素，将该元素移到下一位置；
4. 重复步骤 3，直到找到已排序的元素小于或者等于新元素的位置；
5. 将新元素插入到该位置后；
6. 重复步骤 2~5。

**算法分析：**

- **稳定性**：稳定；**排序方式**：In-place
- **时间复杂度**：最佳：O(n) ，最差：O(n2)， 平均：O(n2)；**空间复杂度**：O(1)

```java
public static int[] insertionSort(int[] arr) {
    for (int i = 1; i < arr.length; i++) {
        int preIndex = i - 1;
        int current = arr[i];
        while (preIndex >= 0 && current < arr[preIndex]) {
            arr[preIndex + 1] = arr[preIndex];
            preIndex -= 1;
        }
        arr[preIndex + 1] = current;
    }
    return arr;
}

```

### 快速排序 (Quick Sort)

快速排序用到了分治思想，同样的还有归并排序。乍看起来快速排序和归并排序非常相似，都是将问题变小，先排序子串，最后合并。不同的是快速排序在划分子问题的时候经过多一步处理，将划分的两组数据划分为一大一小，这样在最后合并的时候就不必像归并排序那样再进行比较。但也正因为如此，划分的不定性使得快速排序的时间复杂度并不稳定。

快速排序的基本思想：通过一趟排序将待排序列分隔成独立的两部分，其中一部分记录的元素均比另一部分的元素小，则可分别对这两部分子序列继续进行排序，以达到整个序列有序。

**算法步骤:** 

快速排序使用 [分治法open in new window](https://zh.wikipedia.org/wiki/分治法) 策略来把一个序列分为较小和较大的 2 个子序列，然后递回地排序两个子序列。具体算法描述如下：

1. 从序列中**随机**挑出一个元素，做为 “基准”(`pivot`)；
2. 重新排列序列，将所有比基准值小的元素摆放在基准前面，所有比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个操作结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作；
3. 递归地把小于基准值元素的子序列和大于基准值元素的子序列进行快速排序。

**算法分析**

- **稳定性**：不稳定
- **时间复杂度**：最佳：O(nlogn)， 最差：O(nlogn)，平均：O(nlogn)；**空间复杂度**：O(logn)

```java
public class QuickSort {
    public static void main(String[] args) {  
	    int[] arr = new int[]{1,5,2,23,6,7,8,8,15};  
	    int[] nums = Arrays.copyOf(arr, arr.length);  
	    int[] selectSort = quickSort(nums, 0, nums.length - 1);  
	    System.out.println(Arrays.toString(selectSort));  
	}  
  
  
	public static int[] quickSort(int[] nums, int left, int right) {  
	    // int[] nums = Arrays.copyOf(arr, arr.length);  
	    if (left < right) {  
	        int partition = partition(nums, left, right);  
	        quickSort(nums, left, partition - 1);  
	        quickSort(nums, partition + 1, right);  
	    }  
	    return nums;  
	}  
  
	public static int partition(int[] nums, int left, int right) {  
	    int pivot = left;  
	    int index = pivot + 1;  
	    for (int i = index; i <= right; i++) {  
	        // 当当前值小于基准值，放在基准左边  
	        if (nums[pivot] > nums[i]) {  
	            swap(nums, i, index);  
	            index++;  
	        }  
	    }  
	    index--;  
	    swap(nums, pivot, index);  
	    return index;  
	}  
  
	public static void swap(int[] nums, int left, int right) {  
	    int temp = nums[left];  
	    nums[left] = nums[right];  
	    nums[right] = temp;
	}
}
```




### 归并排序 (Merge Sort)

归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法 (Divide and Conquer) 的一个非常典型的应用。归并排序是一种稳定的排序方法。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为 2路归并。

和选择排序一样，归并排序的性能不受输入数据的影响，但表现比选择排序好的多，因为始终都是 `O(nlogn)` 的时间复杂度。代价是需要额外的内存空间。

**算法步骤:**  归并排序算法是一个递归过程，边界条件为当输入序列仅有一个元素时，直接返回，具体过程如下：

1. 如果输入内只有一个元素，则直接返回，否则将长度为 `n` 的输入序列分成两个长度为 `n/2` 的子序列；
2. 分别对这两个子序列进行归并排序，使子序列变为有序状态；
3. 设定两个指针，分别指向两个已经排序子序列的起始位置；
4. 比较两个指针所指向的元素，选择相对小的元素放入到合并空间（用于存放排序结果），并移动指针到下一位置；
5. 重复步骤 3 ~4 直到某一指针达到序列尾；
6. 将另一序列剩下的所有元素直接复制到合并序列尾。

**算法分析：** 

- **稳定性**：稳定
- **时间复杂度**：最佳：O(nlogn)， 最差：O(nlogn)， 平均：O(nlogn)；**空间复杂度**：O(n) 

```java
ppublic static int[] sort(int[] sourceArray) {  
    // 对 arr 进行拷贝，不改变参数内容  
    int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);  
    if (arr.length < 2) {  
        return arr;  
    }  
    int middle = arr.length / 2;
    int[] left = Arrays.copyOfRange(arr, 0, middle);  
    int[] right = Arrays.copyOfRange(arr, middle, arr.length);
    return merge(sort(left), sort(right));  
}  
  
public static int[] merge(int[] left, int[] right) {  
    int[] result = new int[left.length + right.length];  
    int i = 0;  
    while (left.length > 0 && right.length > 0) {  
        if (left[0] <= right[0]) {  
            result[i++] = left[0];  
            left = Arrays.copyOfRange(left, 1, left.length);  
        } else {  
            result[i++] = right[0];  
            right = Arrays.copyOfRange(right, 1, right.length);  
        }  
    }  
    while (left.length > 0) {  
        result[i++] = left[0];  
        left = Arrays.copyOfRange(left, 1, left.length);  
    }    
    while (right.length > 0) {  
        result[i++] = right[0];  
        right = Arrays.copyOfRange(right, 1, right.length);  
    }  
  
    return result;  
}
```



## 系统设计场景

### 如何设计一个高可用系统

高可用系统指的是一个系统在大部分情况下都是能够正常提供服务的。即使在部分硬件发生故障或系统升级的时候，多数服务仍然对外提供访问。

**==系统不可用的因素：==**

- 黑客恶意攻击；
- 硬件故障，比如部分服务器宕机；
- 中间组件或数据库故障，比如 Nginx 服务器或数据库出问题；
- 代码不规范，导致内存泄漏或其他不可描述的 Bug；
- 并发量激增导致部分服务不可用甚至整个系统挂掉；

**==提高系统可用性的举措：==**

- **提高代码质量，注重 CodeReview**

- **使用缓存**

  当系统并发量比较大的适合，大量请求直接落到数据库可能因为锁或者硬盘访问导致访问慢，甚至数据库直接挂掉。因此可以考虑对部分数据使用 Redis 进行缓存，Redis 能够应付的访问请求远大于 MySQL。~~（Redis QPS 能达到 10 万，而 MySQL 很难破万）~~

- **使用集群，避免单点故障**

  比如 MySQL 读写分离，将数据库拆分为主库和从库，主库负责处理事务性的增删改操作，从库负责处理查询操作，同时做好数据备份。

  构建 Redis 集群，当某一个 Redis 节点挂了，可以从其他节点读取缓存数据。

- **系统服务集群**

  微服务架构下，构建服务集群，通过 Nginx 将用户请求根据==负载均衡策略（轮询、IP 哈希、最小连接数）==分配到不同的集群节点上。

- **服务限流**

  当服务请求（QPS 或并发线程数，可通过阿里开源的 ==Sentinel== 实现）达到设定的阈值，就对请求进行控制（随机截断部分请求），避免该服务被瞬时的大量请求冲垮。

- **超时重试机制**

  当用户对服务的请求超过预定的时间得不到响应，即抛出异常。对于响应慢的请求不进行超时中断，可能会导致请求堆积让系统无法处理。

  对于涉及到第三方接口的服务，尤其适合设置超时重试，重试次数一般设置为 3 次即可，否则可能加重服务器负担。

- **熔断机制**

  系统借助外部工具（Sentinel 和 Hystrix）收集所依赖服务的资源使用情况和性能指标，当所依赖服务恶化或调用失败次数达到阈值就停止依赖该服务，让系统切换到其他的备用服务。

- **异步处理**

  1）特定请求结果的异步调用：比如用户下单付款后，涉及到对应订单内容的查表和写表，可以直接返回用户下单成功的结果，然后通过其他线程异步处理具体的操作。

  2）也可以引入 RabbitMQ 消息队列处理上述异步过程。在有些业务场景，系统难以快速处理大量请求时，使用消息队列进行流量削峰。

### 如何涉及一个秒杀系统

秒杀系统主要是为爆款商品或者抢票等活动提供支持，因此这些活动会限制商品的数量和持续时间。

主要的难点是如何保证向短时间内大量的请求提供正常服务和库存有效，因此需要关注这些问题 [`高并发、高性能、高可用、一致性`]：

- 秒杀的商品属于热点数据，应该如何处理；
- 商品库存有限，如何保证数据一致性，也就是超卖的问题；
- 如何保证系统的高可用
- 引入消息队列后，如何保证消息可靠性和避免重复消费
- 如何对系统进行压测

==**高性能**==

- **热点数据处理：** 热点数据使用 Redis 等数据库进行缓存，必要的话构建二级缓存架构，本地缓存（JVM 内存）能避免网络传输开销。缓存数据需要设置过期时间，本地缓存的数据不易过多而占用内存过大，设置缓存淘汰策略。
- **静态资源处理：** 对于商品图片、静态网页等静态资源，可以使用 CDN（内容分发网络）进行处理，减轻大量页面刷新时服务器和带宽的负担。

**==高可用==**
分布式锁一般用在分布式场景多节点访问同一个对象
- **集群化：** 搭建集群避免单点故障，比如 Nginx 集群、MySQL 集群、Redis 集群、MQ 集群。
- **限流：** 
  - 接口限流：比如秒杀接口一秒能处理的接口是 10 万，那么只处理当前 10 万个请求，剩余的请求全部拦截抛弃。还可以根据用户、IP进行限流，若这一时间段是同一个 IP 重复访问，则不进行处理。
  - 验证码：通过验证码或其他类似操作延迟用户请求，这样可以避免用户请求过于集中。
  - 前端预处理：前端对于同一个用户的重复点击，在一个时间端内只向后端发起一次请求。
- **流量削峰：** 将暂时处理不了的大量请求放到消息队列中，然后根据系统能处理的请求量从队列中进行消费。
- **降级：** 主要是从系统功能的优先级角度考虑。当请求量达到一个阈值后，关闭或降低一些非核心的功能，将更多服务器资源供应秒杀功能。
- **熔断：** 熔断主要是为了应对所依赖的外部系统故障。比如秒杀功能位于 A 服务，而 A 服务上还有一些比如商品管理功能，当商品管理接口响应很慢的时候，则这个商品管理接口就不再被允许请求，避免发生服务雪崩。

==**一致性**==

- **减库存方案：** 一般是下单就减库存，如果超过一定时间未付款订单则释放该库存。在 Redis 中结合 Lua 脚本维持一个库存变量，如果库存充足，返回1，否则直接返回0；

- **接口幂等性：** 对于相同的重读请求，返回的结果和单个请求的结果是一致的。
  - 业务字段唯一性约束，防止重复订单数据
  - 分布式锁（==Redisson==）看门狗 自动续期
  - 同步锁（==ReentrantLock==）（可以吗？？）



## 测试开发

### 为什么选择测试开发

也是在平时学习的时候接触到测试相关的东西，尤其是在做项目的时候需要对写好的功能进行单元测试，也是在这个过程中就更多去看了一些测试相关的知识。了解到测试测试也是产品研发中重要的步骤，尤其在公司项目中测试有一套完整的流程规范，是产品质量与效率的重要保证。并且测试涉及的技术也很广，并不是网上戏谑的那样。我在浏览贵公司发布的岗位要求的时候，觉得自己的技术栈跟测开岗位也是比较匹配的，所以就投递了测开岗位做一个尝试。

### 软件测试是什么

在规定的条件下通过测试工具对一个产品或者系统进行操作，发现其**功能逻辑错误**，和进行**性能评估**，并对其是**否能满足设计要求**进行综合评估的过程。

而且，现在不仅仅是通过手工测试来发现定位Bug，也会通过编写脚本、测试工具来完成自动化测试，因此，对于测试开发人员来说，他除了保证产品质量之外，还要编写脚本以及开发测试工具。这就是我对测试开发的一点理解。

### 测试开发和测试的区别

- 测试的任务：检查软件**是否有bug**、是否具**有稳定性**，写出相应的**测试计划、测试规范、测试用例、测试数据、测试报告**。总的来说，就是**确保产品的正常运转**。
- 测开的任务：在具备测试经验、熟练使用测试工具并有一定开发能力的前提下，可以**自主开发平台，**或对现有的开源工具进行二次开发。最**终目的是提升产品的测试效率**。
- 两者的关联：测试开发是测试岗位衍生的一个分支，利用开发能力解决测试工作中的问题，小到生成数据、并发模拟等工具的开发，大到整个自动化测试平台的设计与实现，旨在提高效率，降低成本。

### 一个完整的测试流程

测试工作需要贯穿整个软件的生命周期，可以分为以下几个阶段：

1. 需求分析：了解和把握功能需求
2. 制定测试计划：根据开发计划确定各个测试时间点
3. 设计测试用例：根据需求写用例
4. 用例评审：与开发人员、项目经理共同商讨，对用例进行评审
5. 执行测试用例：进行测试，做好记录，发现问题要保留现场
6. 缺陷报告编写及提交：写成正式的缺陷报告，提交给开发人员进行确认和修复
7. 跟踪修改情况

### 如何进行软件测试，从哪些方面考虑

- UI测试：用户界面显示是否正确，排版、控件、图标是否合适等

- 功能测试：根据需求文档的各个功能进行测试

- 兼容性测试：测试应用在不同操作系统上的兼容性、数据格式的兼容性、硬件的兼容性、应用软件的兼容性（测试数据或信息是否能到处第三方软件工具）

- 性能测试：压力测试，以一定的请求总量，逐步增加并发量，观察QPS和响应时间的变化

  TPS：每秒处理的事务数目（事务为当个服务接口：QPS=TPS）      QPS：每秒处理的查询数目       并发量：每秒对待测试接口发起请求的用户数量      响应时间：处理一次请求所需要的平均处理事件     QPS = 并发量/响应时间

- 安全性测试：验证应用程序的安全等级和识别潜在安全缺陷的过程

- 易用性测试：要根据多个用户的测试反馈信息

### 什么是黑盒测试

主要是检查软件的每一个功能是否能够正常使用，检查程序功能是否按照设计需求以及说明书的规定能够正常使用。在测试过程中，不考虑程序内部结构和特性的基础上通过程序接口进行测试

### 黑盒测试常用方法

- 等价类划分：将系统输入划分为若干区域，那么可以认为每类中的一个典型值在测试中的作用与这一类中其他值的作用相同。因此可以从每个部分选取少量代表性数据进行测试
- 边界值分析法：边界值分析法是通过优先选择不同等价类间的边界值覆盖有效等价类和无效等价类来更有效的进行测试，因此该方法要和等价类划分法结合使用。选取的测试数据应该刚好等于、刚刚小于和刚刚大于边界值
- **判定表法**：判定表驱动法是分析和表达多逻辑条件下执行不同操作的情况的工具。（看不懂）
- 错误分析法：错误推测法是基于以往的经验和直觉，参照以往的软件系统出现的错误，推测当前被测程序中可能存在的缺陷和错误，有针对性地设计测试用例。

### 什么是白盒测试

它根据程序的控制结构设计测试用例，白盒测试法检查程序内部逻辑结构，对所有的逻辑路径进行测试，是一种穷举路径的测试方法

### 白盒测试常用方法

- 语句覆盖：设计若干个测试用例，使每个执行语句至少被执行一次
- 判定覆盖：包含语句覆盖，每个判断的取值分支都至少执行一次
- 条件覆盖：包含语句覆盖，判定中每个条件的所有可能结果至少出现一次
- 判定条件覆盖：包含判定覆盖、条件覆盖。说白了就是我们设计的测试用例可以使得判断中每个条件所有的可能取值至少执行一次（条件覆盖），同时每个判断本身所有的结果，也要至少执行一次（判定覆盖）
- 条件组合覆盖：每个条件的每种组合。在白盒测试法中，选择足够的测试用例，使所有判定中各条件判断结果的所有组合至少出现一次，满足这种覆盖标准成为条件组合覆盖
- 路径覆盖：所有路径至少执行一次 

### 测试用例步骤

1. 详细了解并梳理系统功能需求，必要时找产品进行需求澄清；
2. 如果是比较复杂，或者对原有功能改动较多，在梳理需求的过程最好能画出业务流程图；
3. 根据需求/流程图列出所有功能测试点；
4. 根据测试点编写详细的功能测试用例。

### 微信红包测试

==**功能测试：**==

- 红包填写（边界值分析）

  ​	1）非特殊日期正确金额；2）非特殊日期超出金额；3）特殊金额 金额范围；4）错误金额；5）祝福语 / emoji

- 红包发送
  ​	1）支付金额一致性 / 余额 / 密码验证 / 支付方式

- 红包发送成功
  ​	1）扣款正确 / 消息正确 / 发红包记录

- 拆红包

  ​	1）红包消息显示 / 领取金额 /  退款

- 其他功能

==**性能测试：**==

- 多人收发红包

==**异常测试：**==

- 前后台切换，网络异常，低电量，断电，来电，短信等

==**安全性测试：**==

- 敏感隐私内容禁止搜索

==**兼容性测试：**==

- 安卓/iOS，不同分辨率，微信版本

==**界面测试：**==

- 界面颜色/ 无错别字

==**网络测试：**==

- 络兼容性，弱网，无网

### 常见的Linux命令

- 系统管理： 

  su   切换账号      

  ifconfig   查看IP地址

  ping  检查网络是否连接

  kill  杀死进程       kill -9   强制杀死

- 系统资源管理：

  ps   查看进程

  ps  -ef   查看所有的进程

  netstat   查看网络状况

  netstat -anp  查看所有的端口

  tail   -f   文件   实施显示文件（默认末尾的10行，可根据-n参数调整）

- 管道命令：  ps -ef  | grep  “关键字”  查看所有的进程，通过管道找到相应的进程包名

- 目录操作：

  cd  进入目录       cd  / 根目录

  pwd  当前目录       mkdir     创建目录

  rmdir   删除目录      ls    ll  查看所有的目录

- 文件编辑命令：

  vi     a.txt   编辑文件            cat   a.txt      查看文件

  rm   -rf   强制删除           find  目录   -name   .txt      在指定目录下查找txt文件

- 测试相关：ping测试连通性，测试端口连通性telnet
