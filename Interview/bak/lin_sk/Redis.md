# Redis

### 为什么使用redis

- 高性能：MySQL需要从硬盘读取数据，速度较慢。而Redis可以将数据缓存到内存，从内存中读取，性能会高许多
- 高并发：Redis相比于MySQL同时可以处理的请求要大得多

### 为什么设计SDS（简单动态字符串）

- 具有len属性，更快捷地获取字符串长度
- 杜绝缓冲区溢出：在字符串拼接时，会根据len属性判断内存是否够用，不够用会进行相应的空间拓展
- 减少修改字符串时的内存重新分配次数：实现了空间预分配和惰性空间释放
- 二进制安全：c字符串以空字符串判断是否结束，但二进制文件只可能包含空字符串；SDS以len属性判断是否结束
- 兼容部分c字符串函数

### Redis Stream消息ID的设计

时间戳+序号。时间戳是毫秒级的（64位），序号在一个时间戳内自增（64位）

### Redis Stream消费者崩溃带来的会不会消息丢失问题

不会。读取但未处理的数据会存放在pending列表，只有ack确认处理完成才会从pending列表中删除

### Redis Steam 坏消息问题，死信问题

当一个消息无法被XACK，就会一直呆在pending列表，成为死信。

解决：消息内部有一个计数器，当每次被消费者处理不成功时就+1，当达到设定的阈值时，就可以认为死信，手动将其删除

### Redis key 的过期时间和永久有效分别怎么设置

expire和persist

### Redis文件事件的模型

Redis基于Reactor模型，使用IO多路复用技术实现文件事件处理器，同时监听多个套接字并关联不同的事件，当套接字的可读或可写事件发生时，就调用相应的事件处理函数

### 说说Redis哈希槽的概念？为什么是16384个？

用于在集群模式下进行映射来选择节点，key经过hash计算后对16384取模从而确定槽位，而每个节点都会负责一定范围的槽位

16384表示最多有16k个槽位，这个数量的槽位完全足够使用了，使用bitmap压缩后只需2kb空间

### Redis性能问题有哪些

- 慢查询
- 大key
- 集中过期
- 使用Swap：当内存不足时会借用磁盘
- fork耗时：例如AOF重写，主从复制
- 内存碎片：4.0后提供自动碎片整理功能

## 数据类型

### String

String是最基本的key-value结构，数据结构为int和SDS（简单动态字符串），应用场景如下：

- 缓存对象：将对象json序列化后进行缓存
- 常规计数，例如点赞，库存
- 分布式锁：setnx命令
- 共享session：将多台服务器的session存到一台redis主机上实现共享

### List

List是字符串列表，数据结构为双向链表或压缩列表，可以作为消息队列使用，满足三个特性：

- 消息保序：列表结构，并且一端进，一端出，自然有序
- 处理重复消息：需要自己实现唯一id来避免处理重复消息
- 消息可靠性：使用BRPOPLPUSH命令可以留存消息，读出消息后会存到备份list中

作为消息队列的缺陷：不支持多个消费者处理同一条消息

### Hash

hash为key-（filed-value）结构，其中value可以看作一个hash表，适合对象存储，相较于字符串，是否对象属性频繁更改的场景

### Set

set为key-set结构，元素无序且唯一，可以做交并集操作（复杂度高），适用场景：

- 点赞：一个用户只能点一次
- 共同关注：取交集
- 抽奖活动：保证用户不重复抽

### Zset

有序的set，相较于set多了一个sorce值，根据sorce值排序，可以按范围读取，应用场景：排行榜，电话姓名排序

### BitMap

位图，是一串连续的二进制数组，适用于数据量大且二值统计的场景，常用于签到统计、用户登录状态统计

### HyperLogLog

提供不精确的计数统计，标准误算率0.81，应用场景：百万级网页访问量统计

### GEO

存储二维地理位置，底层结构为sorted set，应用场景：附近搜素

### Stream

专门为消息队列设计的数据结构，可以满足以下特性：

- 消息保序：插入消息是有序的并且有id，读消息时可以指定id读取
- 阻塞读取：XREAD block读不到消息会堵塞
- 重复消息处理：在添加消息时会生成唯一id
- 消息可靠性：适用内部队列保存消息，但消息取出时并不会删除，当消费者处理完消息消息队列发送通知，这时消息队列才会把消息进行删除
- 支持消费组进行消费

但仍有不足：

- 消息丢失：在生产端和消费端因为有确认机制所以消息不会丢失，但是在队列中间环节，因为消息本质存储在redis中，在AOF持久化或者主从复制时可能会发生丢失
- 消息不可堆积：消息堆积会导致内存紧张

因此，基于Stream的消息队列一般用在对数据丢失不敏感的场景，例如即时通信

## 持久化

### AOF日志是怎么工作的

开启AOF日志后（默认关），在进行写操作时，先执行命令，然后会将写操作指令写入AOF日志文件缓存，在写入磁盘持久化，这些操作都在主进程进行

先执行命令再写入日志的好处：

- 先执行命令会进行语法检查，如果语法有误，那么也就不会写日志，避免冗余操作
- 不会堵塞当前的操作命令

也有坏处：

- 有丢失风险，可能写了数据但没来得及写入日志，此时宕机就是丢失数据
- 有可能堵塞下一条命令

### AOF三种写回策略

- Always：在每次执行命令后就写入磁盘，高安全性
- EverySec：每秒将文件缓存页写入磁盘（异步执行），折中
- No：不控制，交给操作系统决定何时写入磁盘，高性能

### AOF后台重写

1. 当AOF日志太大时，redis会开启一个子进程来对AOF日志进行重写，通过去重来压缩文件大小。开启的子进程会与主进程共享物理内存，这部分内存是只读的。

2. 当主进程进行写操作时，会触发写时复制，开辟新的物理地址然后更改引用地址，此时主进程的页表指向新地址，子进程的页表仍指向旧地址。

3. 主进程写操作时，这个操作会被记录AOF缓冲区（正常的AOF记录流程，保证旧AOF文件的数据一致性）和AOF重写缓冲区（用于重写后追加，保证新AOF文件的数据一致性）。

4. 在子进程完成重写后，会发送信号给主进程，主进程再将AOF重写缓冲区的命令追加到新AOF文件，最后用新文件替换旧文件完成重写

在重写过程中，页表复制、写时复制和命令追加会导致主进程阻塞

### RDB快照是如何工作的

RDB存储的是记录本身，相较于AOF日志（记录操作），恢复数据的速度更快；RBD可以通过save（主进程调用）和bgsave（子进程调用）执行，也可以设置自动执行；RBD为全数据保存，因此对性能影响较大，通常设置5分钟保存一次

### RDB快照时可以修改数据吗

如果在主进程调用，则主进程其他操作会被堵塞；

如果在子进程调用，那么主进程写操作时会触发写时复制，不过期间主线程的操作不会被RDB快照记录。

### AOF和RDB合体

通过配置文件可以开启AOF和RDB的混合模式，结合了AOF数据丢失少和RDB数据恢复快的优点：

在AOF重写期间，会将内存数据记录为RDB快照记录到AOF文件中，另外在此期间的主进程进行的写操作会保存到重写缓冲区，然后在重写后进行追加命令，然后用新文件替换旧文件。新的AOF文件前部分时RDB快照后半部分是AOF格式的增量。

### 大Key对持久化的影响

1. 首先，如果AOF写回策略选择always，那么大key的写入会堵塞主进程，其他策略不会
2. 在重写AOF和保存RDB时，要复制页表，此阶段会发生堵塞，另外在重写和保存期间，主进程对大key进行了修改也会触发复制导致阻塞
3. 另外大key会增加AOF文件大小，从而导致更快的触发AOF重写，影响性能

## 过期删除和内存淘汰

### 有哪些过期删除策略

- 定时删除：对key设置过期时间后，cpu设置定时器，当时间到时进行删除。这种做法可以有效节约内存空间，但如果大量的key会占用cpu资源，导致性能下降
- 惰性删除：不主动删除，只有当查询到key并检查发现已经过期才删除，这样不影响cpu性能，但浪费内存空间
- 定期删除：cpu定期抽取一些key检查，若发现过期则删除，是上面两种方案的折中考虑

### Redis的过期策略是怎样的

惰性删除+定期删除

惰性删除：对key进行操作时，会调用函数判断是否过期（key是否在过期字典，时间是否过期），若过期则删除

定期删除：

- 多久检查一次：默认一秒10次
- 随机抽查的数量：20个（写死的）
- 循环删除流程：若一次抽查中，过期的key占比大于25%，会循环抽查删除，知道过期key占比小于25%，或者到达超时时间（默认25ms）

### Redis有哪些内存淘汰策略

- noeviction：不进行数据淘汰，内存满就无法写入（默认）

在设置了过期时间的数据范围内

- volatile-random：随机淘汰
- volatile-ttl：优先淘汰快过期的
- volatile-lru：优先淘汰最久没被使用的
- volatile-lfu：优先淘汰最少使用的

在所有数据范围内：

- allkeys-random：随机淘汰
- allkeys-lru：优先淘汰最久没被使用的
- allkeys-lfu：优先淘汰最少使用的

### LRU和LFU的区别

LRU：指会优先淘汰最久没有被访问的数据，redis通过记录数据的最近访问时间来近似实现LRU（无需维护链表）；但LRU无法避免缓存污染，缓存污染指的是大量缓存只被访问一次，但会在内存中存在很久，并且可能会淘汰热点数据

LFU：指会优先淘汰最不常使用的数据，redis通过记录数据的访问频次来实现（具体算法没看懂），可以解决缓存污染的问题

## 高可用

### 主从复制是如何进行的

**全量复制**（第一次同步）：

1. 建立连接，协商同步：从库向主库请求同步，主库收到请求后返回相应给从库，同时开始准备数据同步
2. 主库将数据同步给从库：主库执行bgsave命令开启子进程生成RDB快照，在生成RDB快照期间，发送RDB以及从库复制RDB的期间，主库的写操作命令会记录到缓冲区（replication buffer）
3. 主库将增量操作发送给从库：从库完成同步后发送信息给主库，主库收到后，将缓冲区中的写操作命令发送给从库，从库接受后执行，完成同步

如何分摊第一次同步时的主服务器压力：设置中间节点（经理服务器），中间节点从主库完成复制后再将自己的从库进行同步

**基于长连接的命令传播**：第一次同步后，就建立起一个长连接，后续不断将主库的命令传输给从库，保持主从一致

**增量复制**：在网络中断后恢复时使用，主服务器会有一个环形缓冲区，在每次命令传输时，主服务器会把命令记录到这个缓冲区，并使用一个偏移量记录写入的位置，从服务器同步命令时也会用偏移量记下读的位置。当网络中断恢复后，从服务会向主服务发送请求，同时携带偏移量，主服务器收到请求后，会拿着偏移量在环形缓冲区比对：

- 如果存在：则返回读写偏移量之间的增量命令给从服务进行同步
- 如果不存在：那么说明缺少的数据已经不在环形缓冲区，进行全量复制

###  Redis主从节点时长连接还是短连接？

长连接

### 怎么判断Redis节点是否可用

通过互相ping-pong心跳检测来判断，是否一半以上的节点去ping一个节点都没有反应，那么就认为这个节点挂了。主从节点的心跳检测间隔也有差别：

主节点：默认每隔10s ping一次从节点

从节点：每隔1s 就向主节点发送请求同时带上偏移量，检查是否有数据 丢失，如果有就同步数据

### 主从复制中过期key删除如何同步

如果一个key因过期被删除，主服务器会同步删除命令给从服务器

### 主从复制中两个 Buffer(replication buffer 、repl backlog buffer)有什么区别？

replication buffer 在同步复制的场景都会出现，记录在同步过程中主服务器进行的写操作，用于追加命令保持数据一致性，但空间不足时，会导致连接断开，删除缓存，重新开始全量复制

repl backlog buffer是环形缓冲区，在增量复制的时候出现，它记录一段时间内主服务的操作命令以及主服务器写和从服务读的偏移位置，用于网路中断恢复后，同步这段时间内丢失的数据，如果空间满了，则覆盖旧记录

### 如何应对主从数据不一致

原因：由于主从复制是异步进行的，不能保证数据的强一致性

方法：

1. 尽量保证主从服务器的网络良好，例如放在同一机房，从而保证数据被及时的同步
2. 可以开发一个监测程序，这个程序读取主服务器写操作的进度以及从服务器同步的进度，然后对比两者的进度差，设置一个阈值，如果进度差高于这个阈值，那么说明从服务与主服务器的数据一致性非常差，则禁止客服端访问这个从服务器读取数据，从而避免读到太过时的数据

### 主从切换导致的数据丢失

两种情况会导致主从切换时数据丢失：

- 异步复制导致的数据丢失：由于主从复制是异步的，那么有可能还没来得及同步，主节点挂了，导致数据丢失；
  - 解决方法：设置min-salves-max-lag，当主从节点间的延迟大于阈值时，会暂时关闭redis的写功能，这样一来最多丢失阈值时间内的数据；而客户端发现redis不可用可以采用降级措施，例如将消息先写入消息队列，待redis恢复再重新写入。
- 脑裂问题导致的数据丢失：集群间主从节点因网络问题无法连接，此时选举出新的主节点，但是旧的主节点此时依然与客户端保持正常连接，接受新数据。当集群间网络恢复后，旧的主节点被降级为从节点，其保存的数据也就被删除了，导致数据丢失。
  - 解决方法：设置min-salves-max-lag与min-salves-to-write，设置主节点连接从节点的最小数量与最大延迟，当到达阈值后，就认为该主节点已经挂了，向客户端发送错误信息。此时进行主从切换，选举新节点，让客户端与新主节点连接，避免脑裂问题。

### 什么是哨兵机制

哨兵机制的作用是实现故障时主从切换，它会对主节点进行监测，如果发现主节点不可用，则选举出新的主节点，并通知从节点和客户端。哨兵的工作有三个：监控、选举、通知。

### 如何判断主节点故障

主观下线：哨兵节点会向主从节点每秒ping一次，如果规定时间内没有收到响应就将该节点标记为主观下线

客观下线：客观下线是针对主节点的，指的是主节点因为网络问题或者其他原因发生堵塞而无法对哨兵相应，并不是真的出现了故障。一般为了避免误判主节点下线，会设置多个哨兵节点组成集群。当某个哨兵节点认为主节点下线后，会询问其他哨兵节点进行投票，如果投票超过一定数量（一般是哨兵节点数量/2+1），就将主节点标记为客观下线。

### 谁去进行主从切换

哨兵集群会选出一个leader来进行主从切换。当哨兵节点判断主节点客观下线后，自己会成为leader候选者，此时所有哨兵节点进行投票，如果票数超过半数并且票数超过设定值，该哨兵节点当选leader

因为投票机制，所以哨兵一般至少三个以上，票数要求设置为总数的一半+1

### 如何进行主从故障转换

1. 选出一个新的主节点，发送SLAVEOF no one命令使其成为主节点，并每隔1s询问该节点的身份信息，当身份信息由slave变为master时则确认其变为主节点。选择主节点的原则：
   1. 先排除网络状态不佳的节点
   2. 选择由优先级更高的节点
   3. 选择复制进度最多的节点
   4. 选择id靠前的节点
2. 通知所有从节点新的主节点（ip和端口）
3. 同步发布者-订阅者机制告知客户端新的主节点（ip和端口）。通过发布者/订阅者机制机制，客户端不仅可以在主从切换后得到新主节点的连接信息，还可以监控到主从节点切换过程中发生的各个重要事件
4. 继续监测旧的主节点，当其重新上线后将其降级为从节点

### 哨兵集群是如何组成的

哨兵是通过发布-订阅机制互相发现的

主节点上有一个频道，哨兵会将自己的ip端口信息发布到该频道，从而被其他哨兵所发现；

同时主节点拥有所有从节点信息，哨兵每隔10s会向主节点发送INFO命令来获得从节点信息

## 缓存

### 缓存穿透

原因：查询的key不存在，则会一直访问数据库

解决：

- 不存在的数据缓存空值
- 布隆过滤算法判断是否存在
- 加强格式检查，拦截无效请求

### 缓存雪崩

原因：某一时间大量的key同时过期，导致大量请求访问到数据库；或者Redis宕机

解决：

- 设置过期时间的时候加一些随机值
- 设置降级措施
- 设置高可用Redis集群

### 缓存击穿

原因：某个热点key失效导致大量请求访问数据库

解决：

- 互斥锁+逻辑过期时间

### 数据库与缓存如何保持一致

不论是先更新数据库还是先更新缓存，在并发场景下都可能发生数据不一致的问题；可以使用

先更新数据库再删除缓存可以保证数据一致（出现问题的概率很小），但会导致缓存命中率降低

## 事务

### Redis事务相关命令

- Multi：开启事务，之后的命令会进入队列
- Exex：执行队列中的所有命令
- Discard：取消事务
- Watch：在事务开启前监视一些key，在执行前检查key修改，如果修改了会中断事务，事务失败
- Unwatch：取消监视

### Redis事务的三个阶段

- 开启
- 入队
- 执行

### Redis事务其它实现

- lua脚本，但不提供运行错误的回滚
- 记录标记量，通过标记量来判断事务是否成功，需要代码层面的维护

### Redis事务中会出现哪些错误

- 语法错误：编译时错误，会导致事务失败进行回滚
- 类型错误：运行时错误，不会导致事务失败仅该条命令执行失败

### 为什么Redis不支持回滚

- 失败的命令应当在编译时就被发现
- 内部可以保持简洁和高效

### Redis对ACID的支持

- 原子性：不支持，运行时命令错误也不会回滚
- 一致性：支持，错误的命令要么导致事务失败，要么跳过
- 隔离性：支持，单线程+Watch机制保证事务开启后其他客户端无法访问
- 持久性：不支持，Redis中的持久化都是异步执行的，从而无法保证完全可靠的持久化

